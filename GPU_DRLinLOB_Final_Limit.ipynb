{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9p3-S92lKExR"
   },
   "source": [
    "#**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BIlu8fyTWLSS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def rescale_data(data_order, data_message, data_level, time_window=0.1):\n",
    "    start_time = 34201\n",
    "    end_time = 57599\n",
    "    data = np.concatenate((data_message[:-1, 0].reshape([-1, 1]), data_order[1:, :]), axis=1)\n",
    "    data_new = np.empty([int((end_time - start_time) / time_window) + 1, int(4 * data_level)])\n",
    "    time_scale = np.arange(start_time, end_time, time_window)\n",
    "    k = 0\n",
    "    for i in range(time_scale.shape[0]):\n",
    "        while k < data.shape[0] and data[k, 0] < time_scale[i]:\n",
    "            k = k + 1\n",
    "        \n",
    "        data_new[i] = data[k - 1, 1:]\n",
    "\n",
    "    n, m = data_new.shape\n",
    "    for i in range(int(m / 2)):\n",
    "        data_new[:, 2 * i] = data_new[:, 2 * i] / 10000\n",
    "\n",
    "    return data_new,time_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0-_fVQCoMq79"
   },
   "outputs": [],
   "source": [
    "#level_5\n",
    "columns = ['L1_ask_price','L1_ask_quantity','L1_bid_price','L1_bid_quantity','L2_ask_price','L2_ask_quantity','L2_bid_price','L2_bid_quantity','L3_ask_price','L3_ask_quantity','L3_bid_price','L3_bid_quantity','L4_ask_price','L4_ask_quantity','L4_bid_price','L4_bid_quantity','L5_ask_price','L5_ask_quantity','L5_bid_price','L5_bid_quantity']\n",
    "\n",
    "#level_10\n",
    "#columns = ['L1_ask_price','L1_ask_quantity','L1_bid_price','L1_bid_quantity','L2_ask_price','L2_ask_quantity','L2_bid_price','L2_bid_quantity','L3_ask_price','L3_ask_quantity','L3_bid_price','L3_bid_quantity','L4_ask_price','L4_ask_quantity','L4_bid_price','L4_bid_quantity','L5_ask_price','L5_ask_quantity','L5_bid_price','L5_bid_quantity','L6_ask_price','L6_ask_quantity','L6_bid_price','L6_bid_quantity','L7_ask_price','L7_ask_quantity','L7_bid_price','L7_bid_quantity','L8_ask_price','L8_ask_quantity','L8_bid_price','L8_bid_quantity','L9_ask_price','L9_ask_quantity','L9_bid_price','L9_bid_quantity','L10_ask_price','L10_ask_quantity','L10_bid_price','L10_bid_quantity']\n",
    "\n",
    "def get_dataframe(name):\n",
    "  # load the order and message book. We use the level 5 limit order book data.\n",
    "  file_path = './'\n",
    "  data_name = '{}_2012-06-21_34200000_57600000_'.format(name)\n",
    "  data_level = 5\n",
    "  data_order = np.loadtxt(file_path + data_name + 'orderbook_' + str(data_level) + '.csv', delimiter=',')\n",
    "  data_message = np.loadtxt(file_path + data_name + 'message_' + str(data_level) + '.csv', delimiter=',')\n",
    "\n",
    "  # set time window, forecast size, and look back range.\n",
    "  time_window = 0.25\n",
    "\n",
    "  # turn data into evenly spaced, then split the one day dataset into two half day datasets.\n",
    "  evenly_spaced_data,time_scale = rescale_data(data_order, data_message, data_level, time_window)\n",
    "\n",
    "  even_df = pd.DataFrame(evenly_spaced_data,columns=columns)\n",
    "  date  = pd.DataFrame(time_scale,columns=['date'])\n",
    "\n",
    "  #mid = (even_df['L1_ask_price'] + even_df['L1_bid_price']) /2\n",
    "  #mid_price = pd.DataFrame(mid,columns=['mid_price'])\n",
    "\n",
    "  #ask_bid = pd.DataFrame((even_df['L1_ask_price'],even_df['L1_bid_price']),columns=['ask_bid'])\n",
    "  #ask_bid_q = pd.DataFrame((even_df['L1_ask_quantity'],even_df['L1_bid_quantity']),columns=['ask_bid_quantity'])\n",
    "  \n",
    "  #even_df['ask_bid_price'] = list(zip(even_df['L1_ask_price'],even_df['L1_bid_price']))\n",
    "  #even_df['ask_bid_quantity'] = list(zip(even_df['L1_ask_quantity'],even_df['L1_bid_quantity']))\n",
    "  #new_df = even_df[['ask_bid_price','ask_bid_quantity']]\n",
    "  #even_df.drop(['ask_bid_price', 'ask_bid_quantity'], axis=1,inplace=True)\n",
    "\n",
    "  df = pd.concat([date,even_df],axis=1)\n",
    "  df.dropna(inplace=True)\n",
    "  day = '2012-6-21 '\n",
    "  df.date =[(day + str(datetime.timedelta(seconds=i))) for i in df.date.values]\n",
    "  df['date']= pd.to_datetime(df['date'])\n",
    "  df['tic'] = name\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cjSdPb4COOdv"
   },
   "outputs": [],
   "source": [
    "AAPL_df = get_dataframe('AAPL')\n",
    "AMZN_df = get_dataframe('AMZN')\n",
    "GOOG_df = get_dataframe('GOOG')\n",
    "INTC_df = get_dataframe('INTC')\n",
    "MSFT_df = get_dataframe('MSFT')\n",
    "\n",
    "data = pd.concat([AAPL_df,AMZN_df,GOOG_df,INTC_df,MSFT_df], ignore_index=True)\n",
    "\n",
    "data = data.sort_values(['date','tic'],ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IAwU0H5U_74i",
    "outputId": "9a41df38-8760-482d-8790-23cef7500db3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467960, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "lJUJEqLRG7mh",
    "outputId": "ee9a2e2d-08d6-48e8-e69d-7ce1aa068754"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>L1_ask_price</th>\n",
       "      <th>L1_ask_quantity</th>\n",
       "      <th>L1_bid_price</th>\n",
       "      <th>L1_bid_quantity</th>\n",
       "      <th>L2_ask_price</th>\n",
       "      <th>L2_ask_quantity</th>\n",
       "      <th>L2_bid_price</th>\n",
       "      <th>L2_bid_quantity</th>\n",
       "      <th>L3_ask_price</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_bid_quantity</th>\n",
       "      <th>L4_ask_price</th>\n",
       "      <th>L4_ask_quantity</th>\n",
       "      <th>L4_bid_price</th>\n",
       "      <th>L4_bid_quantity</th>\n",
       "      <th>L5_ask_price</th>\n",
       "      <th>L5_ask_quantity</th>\n",
       "      <th>L5_bid_price</th>\n",
       "      <th>L5_bid_quantity</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-21 09:30:01</td>\n",
       "      <td>585.87</td>\n",
       "      <td>100.0</td>\n",
       "      <td>585.74</td>\n",
       "      <td>100.0</td>\n",
       "      <td>585.89</td>\n",
       "      <td>100.0</td>\n",
       "      <td>585.71</td>\n",
       "      <td>18.0</td>\n",
       "      <td>585.93</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>585.94</td>\n",
       "      <td>300.0</td>\n",
       "      <td>585.69</td>\n",
       "      <td>20.0</td>\n",
       "      <td>585.98</td>\n",
       "      <td>400.0</td>\n",
       "      <td>585.65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-06-21 09:30:01</td>\n",
       "      <td>223.86</td>\n",
       "      <td>100.0</td>\n",
       "      <td>223.84</td>\n",
       "      <td>100.0</td>\n",
       "      <td>223.95</td>\n",
       "      <td>60.0</td>\n",
       "      <td>223.75</td>\n",
       "      <td>74.0</td>\n",
       "      <td>224.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>224.24</td>\n",
       "      <td>20.0</td>\n",
       "      <td>223.60</td>\n",
       "      <td>15.0</td>\n",
       "      <td>224.25</td>\n",
       "      <td>100.0</td>\n",
       "      <td>223.51</td>\n",
       "      <td>100.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-06-21 09:30:01</td>\n",
       "      <td>579.79</td>\n",
       "      <td>210.0</td>\n",
       "      <td>579.19</td>\n",
       "      <td>75.0</td>\n",
       "      <td>579.89</td>\n",
       "      <td>25.0</td>\n",
       "      <td>579.12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>579.95</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>579.98</td>\n",
       "      <td>5.0</td>\n",
       "      <td>578.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>580.00</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>578.70</td>\n",
       "      <td>400.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-06-21 09:30:01</td>\n",
       "      <td>27.53</td>\n",
       "      <td>326.0</td>\n",
       "      <td>27.52</td>\n",
       "      <td>200.0</td>\n",
       "      <td>27.54</td>\n",
       "      <td>673.0</td>\n",
       "      <td>27.51</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>27.55</td>\n",
       "      <td>...</td>\n",
       "      <td>11781.0</td>\n",
       "      <td>27.56</td>\n",
       "      <td>200.0</td>\n",
       "      <td>27.49</td>\n",
       "      <td>400.0</td>\n",
       "      <td>27.57</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>27.48</td>\n",
       "      <td>3761.0</td>\n",
       "      <td>INTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-06-21 09:30:01</td>\n",
       "      <td>31.00</td>\n",
       "      <td>28256.0</td>\n",
       "      <td>30.98</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.01</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>30.97</td>\n",
       "      <td>353.0</td>\n",
       "      <td>31.02</td>\n",
       "      <td>...</td>\n",
       "      <td>218.0</td>\n",
       "      <td>31.03</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>30.95</td>\n",
       "      <td>8261.0</td>\n",
       "      <td>31.04</td>\n",
       "      <td>6767.0</td>\n",
       "      <td>30.94</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  L1_ask_price  L1_ask_quantity  L1_bid_price  \\\n",
       "0 2012-06-21 09:30:01        585.87            100.0        585.74   \n",
       "1 2012-06-21 09:30:01        223.86            100.0        223.84   \n",
       "2 2012-06-21 09:30:01        579.79            210.0        579.19   \n",
       "3 2012-06-21 09:30:01         27.53            326.0         27.52   \n",
       "4 2012-06-21 09:30:01         31.00          28256.0         30.98   \n",
       "\n",
       "   L1_bid_quantity  L2_ask_price  L2_ask_quantity  L2_bid_price  \\\n",
       "0            100.0        585.89            100.0        585.71   \n",
       "1            100.0        223.95             60.0        223.75   \n",
       "2             75.0        579.89             25.0        579.12   \n",
       "3            200.0         27.54            673.0         27.51   \n",
       "4            100.0         31.01           1599.0         30.97   \n",
       "\n",
       "   L2_bid_quantity  L3_ask_price  ...  L3_bid_quantity  L4_ask_price  \\\n",
       "0             18.0        585.93  ...             44.0        585.94   \n",
       "1             74.0        224.00  ...              2.0        224.24   \n",
       "2            100.0        579.95  ...             41.0        579.98   \n",
       "3           3215.0         27.55  ...          11781.0         27.56   \n",
       "4            353.0         31.02  ...            218.0         31.03   \n",
       "\n",
       "   L4_ask_quantity  L4_bid_price  L4_bid_quantity  L5_ask_price  \\\n",
       "0            300.0        585.69             20.0        585.98   \n",
       "1             20.0        223.60             15.0        224.25   \n",
       "2              5.0        578.99              1.0        580.00   \n",
       "3            200.0         27.49            400.0         27.57   \n",
       "4           3400.0         30.95           8261.0         31.04   \n",
       "\n",
       "   L5_ask_quantity  L5_bid_price  L5_bid_quantity   tic  \n",
       "0            400.0        585.65              5.0  AAPL  \n",
       "1            100.0        223.51            100.0  AMZN  \n",
       "2           2937.0        578.70            400.0  GOOG  \n",
       "3           1100.0         27.48           3761.0  INTC  \n",
       "4           6767.0         30.94           1573.0  MSFT  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.set_index('date',inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QNMLdZVGpkQ"
   },
   "source": [
    "#**installing & Importing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35ZOExzqMWM5",
    "outputId": "b1133689-4820-4153-aeef-988635be9639"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelmoez/.local/lib/python3.8/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "\n",
    "from finrl.apps import config\n",
    "# from finrl.neo_finrl.preprocessor.preprocessors import data_split\n",
    "#from finrl.neo_finrl.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.drl_agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "elPwGMhEMYOW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3GmpJmRMeCr"
   },
   "source": [
    "#**Feautre Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Nf34PH_NP49"
   },
   "source": [
    "#**Design Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ssqMrDu1696K"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from copy import deepcopy\n",
    "%matplotlib inline\n",
    "\n",
    "# from stable_baselines3.common import logger\n",
    "\n",
    "\n",
    "class StockTradingEnv(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        stock_dim,\n",
    "        #hmax,\n",
    "        initial_amount,\n",
    "        #buy_cost_pct,\n",
    "        #sell_cost_pct,\n",
    "        reward_scaling,\n",
    "        state_space,\n",
    "        action_space,\n",
    "        depth_list,\n",
    "        #turbulence_threshold=None,\n",
    "        #risk_indicator_col=\"turbulence\",\n",
    "        debt_amount = 0,\n",
    "        make_plots=False,\n",
    "        print_verbosity=10,\n",
    "        time_frame=0,\n",
    "        initial=True,\n",
    "        previous_state=[],\n",
    "        model_name=\"\",\n",
    "        mode=\"\",\n",
    "        shares_limit=500,\n",
    "        position_limit=500,\n",
    "        no_limit=1,\n",
    "        iteration=\"\"):\n",
    "        self.shares_limit = shares_limit\n",
    "        self.position_limit = position_limit\n",
    "        self.no_limit = no_limit\n",
    "        self.time_frame = time_frame\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        #self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.debt_amount = debt_amount\n",
    "        #self.buy_cost_pct = buy_cost_pct\n",
    "        #self.sell_cost_pct = sell_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.depth_list = depth_list\n",
    "        self.action_space = spaces.Box(low= 1, high= 100, shape=(self.stock_dim*2,))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.state_space,))\n",
    "        self.data = self.df.loc[self.stock_dim*self.time_frame : self.stock_dim*(self.time_frame + 1)-1,:]\n",
    "        self.terminal = False\n",
    "        self.make_plots = make_plots\n",
    "        self.print_verbosity = print_verbosity\n",
    "        #self.turbulence_threshold = turbulence_threshold\n",
    "        #self.risk_indicator_col = risk_indicator_col\n",
    "        self.initial = initial\n",
    "        self.previous_state = previous_state\n",
    "        self.model_name = model_name\n",
    "        self.mode = mode\n",
    "        self.iteration = iteration\n",
    "        # initalize state\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        # initialize reward\n",
    "        self.reward = 0\n",
    "        #self.turbulence = 0\n",
    "        #self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.episode = 0\n",
    "        # memorize all the total balance change\n",
    "        self.asset_memory = [self.initial_amount-self.debt_amount]\n",
    "        self.rewards_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "        # self.reset()\n",
    "        self._seed()\n",
    "          \n",
    "    def _sell_short_stock(self, index, action):\n",
    "\n",
    "        sell_num_shares = min(action, self.state[index + 2 + 5 * self.stock_dim])\n",
    "\n",
    "        sell_amount = (\n",
    "            self.state[index + 2 + 4*self.stock_dim]\n",
    "            * sell_num_shares\n",
    "            )\n",
    "        debt = (\n",
    "            self.state[index + 2 + 2*self.stock_dim]\n",
    "            * sell_num_shares\n",
    "            )\n",
    "        # update balance\n",
    "        self.state[0] += sell_amount\n",
    "        self.state[1] += debt\n",
    "        self.state[index + 2+self.stock_dim] += sell_num_shares    \n",
    "        self.trades += 1\n",
    "\n",
    "        return sell_num_shares\n",
    "            \n",
    "    def _buy_short_stock(self, index, action):\n",
    "        \n",
    "        if self.state[2+index+self.stock_dim] <= 0:\n",
    "            return 0\n",
    "            \n",
    "        else:\n",
    "            available_amount = (self.state[0] // self.state[index + 2 + self.stock_dim*2])\n",
    "            # print('available_amount:{}'.format(available_amount))\n",
    "\n",
    "            # update balance\n",
    "            buy_num_shares = min(action,available_amount, self.state[index+2+self.stock_dim],self.state[index + 2 + 3*self.stock_dim])\n",
    "\n",
    "            buy_amount = (\n",
    "                  self.state[index + 2 + self.stock_dim*2] * buy_num_shares \n",
    "                )\n",
    "            \n",
    "            self.state[0] -= buy_amount\n",
    "            self.state[1] -= buy_amount\n",
    "            self.state[index + 2+self.stock_dim] -= buy_num_shares\n",
    "            self.trades += 1\n",
    "\n",
    "            return buy_num_shares\n",
    "            \n",
    "    def _sell_stock(self, index, action):\n",
    "\n",
    "            if self.state[2+index] <= 0:\n",
    "              return 0\n",
    "            \n",
    "            else:\n",
    "              sell_num_shares = min(action,self.state[2+index], self.state[index + 2 + 5 * self.stock_dim])\n",
    "\n",
    "            sell_amount = (\n",
    "                  self.state[index + 2 + 4*self.stock_dim]\n",
    "                  * sell_num_shares\n",
    "                )\n",
    "            # update balance\n",
    "            self.state[0] += sell_amount\n",
    "            self.state[index + 2] -= sell_num_shares    \n",
    "            self.trades += 1\n",
    "\n",
    "            return sell_num_shares\n",
    "            \n",
    "    def _buy_stock(self, index, action):\n",
    "\n",
    "            available_amount = (self.state[0] // self.state[index + 2 + self.stock_dim*2])\n",
    "            # print('available_amount:{}'.format(available_amount))\n",
    "\n",
    "            # update balance\n",
    "            buy_num_shares = min(action,available_amount, self.state[index + 2 + 3*self.stock_dim])\n",
    "\n",
    "            buy_amount = (\n",
    "                  self.state[index + 2 + self.stock_dim*2] * buy_num_shares \n",
    "                )\n",
    "            \n",
    "            self.state[0] -= buy_amount\n",
    "            self.state[index + 2] += buy_num_shares\n",
    "            self.trades += 1\n",
    "\n",
    "            return buy_num_shares\n",
    "\n",
    "\n",
    "\n",
    "    def _make_plot(self):\n",
    "        plt.plot(self.asset_memory, \"r\")\n",
    "        plt.savefig(\"results/account_value_trade_{}.png\".format(self.episode))\n",
    "        plt.close()\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.terminal = self.time_frame >= (len(self.df.date.unique())-1)\n",
    "        self.debt_amount = sum(\n",
    "            np.array(self.state[(self.stock_dim + 2):(self.stock_dim*2 + 2)])\n",
    "            * np.array(self.state[(self.stock_dim * 2 + 2) : (self.stock_dim * 3 + 2)]))\n",
    "        self.state[1] = self.debt_amount\n",
    "\n",
    "        if self.terminal:\n",
    "            # print(len(self.state))\n",
    "            # print(len(self.state[1 : (self.stock_dim + 1)]))\n",
    "            # print(len(self.state[(self.stock_dim * 3 + 1) : (self.stock_dim * 4 + 1)]))\n",
    "            # print(f\"Episode: {self.episode}\")\n",
    "            if self.make_plots:\n",
    "                self._make_plot()\n",
    "            end_total_asset = self.state[0] - self.state[1] + sum(\n",
    "                np.array(self.state[2 : (self.stock_dim + 2)])\n",
    "                * np.array(self.state[(self.stock_dim * 4 + 2) : (self.stock_dim * 5 + 2)])\n",
    "            )\n",
    "            df_total_value = pd.DataFrame(self.asset_memory)\n",
    "            tot_reward = ( end_total_asset - self.initial_amount)\n",
    "            df_total_value.columns = [\"account_value\"]\n",
    "            df_total_value[\"date\"] = self.date_memory\n",
    "            df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(\n",
    "                1\n",
    "            )\n",
    "            if df_total_value[\"daily_return\"].std() != 0:\n",
    "                sharpe = (\n",
    "                    (252 ** 0.5)\n",
    "                    * df_total_value[\"daily_return\"].mean()\n",
    "                    / df_total_value[\"daily_return\"].std()\n",
    "                )\n",
    "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
    "            df_rewards.columns = [\"account_rewards\"]\n",
    "            df_rewards[\"date\"] = self.date_memory[:-1]\n",
    "            if self.episode % self.print_verbosity == 0:\n",
    "                print(f\"Moment: {self.time_frame}, episode: {self.episode}\")\n",
    "                print(f\"begin_total_asset: {self.asset_memory[0]:0.2f}\")\n",
    "                print(f\"end_total_asset: {end_total_asset:0.2f}\")\n",
    "                print(f\"total_reward: {tot_reward:0.2f}\")\n",
    "                #print(f\"total_cost: {self.cost:0.2f}\")\n",
    "                print(f\"total_trades: {self.trades}\")\n",
    "                if df_total_value[\"daily_return\"].std() != 0:\n",
    "                    print(f\"Sharpe: {sharpe:0.3f}\")\n",
    "                print(\"=================================\")\n",
    "\n",
    "            if (self.model_name != \"\") and (self.mode != \"\"):\n",
    "                df_actions = self.save_action_memory()\n",
    "                df_actions.to_csv(\n",
    "                    \"results/actions_{}_{}_{}.csv\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    )\n",
    "                )\n",
    "                df_total_value.to_csv(\n",
    "                    \"results/account_value_{}_{}_{}.csv\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    ),\n",
    "                    index=False,\n",
    "                )\n",
    "                df_rewards.to_csv(\n",
    "                    \"results/account_rewards_{}_{}_{}.csv\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    ),\n",
    "                    index=False,\n",
    "                )\n",
    "                plt.plot(self.asset_memory, \"r\")\n",
    "                plt.savefig(\n",
    "                    \"results/account_value_{}_{}_{}.png\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    ),\n",
    "                    index=False,\n",
    "                )\n",
    "                plt.close()\n",
    "\n",
    "            # Add outputs to logger interface\n",
    "            # logger.record(\"environment/portfolio_value\", end_total_asset)\n",
    "            # logger.record(\"environment/total_reward\", tot_reward)\n",
    "            # logger.record(\"environment/total_reward_pct\", (tot_reward / (end_total_asset - tot_reward)) * 100)\n",
    "            # logger.record(\"environment/total_cost\", self.cost)\n",
    "            # logger.record(\"environment/total_trades\", self.trades)\n",
    "            # print(self.state[0:self.stock_dim+1])\n",
    "            return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "        else:\n",
    "            limit_dict = {\n",
    "                'S_Stock' : 0,\n",
    "                'S_Pos' : 0,\n",
    "                'L_Stock' : 0,\n",
    "                'L_Pos' : 0}\n",
    "            limit_list = [limit_dict]*self.stock_dim\n",
    "            \n",
    "            #actions = actions * self.hmax  # actions initially is scaled between 0 to 1\n",
    "            actions = actions.astype(\n",
    "                int\n",
    "            )  # convert into integer because we can't by fraction of shares\n",
    "            # print(actions.shape)\n",
    "            # print(actions)\n",
    "            begin_total_asset = self.state[0] - self.state[1]+ sum(\n",
    "                np.array(self.state[2 : (self.stock_dim + 2)])\n",
    "                * np.array(self.state[(self.stock_dim * 4 + 2) : (self.stock_dim * 5 + 2)])\n",
    "            )\n",
    "            # print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
    "\n",
    "            \n",
    "            sell_index = np.intersect1d(np.where(actions[:self.stock_dim] > 60),np.where(actions[:self.stock_dim]<81)).tolist()\n",
    "            buy_index = np.intersect1d(np.where(actions[:self.stock_dim] > 0),np.where(actions[:self.stock_dim]<21)).tolist()\n",
    "            short_sell_id = np.intersect1d(np.where(actions[:self.stock_dim] > 80),np.where(actions[:self.stock_dim]<101)).tolist()\n",
    "            short_buy_id = np.intersect1d(np.where(actions[:self.stock_dim] > 20),np.where(actions[:self.stock_dim]<41)).tolist()\n",
    "            new_action = ['None']*self.stock_dim\n",
    "            # print(buy_index)\n",
    "            # print(sell_index)\n",
    "            \n",
    "            if not self.no_limit:\n",
    "                for i in range(self.stock_dim):\n",
    "                  if limit_list[i]['L_Stock'] >= 0:\n",
    "                    limit_list[i]['L_Pos'] +=1\n",
    "                  if limit_list[i]['S_Stock'] >= 0:\n",
    "                    limit_list[i]['S_Pos'] +=1\n",
    "                  if limit_list[i]['L_Stock']>=self.shares_limit:\n",
    "                    if i in buy_index:\n",
    "                      buy_index.remove(i)\n",
    "                  if limit_list[i]['S_Stock']>=self.shares_limit:\n",
    "                    if i in short_sell_id:\n",
    "                      short_sell_id.remove(i)\n",
    "                  if limit_list[i]['L_Pos']>=self.position_limit:\n",
    "                    val = self._sell_stock(i, self.state[i+2])\n",
    "                    new_action[i] = 'LS'+str(val)\n",
    "                    limit_list[i][\"L_Stock\"] -= val\n",
    "                    if limit_list[i][\"L_Stock\"] <= 0: \n",
    "                      limit_list[i][\"L_Pos\"] = 0\n",
    "                    if i in buy_index:\n",
    "                      buy_index.remove(i)\n",
    "                  if limit_list[i]['L_Pos']>=self.position_limit:\n",
    "                    val = self._buy_short_stock(i, self.state[i+2+self.stock_dim])\n",
    "                    new_action[i] = 'SB'+str(val)\n",
    "                    limit_list[i][\"S_Stock\"] -= val\n",
    "                    if limit_list[i][\"S_Stock\"] <= 0: \n",
    "                      limit_list[i][\"S_Pos\"] = 0\n",
    "                    if i in short_sell_id:\n",
    "                      short_sell_id.remove(i)\n",
    "\n",
    "            for index in sell_index:\n",
    "                # print(f\"Num shares before: {self.state[index+self.stock_dim+1]}\")\n",
    "                # print(f'take sell action before : {actions[index]}')\n",
    "                val = self._sell_stock(index, actions[self.stock_dim:][index])\n",
    "                new_action[index] = 'LS'+str(val)\n",
    "                limit_list[index][\"L_Stock\"] -= val\n",
    "                if limit_list[index][\"L_Stock\"] <= 0: \n",
    "                  limit_list[index][\"L_Pos\"] = 0\n",
    "                # print(f'take sell action after : {actions[index]}')\n",
    "                # print(f\"Num shares after: {self.state[index+self.stock_dim+1]}\")\n",
    "\n",
    "            for index in buy_index:\n",
    "                # print('take buy action: {}'.format(actions[index]))\n",
    "                val = self._buy_stock(index, actions[self.stock_dim:][index])                                                                                      \n",
    "                new_action[index] = 'LB'+str(val)\n",
    "                limit_list[index][\"L_Stock\"] += val\n",
    "            for index in short_sell_id:\n",
    "                            # print('take buy action: {}'.format(actions[index]))\n",
    "                val = self._sell_short_stock(index, actions[self.stock_dim:][index])\n",
    "                new_action[index] = 'SS'+str(val)\n",
    "                limit_list[index][\"S_Stock\"] += val\n",
    "            for index in short_buy_id:\n",
    "                            # print('take buy action: {}'.format(actions[index]))\n",
    "                val = self._buy_short_stock(index, actions[self.stock_dim:][index])\n",
    "                new_action[index] = 'SB'+str(val)\n",
    "                limit_list[index][\"S_Stock\"] -= val\n",
    "                if limit_list[index][\"S_Stock\"] <= 0: \n",
    "                  limit_list[index][\"S_Pos\"] = 0\n",
    "\n",
    "            self.actions_memory.append(new_action)\n",
    "\n",
    "            # state: s -> s+1\n",
    "            self.time_frame += 1\n",
    "            self.data = self.df.loc[self.stock_dim*self.time_frame : self.stock_dim*(self.time_frame + 1)-1,:]\n",
    "            self.state = self._update_state()\n",
    "\n",
    "            # print(len(self.state))\n",
    "            # print(len(self.state[1 : (self.stock_dim + 1)]))\n",
    "            # print(len(self.state[(self.stock_dim * 3 + 1) : (self.stock_dim * 4 + 1)]))\n",
    "\n",
    "            end_total_asset = self.state[0] - self.state[1]+ sum(\n",
    "                np.array(self.state[2 : (self.stock_dim + 2)])\n",
    "                * np.array(self.state[(self.stock_dim * 4 + 2) : (self.stock_dim * 5 + 2)])\n",
    "            )\n",
    "            self.asset_memory.append(end_total_asset)\n",
    "            self.date_memory.append(self._get_date())\n",
    "            self.reward = end_total_asset - begin_total_asset\n",
    "            self.rewards_memory.append(self.reward)\n",
    "            self.reward = (self.reward * self.reward_scaling)\n",
    "        # print(len(self.state))\n",
    "        # print(self.state[1:self.stock_dim+1])\n",
    "        # print(self.state[0])\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def reset(self):\n",
    "        # initiate state\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        if self.initial:\n",
    "            self.asset_memory = [self.initial_amount-self.debt_amount]\n",
    "        else:\n",
    "            if self.stock_dim>1:\n",
    "              previous_total_asset = self.previous_state[0] - self.state[1] + sum(\n",
    "               np.array(self.state[2 : (self.stock_dim + 2)])\n",
    "                * np.array(self.state[(self.stock_dim * 4+ 2) : (self.stock_dim * 5 + 2)])\n",
    "                )\n",
    "            else:\n",
    "              previous_total_asset = self.previous_state[0] -self.state[1]+ self.state[2]*self.state[5]\n",
    "            \n",
    "            self.asset_memory = [previous_total_asset]\n",
    "\n",
    "        self.time_frame = 0\n",
    "        self.data = self.df.loc[self.stock_dim*self.time_frame : self.stock_dim*(self.time_frame + 1)-1,:]\n",
    "        #self.turbulence = 0\n",
    "        #self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.terminal = False\n",
    "        # self.iteration=self.iteration\n",
    "        self.rewards_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "\n",
    "        self.episode += 1\n",
    "        return self.state\n",
    "\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        return self.state\n",
    "\n",
    "    def _initiate_state(self):\n",
    "        if self.initial:\n",
    "            # For Initial State\n",
    "            if len(self.df.tic.unique()) > 1:\n",
    "                # for multiple stock\n",
    "                state = (\n",
    "                    [self.initial_amount]\n",
    "                    + [self.debt_amount]\n",
    "                    #+ self.data.close.values.tolist()\n",
    "                    + [0] * self.stock_dim\n",
    "                    + [0] * self.stock_dim\n",
    "                    + sum(\n",
    "                        [\n",
    "                            self.data[depth].values.tolist()\n",
    "                            for depth in self.depth_list\n",
    "                        ],\n",
    "                        [],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # for single stock\n",
    "                state = (\n",
    "                    [self.initial_amount]\n",
    "                    + [self.debt_amount]\n",
    "                    #+ self.data.close.values.tolist()\n",
    "                    + [0] * self.stock_dim\n",
    "                    + [0] * self.stock_dim\n",
    "                    + sum([[self.data[depth]] for depth in self.depth_list], [])\n",
    "                )\n",
    "        else:\n",
    "            # Using Previous State\n",
    "            if len(self.df.tic.unique()) > 1:\n",
    "                # for multiple stock\n",
    "                state = (\n",
    "                    [self.previous_state[0]]\n",
    "                    +[self.previous_state[1]]\n",
    "                    #+ self.data.close.values.tolist()\n",
    "                    + self.previous_state[\n",
    "                        2 : (self.stock_dim*2 + 2)\n",
    "                    ]\n",
    "                    + sum(\n",
    "                        [\n",
    "                            self.data[depth].values.tolist()\n",
    "                            for depth in self.depth_list\n",
    "                        ],\n",
    "                        [],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # for single stock\n",
    "                state = (\n",
    "                    [self.previous_state[0]]\n",
    "                    + [self.previous_state[1]]\n",
    "                    + self.previous_state[\n",
    "                        2 : (self.stock_dim*2 + 2)\n",
    "                    ]\n",
    "                    + sum([[self.data[depth]] for depth in self.depth_list], [])\n",
    "                )\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _update_state(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            # for multiple stock\n",
    "            state = (\n",
    "                [self.state[0]]\n",
    "                +[self.state[1]]\n",
    "                + self.state[2 : (self.stock_dim*2 + 2)]\n",
    "                + sum(\n",
    "                    [\n",
    "                        self.data[depth].values.tolist()\n",
    "                        for depth in self.depth_list\n",
    "                    ],\n",
    "                    [],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # for single stock\n",
    "            state = (\n",
    "                [self.state[0]]\n",
    "                + [self.state[1]]\n",
    "                + self.state[2 : (self.stock_dim + 2)]\n",
    "                + sum([[self.data[depth]] for depth in self.depth_list], [])\n",
    "            )\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _get_date(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            date = self.data.date.unique()\n",
    "        else:\n",
    "            date = self.data.date\n",
    "        return date\n",
    " \n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        asset_list = self.asset_memory\n",
    "        # print(len(date_list))\n",
    "        # print(len(asset_list))\n",
    "        df_account_value = pd.DataFrame(\n",
    "            {\"date\": date_list, \"account_value\": asset_list}\n",
    "        )\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            # date and close price length must match actions length\n",
    "            date_list = self.date_memory[:-1]\n",
    "            df_date = pd.DataFrame(date_list)\n",
    "            df_date.columns = [\"date\"]\n",
    "\n",
    "            action_list = self.actions_memory\n",
    "            df_actions = pd.DataFrame(action_list)\n",
    "            df_actions.columns = self.data.tic.values\n",
    "            df_actions.index = df_date.date\n",
    "            # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        else:\n",
    "            date_list = self.date_memory[:-1]\n",
    "            action_list = self.actions_memory\n",
    "            df_actions = pd.DataFrame({\"date\": date_list, \"actions\": action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "      def get_self():\n",
    "          return deepcopy(self)\n",
    "      e = DummyVecEnv([get_self])\n",
    "      obs = e.reset()\n",
    "      return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aZYeJwzReazA"
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "split = 0.80\n",
    "split_date = data.date.unique()[:floor(split*data.date.unique().shape[0])]\n",
    "train = data[data.date<split_date[-1]]\n",
    "trade = data[data.date>split_date[-2]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIUUYJpgNeoL"
   },
   "source": [
    "##**Environment for Portfolio Allocation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "981i4t3jNVep",
    "outputId": "21a1e4f2-7996-478d-8de8-35e23f4d6964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 5, State Space: 112\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 2 + (len(columns)+2)*(stock_dimension)\n",
    "#state_space = 1 + 2*stock_dimension + len(tech_indicator_list)*stock_dimension\n",
    "#state_space = 1 + 2*(stock_dimension+2) + (len(tech_indicator_list)-2)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PoQilxkcNgcS"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"initial_amount\": 100000,\n",
    "    #\"buy_cost_pct\": 0.001,\n",
    "    #\"sell_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"depth_list\": columns, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"shares_limit\":1000,\n",
    "    \"position_limit\":1000,\n",
    "    \"no_limit\":0\n",
    "}\n",
    "e_train_gym = StockTradingEnv(df = train ,**env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSB0olPMNhqc",
    "outputId": "f43629d3-2b21-4b38-97b4-c4a3e2020158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "f-KAKzIVNjoo"
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOBMeQykNkow",
    "outputId": "25cb2abd-3712-45ab-ebcc-405c36e171f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_trade, _ = e_trade_gym.get_sb_env()\n",
    "print(type(env_trade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yw-y8Yf5NoH3"
   },
   "source": [
    "#**DRL Algorithms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kvlKwFOkcabE"
   },
   "outputs": [],
   "source": [
    "def DRL_prediction(model, environment):\n",
    "        test_env, test_obs = environment.get_sb_env()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "        test_env.reset()\n",
    "        for i in range(len(environment.df.date.unique())):\n",
    "            action, _states = model.predict(test_obs)\n",
    "            # account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "            # actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "            test_obs, rewards, dones, info = test_env.step(action)\n",
    "            if i == (len(environment.df.date.unique()) - 2):\n",
    "                account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        return account_memory[0], actions_memory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ay8ffH9tNlwI"
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "agent = DRLAgent(env = env_train)\n",
    "trade_agent = DRLAgent(env = env_trade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR6KgltjNuGk"
   },
   "source": [
    "##**A2C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAS0rLX_mtkm",
    "outputId": "23288eb0-d1c3-4ee3-9741-2ee13a67d8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 100, 'ent_coef': 0.02, 'learning_rate': 0.0007}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "A2C_PARAMS = {'n_steps': 100, 'ent_coef': 0.02, 'learning_rate': 0.0007}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tWcvHTRNxIa"
   },
   "source": [
    "###**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRNx-XICNscs",
    "outputId": "e8974cc8-2874-40b1-a41c-d256938067a6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 431      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.8    |\n",
      "|    explained_variance | -9.44    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -1.13    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.0211   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 864      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.6    |\n",
      "|    explained_variance | -0.592   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.19     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 0.00742  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 1307     |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -10.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.506    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.00283  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 1744     |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -17      |\n",
      "|    explained_variance | -8.04    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.088    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.32     |\n",
      "|    value_loss         | 0.000185 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 2181     |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -17.6    |\n",
      "|    explained_variance | -108     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.123    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.41     |\n",
      "|    value_loss         | 0.000107 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 2621     |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -18.3    |\n",
      "|    explained_variance | -0.681   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.809    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 0.00352  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 3059     |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -18.9    |\n",
      "|    explained_variance | -0.495   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.992    |\n",
      "|    reward             | 6.9e-05  |\n",
      "|    std                | 1.61     |\n",
      "|    value_loss         | 0.00371  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 3500     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -19.4    |\n",
      "|    explained_variance | -9.47    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.161   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.69     |\n",
      "|    value_loss         | 0.000513 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 3936     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -20.2    |\n",
      "|    explained_variance | -72      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.0388   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.82     |\n",
      "|    value_loss         | 0.000114 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 4361     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -20.9    |\n",
      "|    explained_variance | 0.474    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.226    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.95     |\n",
      "|    value_loss         | 0.00015  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 4783     |\n",
      "|    total_timesteps    | 110000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -21.6    |\n",
      "|    explained_variance | -22.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.034   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.09     |\n",
      "|    value_loss         | 1.92e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 5205     |\n",
      "|    total_timesteps    | 120000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -22.2    |\n",
      "|    explained_variance | -14      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.0432   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.24     |\n",
      "|    value_loss         | 2.69e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 5627     |\n",
      "|    total_timesteps    | 130000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -22.9    |\n",
      "|    explained_variance | -4.23    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.0118   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.4      |\n",
      "|    value_loss         | 4.61e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 6048      |\n",
      "|    total_timesteps    | 140000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.6     |\n",
      "|    explained_variance | -3.38     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -0.625    |\n",
      "|    reward             | -0.000213 |\n",
      "|    std                | 2.57      |\n",
      "|    value_loss         | 0.00104   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 6469      |\n",
      "|    total_timesteps    | 150000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -24.3     |\n",
      "|    explained_variance | -5.65e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 0.366     |\n",
      "|    reward             | -0.000207 |\n",
      "|    std                | 2.76      |\n",
      "|    value_loss         | 0.043     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 6892     |\n",
      "|    total_timesteps    | 160000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -24.9    |\n",
      "|    explained_variance | -2.3     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.151   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.93     |\n",
      "|    value_loss         | 5.1e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 7315     |\n",
      "|    total_timesteps    | 170000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -25.6    |\n",
      "|    explained_variance | -97      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.17     |\n",
      "|    reward             | 0.001173 |\n",
      "|    std                | 3.14     |\n",
      "|    value_loss         | 9.13e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 7737     |\n",
      "|    total_timesteps    | 180000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -26.3    |\n",
      "|    explained_variance | -1.05    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.0216  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.36     |\n",
      "|    value_loss         | 2.62e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 8159     |\n",
      "|    total_timesteps    | 190000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27      |\n",
      "|    explained_variance | -0.13    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.0741   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.61     |\n",
      "|    value_loss         | 9.41e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 8581     |\n",
      "|    total_timesteps    | 200000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.7    |\n",
      "|    explained_variance | -1.38    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.0484  |\n",
      "|    reward             | -6.9e-05 |\n",
      "|    std                | 3.86     |\n",
      "|    value_loss         | 4.33e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 9003     |\n",
      "|    total_timesteps    | 210000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.4    |\n",
      "|    explained_variance | -0.568   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.0142  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.14     |\n",
      "|    value_loss         | 8.14e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 9423     |\n",
      "|    total_timesteps    | 220000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.1    |\n",
      "|    explained_variance | -0.223   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.0174   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.44     |\n",
      "|    value_loss         | 8.34e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 9844     |\n",
      "|    total_timesteps    | 230000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.7    |\n",
      "|    explained_variance | -9.43    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.719    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.74     |\n",
      "|    value_loss         | 0.000936 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 10264    |\n",
      "|    total_timesteps    | 240000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.4    |\n",
      "|    explained_variance | -0.184   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.187   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.08     |\n",
      "|    value_loss         | 4.77e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 10684    |\n",
      "|    total_timesteps    | 250000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.1    |\n",
      "|    explained_variance | -0.611   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.187   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.45     |\n",
      "|    value_loss         | 4.71e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 11104    |\n",
      "|    total_timesteps    | 260000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.8    |\n",
      "|    explained_variance | -4.49    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.0524   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.84     |\n",
      "|    value_loss         | 8.2e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 11524    |\n",
      "|    total_timesteps    | 270000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.5    |\n",
      "|    explained_variance | 0.0672   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.0205  |\n",
      "|    reward             | 4.8e-05  |\n",
      "|    std                | 6.26     |\n",
      "|    value_loss         | 2.93e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 11938    |\n",
      "|    total_timesteps    | 280000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.2    |\n",
      "|    explained_variance | -0.256   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.0351  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 6.72     |\n",
      "|    value_loss         | 5.2e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 12351    |\n",
      "|    total_timesteps    | 290000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.531   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 7.2      |\n",
      "|    value_loss         | 0.000292 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 12764     |\n",
      "|    total_timesteps    | 300000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -34.6     |\n",
      "|    explained_variance | -4.36e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 1.66      |\n",
      "|    reward             | 0.001133  |\n",
      "|    std                | 7.72      |\n",
      "|    value_loss         | 0.00765   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 13176    |\n",
      "|    total_timesteps    | 310000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.3    |\n",
      "|    explained_variance | 0.0127   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.0683  |\n",
      "|    reward             | 0.000189 |\n",
      "|    std                | 8.25     |\n",
      "|    value_loss         | 5.03e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 13590    |\n",
      "|    total_timesteps    | 320000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36      |\n",
      "|    explained_variance | -1.22    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.548   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 8.85     |\n",
      "|    value_loss         | 0.000318 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 14003     |\n",
      "|    total_timesteps    | 330000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -36.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -0.0143   |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 9.49      |\n",
      "|    value_loss         | 2.13e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 14416    |\n",
      "|    total_timesteps    | 340000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.4    |\n",
      "|    explained_variance | 0.0069   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.0298   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 10.2     |\n",
      "|    value_loss         | 1.57e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 14828    |\n",
      "|    total_timesteps    | 350000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.1    |\n",
      "|    explained_variance | -0.205   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.103   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 10.9     |\n",
      "|    value_loss         | 7.93e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 15241    |\n",
      "|    total_timesteps    | 360000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.8    |\n",
      "|    explained_variance | -0.935   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.383   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 11.7     |\n",
      "|    value_loss         | 0.000124 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 15654    |\n",
      "|    total_timesteps    | 370000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.5    |\n",
      "|    explained_variance | -0.0877  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.113    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 12.5     |\n",
      "|    value_loss         | 1.08e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 16070    |\n",
      "|    total_timesteps    | 380000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.1    |\n",
      "|    explained_variance | -8.7     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.0656   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 13.4     |\n",
      "|    value_loss         | 2.16e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 16491    |\n",
      "|    total_timesteps    | 390000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.0116  |\n",
      "|    reward             | 0.000558 |\n",
      "|    std                | 14.4     |\n",
      "|    value_loss         | 3.47e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 16911    |\n",
      "|    total_timesteps    | 400000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.5    |\n",
      "|    explained_variance | 0.282    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.0494  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 15.4     |\n",
      "|    value_loss         | 2.02e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 17332    |\n",
      "|    total_timesteps    | 410000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | -0.0736  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.27    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 16.5     |\n",
      "|    value_loss         | 4.88e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 17752    |\n",
      "|    total_timesteps    | 420000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | -189     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -0.447   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 17.7     |\n",
      "|    value_loss         | 0.000127 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 18173    |\n",
      "|    total_timesteps    | 430000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -0.716   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.565    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 19       |\n",
      "|    value_loss         | 0.000218 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 18593    |\n",
      "|    total_timesteps    | 440000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.185   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 20.4     |\n",
      "|    value_loss         | 2.27e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 19014    |\n",
      "|    total_timesteps    | 450000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45      |\n",
      "|    explained_variance | -1.63    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -1.21    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 21.8     |\n",
      "|    value_loss         | 0.00216  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 19435    |\n",
      "|    total_timesteps    | 460000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.7    |\n",
      "|    explained_variance | 0.338    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.0975   |\n",
      "|    reward             | 0.000832 |\n",
      "|    std                | 23.4     |\n",
      "|    value_loss         | 6.4e-06  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 19856    |\n",
      "|    total_timesteps    | 470000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.4    |\n",
      "|    explained_variance | -0.159   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 0.0856   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 25.1     |\n",
      "|    value_loss         | 5.68e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 20277    |\n",
      "|    total_timesteps    | 480000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | -6.63    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.253    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 26.9     |\n",
      "|    value_loss         | 3.47e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 20698    |\n",
      "|    total_timesteps    | 490000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.8    |\n",
      "|    explained_variance | -0.542   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.859    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 28.7     |\n",
      "|    value_loss         | 0.000898 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 21118     |\n",
      "|    total_timesteps    | 500000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.4     |\n",
      "|    explained_variance | -14.3     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 0.466     |\n",
      "|    reward             | -0.000197 |\n",
      "|    std                | 30.6      |\n",
      "|    value_loss         | 0.000185  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 21539    |\n",
      "|    total_timesteps    | 510000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.1    |\n",
      "|    explained_variance | -0.43    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 2.09     |\n",
      "|    reward             | 0.000553 |\n",
      "|    std                | 32.8     |\n",
      "|    value_loss         | 0.00257  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 21960    |\n",
      "|    total_timesteps    | 520000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.8    |\n",
      "|    explained_variance | 0.108    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.358    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 35.2     |\n",
      "|    value_loss         | 0.000103 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 22381     |\n",
      "|    total_timesteps    | 530000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.5     |\n",
      "|    explained_variance | 0.0149    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 1.05      |\n",
      "|    reward             | -0.000758 |\n",
      "|    std                | 37.6      |\n",
      "|    value_loss         | 0.000468  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 22813     |\n",
      "|    total_timesteps    | 540000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 1.48      |\n",
      "|    reward             | -0.000544 |\n",
      "|    std                | 40.3      |\n",
      "|    value_loss         | 0.00111   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 23249    |\n",
      "|    total_timesteps    | 550000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -3.89    |\n",
      "|    reward             | 0.001332 |\n",
      "|    std                | 43       |\n",
      "|    value_loss         | 0.00889  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 23685    |\n",
      "|    total_timesteps    | 560000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 2.34     |\n",
      "|    reward             | -7e-06   |\n",
      "|    std                | 45.8     |\n",
      "|    value_loss         | 0.00343  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 24121    |\n",
      "|    total_timesteps    | 570000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -5.52    |\n",
      "|    reward             | -0.00052 |\n",
      "|    std                | 48.2     |\n",
      "|    value_loss         | 0.0188   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 24557    |\n",
      "|    total_timesteps    | 580000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 26.7     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 50.5     |\n",
      "|    value_loss         | 0.375    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 24988     |\n",
      "|    total_timesteps    | 590000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -53.8     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 14.8      |\n",
      "|    reward             | -0.000806 |\n",
      "|    std                | 52.4      |\n",
      "|    value_loss         | 0.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 25423     |\n",
      "|    total_timesteps    | 600000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.1     |\n",
      "|    explained_variance | 0.00873   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -2.77     |\n",
      "|    reward             | -0.008012 |\n",
      "|    std                | 54.2      |\n",
      "|    value_loss         | 0.00429   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 25857     |\n",
      "|    total_timesteps    | 610000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -1.15     |\n",
      "|    reward             | -0.000708 |\n",
      "|    std                | 57        |\n",
      "|    value_loss         | 0.0234    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 26293     |\n",
      "|    total_timesteps    | 620000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 8.09      |\n",
      "|    reward             | -0.000557 |\n",
      "|    std                | 59.4      |\n",
      "|    value_loss         | 0.0788    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 26728     |\n",
      "|    total_timesteps    | 630000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -3.3      |\n",
      "|    reward             | -0.000812 |\n",
      "|    std                | 61.3      |\n",
      "|    value_loss         | 0.0922    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 27164    |\n",
      "|    total_timesteps    | 640000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -50.8    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 62.8     |\n",
      "|    value_loss         | 1.05     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 27600     |\n",
      "|    total_timesteps    | 650000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 123       |\n",
      "|    reward             | -0.000641 |\n",
      "|    std                | 63.8      |\n",
      "|    value_loss         | 5.96      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 6600           |\n",
      "|    time_elapsed       | 28035          |\n",
      "|    total_timesteps    | 660000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -55.9          |\n",
      "|    explained_variance | -2.38e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6599           |\n",
      "|    policy_loss        | -65.5          |\n",
      "|    reward             | -1.0000006e-06 |\n",
      "|    std                | 65             |\n",
      "|    value_loss         | 2              |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 6700           |\n",
      "|    time_elapsed       | 28471          |\n",
      "|    total_timesteps    | 670000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -56            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6699           |\n",
      "|    policy_loss        | -99.8          |\n",
      "|    reward             | -3.5999998e-05 |\n",
      "|    std                | 65.6           |\n",
      "|    value_loss         | 3.83           |\n",
      "------------------------------------------\n",
      "Moment: 74871, episode: 10\n",
      "begin_total_asset: -42444138.72\n",
      "end_total_asset: -129410.43\n",
      "total_reward: -229410.43\n",
      "total_trades: 340003\n",
      "Sharpe: -0.057\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 28906     |\n",
      "|    total_timesteps    | 680000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -1.76     |\n",
      "|    reward             | -0.011735 |\n",
      "|    std                | 67.3      |\n",
      "|    value_loss         | 0.0568    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 29342     |\n",
      "|    total_timesteps    | 690000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -17.9     |\n",
      "|    reward             | -0.001397 |\n",
      "|    std                | 68.9      |\n",
      "|    value_loss         | 0.176     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 29779     |\n",
      "|    total_timesteps    | 700000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 14.2      |\n",
      "|    reward             | -0.132284 |\n",
      "|    std                | 70.3      |\n",
      "|    value_loss         | 0.227     |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 7100          |\n",
      "|    time_elapsed       | 30215         |\n",
      "|    total_timesteps    | 710000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -56.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7099          |\n",
      "|    policy_loss        | -29.7         |\n",
      "|    reward             | -6.999999e-06 |\n",
      "|    std                | 71.4          |\n",
      "|    value_loss         | 0.48          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 30651    |\n",
      "|    total_timesteps    | 720000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 10.4     |\n",
      "|    reward             | -0.00036 |\n",
      "|    std                | 72.3     |\n",
      "|    value_loss         | 0.0689   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 31087    |\n",
      "|    total_timesteps    | 730000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | -65.7    |\n",
      "|    reward             | -9.5e-05 |\n",
      "|    std                | 72.9     |\n",
      "|    value_loss         | 2.25     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 31522    |\n",
      "|    total_timesteps    | 740000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | -68.2    |\n",
      "|    reward             | -7.6e-05 |\n",
      "|    std                | 73.6     |\n",
      "|    value_loss         | 1.84     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 31955    |\n",
      "|    total_timesteps    | 750000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -2.49    |\n",
      "|    reward             | -9e-06   |\n",
      "|    std                | 74.4     |\n",
      "|    value_loss         | 0.00323  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 32392     |\n",
      "|    total_timesteps    | 760000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 38.6      |\n",
      "|    reward             | -8.6e-05  |\n",
      "|    std                | 76.3      |\n",
      "|    value_loss         | 0.487     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 32828     |\n",
      "|    total_timesteps    | 770000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.7     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 21.4      |\n",
      "|    reward             | -0.000531 |\n",
      "|    std                | 77.6      |\n",
      "|    value_loss         | 0.336     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 33264    |\n",
      "|    total_timesteps    | 780000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.8    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -17.6    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 78.4     |\n",
      "|    value_loss         | 0.379    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 33700    |\n",
      "|    total_timesteps    | 790000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -153     |\n",
      "|    reward             | 0.137833 |\n",
      "|    std                | 79.2     |\n",
      "|    value_loss         | 7.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 34136     |\n",
      "|    total_timesteps    | 800000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 75.5      |\n",
      "|    reward             | -0.001089 |\n",
      "|    std                | 80        |\n",
      "|    value_loss         | 3.63      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 34572    |\n",
      "|    total_timesteps    | 810000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -14.7    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 80.8     |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 35008     |\n",
      "|    total_timesteps    | 820000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -341      |\n",
      "|    reward             | -0.002937 |\n",
      "|    std                | 81.2      |\n",
      "|    value_loss         | 49.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 35443     |\n",
      "|    total_timesteps    | 830000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -9.76     |\n",
      "|    reward             | -0.001556 |\n",
      "|    std                | 83.1      |\n",
      "|    value_loss         | 0.0568    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 35878     |\n",
      "|    total_timesteps    | 840000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -32.6     |\n",
      "|    reward             | -0.000169 |\n",
      "|    std                | 84.6      |\n",
      "|    value_loss         | 0.584     |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 8500           |\n",
      "|    time_elapsed       | 36314          |\n",
      "|    total_timesteps    | 850000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -58.7          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8499           |\n",
      "|    policy_loss        | -26            |\n",
      "|    reward             | -7.7000004e-05 |\n",
      "|    std                | 85.7           |\n",
      "|    value_loss         | 0.611          |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 36750     |\n",
      "|    total_timesteps    | 860000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -177      |\n",
      "|    reward             | -0.000145 |\n",
      "|    std                | 86.6      |\n",
      "|    value_loss         | 13.2      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 8700          |\n",
      "|    time_elapsed       | 37185         |\n",
      "|    total_timesteps    | 870000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -58.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8699          |\n",
      "|    policy_loss        | 145           |\n",
      "|    reward             | -9.999991e-07 |\n",
      "|    std                | 87.2          |\n",
      "|    value_loss         | 10.6          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 37619    |\n",
      "|    total_timesteps    | 880000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -322     |\n",
      "|    reward             | -2.8e-05 |\n",
      "|    std                | 87.6     |\n",
      "|    value_loss         | 41.5     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 8900           |\n",
      "|    time_elapsed       | 38052          |\n",
      "|    total_timesteps    | 890000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -59            |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8899           |\n",
      "|    policy_loss        | -28.2          |\n",
      "|    reward             | -0.00015899999 |\n",
      "|    std                | 88.3           |\n",
      "|    value_loss         | 0.897          |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 38480     |\n",
      "|    total_timesteps    | 900000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -0.974    |\n",
      "|    reward             | -0.000275 |\n",
      "|    std                | 89        |\n",
      "|    value_loss         | 0.00336   |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 9100           |\n",
      "|    time_elapsed       | 38894          |\n",
      "|    total_timesteps    | 910000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -59.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 9099           |\n",
      "|    policy_loss        | 2.92           |\n",
      "|    reward             | -1.9999995e-06 |\n",
      "|    std                | 90.8           |\n",
      "|    value_loss         | 0.0318         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 9200           |\n",
      "|    time_elapsed       | 39306          |\n",
      "|    total_timesteps    | 920000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -59.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 9199           |\n",
      "|    policy_loss        | 78             |\n",
      "|    reward             | -2.1000002e-05 |\n",
      "|    std                | 91.8           |\n",
      "|    value_loss         | 2.6            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 39720     |\n",
      "|    total_timesteps    | 930000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -56       |\n",
      "|    reward             | -0.000202 |\n",
      "|    std                | 93        |\n",
      "|    value_loss         | 21.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 40132     |\n",
      "|    total_timesteps    | 940000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 115       |\n",
      "|    reward             | -0.310343 |\n",
      "|    std                | 93.5      |\n",
      "|    value_loss         | 4.48      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 40545     |\n",
      "|    total_timesteps    | 950000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -0.345    |\n",
      "|    reward             | -0.000559 |\n",
      "|    std                | 93.9      |\n",
      "|    value_loss         | 0.433     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 40959     |\n",
      "|    total_timesteps    | 960000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 118       |\n",
      "|    reward             | -0.000116 |\n",
      "|    std                | 94.6      |\n",
      "|    value_loss         | 8.37      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 9700          |\n",
      "|    time_elapsed       | 41371         |\n",
      "|    total_timesteps    | 970000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -59.7         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9699          |\n",
      "|    policy_loss        | -160          |\n",
      "|    reward             | -2.000004e-06 |\n",
      "|    std                | 94.9          |\n",
      "|    value_loss         | 20.4          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 41784    |\n",
      "|    total_timesteps    | 980000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 46.6     |\n",
      "|    reward             | 0.026155 |\n",
      "|    std                | 96.5     |\n",
      "|    value_loss         | 0.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 42199    |\n",
      "|    total_timesteps    | 990000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 35.5     |\n",
      "|    reward             | 0.005284 |\n",
      "|    std                | 97.8     |\n",
      "|    value_loss         | 0.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 42613    |\n",
      "|    total_timesteps    | 1000000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -42      |\n",
      "|    reward             | -0.00075 |\n",
      "|    std                | 98.6     |\n",
      "|    value_loss         | 0.809    |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 10100          |\n",
      "|    time_elapsed       | 43027          |\n",
      "|    total_timesteps    | 1010000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -60.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 10099          |\n",
      "|    policy_loss        | 29.9           |\n",
      "|    reward             | -1.5999996e-05 |\n",
      "|    std                | 99.4           |\n",
      "|    value_loss         | 0.479          |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 43442     |\n",
      "|    total_timesteps    | 1020000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -533      |\n",
      "|    reward             | -0.002462 |\n",
      "|    std                | 99.9      |\n",
      "|    value_loss         | 99.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 43856     |\n",
      "|    total_timesteps    | 1030000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | 40.2      |\n",
      "|    reward             | -0.000538 |\n",
      "|    std                | 100       |\n",
      "|    value_loss         | 2.43      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 44270     |\n",
      "|    total_timesteps    | 1040000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.3     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 181       |\n",
      "|    reward             | -0.000128 |\n",
      "|    std                | 101       |\n",
      "|    value_loss         | 10.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 44683     |\n",
      "|    total_timesteps    | 1050000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | 8.02      |\n",
      "|    reward             | -0.023953 |\n",
      "|    std                | 101       |\n",
      "|    value_loss         | 0.0503    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 45097     |\n",
      "|    total_timesteps    | 1060000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | 67.5      |\n",
      "|    reward             | -0.048512 |\n",
      "|    std                | 103       |\n",
      "|    value_loss         | 1.63      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 10700         |\n",
      "|    time_elapsed       | 45511         |\n",
      "|    total_timesteps    | 1070000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -60.6         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10699         |\n",
      "|    policy_loss        | -47.2         |\n",
      "|    reward             | -1.000002e-06 |\n",
      "|    std                | 104           |\n",
      "|    value_loss         | 1.23          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10800     |\n",
      "|    time_elapsed       | 45927     |\n",
      "|    total_timesteps    | 1080000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10799     |\n",
      "|    policy_loss        | 29.7      |\n",
      "|    reward             | -0.000431 |\n",
      "|    std                | 105       |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 46341     |\n",
      "|    total_timesteps    | 1090000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -54.5     |\n",
      "|    reward             | -0.951719 |\n",
      "|    std                | 106       |\n",
      "|    value_loss         | 2.73      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 46754     |\n",
      "|    total_timesteps    | 1100000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | 192       |\n",
      "|    reward             | -8e-05    |\n",
      "|    std                | 107       |\n",
      "|    value_loss         | 11.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 47192     |\n",
      "|    total_timesteps    | 1110000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | 34        |\n",
      "|    reward             | -0.923283 |\n",
      "|    std                | 107       |\n",
      "|    value_loss         | 2.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 47627     |\n",
      "|    total_timesteps    | 1120000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | 55.8      |\n",
      "|    reward             | -0.720398 |\n",
      "|    std                | 107       |\n",
      "|    value_loss         | 2.81      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 48062     |\n",
      "|    total_timesteps    | 1130000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -1.44     |\n",
      "|    reward             | -0.002082 |\n",
      "|    std                | 109       |\n",
      "|    value_loss         | 0.309     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 48497     |\n",
      "|    total_timesteps    | 1140000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -30       |\n",
      "|    reward             | -0.000209 |\n",
      "|    std                | 110       |\n",
      "|    value_loss         | 0.738     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 48920     |\n",
      "|    total_timesteps    | 1150000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | 6.57      |\n",
      "|    reward             | -0.000494 |\n",
      "|    std                | 111       |\n",
      "|    value_loss         | 0.214     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 49342     |\n",
      "|    total_timesteps    | 1160000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.3     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | -501      |\n",
      "|    reward             | -0.000233 |\n",
      "|    std                | 111       |\n",
      "|    value_loss         | 122       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 49765     |\n",
      "|    total_timesteps    | 1170000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.3     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | 97.4      |\n",
      "|    reward             | -0.000222 |\n",
      "|    std                | 112       |\n",
      "|    value_loss         | 6.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 50187     |\n",
      "|    total_timesteps    | 1180000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -7.38     |\n",
      "|    reward             | -0.000942 |\n",
      "|    std                | 112       |\n",
      "|    value_loss         | 2.92      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 50609    |\n",
      "|    total_timesteps    | 1190000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | -142     |\n",
      "|    reward             | -9.9e-05 |\n",
      "|    std                | 112      |\n",
      "|    value_loss         | 10.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 51031     |\n",
      "|    total_timesteps    | 1200000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -25.5     |\n",
      "|    reward             | -0.000205 |\n",
      "|    std                | 113       |\n",
      "|    value_loss         | 0.186     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 51454    |\n",
      "|    total_timesteps    | 1210000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -93.5    |\n",
      "|    reward             | 0.091263 |\n",
      "|    std                | 114      |\n",
      "|    value_loss         | 2.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 51879    |\n",
      "|    total_timesteps    | 1220000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 14.6     |\n",
      "|    reward             | -0.10512 |\n",
      "|    std                | 115      |\n",
      "|    value_loss         | 3.33     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 52303     |\n",
      "|    total_timesteps    | 1230000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -52.2     |\n",
      "|    reward             | -0.000308 |\n",
      "|    std                | 116       |\n",
      "|    value_loss         | 0.998     |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 12400          |\n",
      "|    time_elapsed       | 52726          |\n",
      "|    total_timesteps    | 1240000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -61.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 12399          |\n",
      "|    policy_loss        | -224           |\n",
      "|    reward             | -0.00010099999 |\n",
      "|    std                | 117            |\n",
      "|    value_loss         | 18.5           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 53150     |\n",
      "|    total_timesteps    | 1250000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | -5.81     |\n",
      "|    reward             | -7.8e-05  |\n",
      "|    std                | 117       |\n",
      "|    value_loss         | 6.74      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 53573     |\n",
      "|    total_timesteps    | 1260000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | 246       |\n",
      "|    reward             | -0.774127 |\n",
      "|    std                | 117       |\n",
      "|    value_loss         | 20.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 53996     |\n",
      "|    total_timesteps    | 1270000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | 396       |\n",
      "|    reward             | -0.001346 |\n",
      "|    std                | 117       |\n",
      "|    value_loss         | 49.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 54419     |\n",
      "|    total_timesteps    | 1280000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -14.8     |\n",
      "|    reward             | -0.001501 |\n",
      "|    std                | 119       |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 54842     |\n",
      "|    total_timesteps    | 1290000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | 117       |\n",
      "|    reward             | -0.000414 |\n",
      "|    std                | 120       |\n",
      "|    value_loss         | 5.09      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 13000    |\n",
      "|    time_elapsed       | 55266    |\n",
      "|    total_timesteps    | 1300000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12999    |\n",
      "|    policy_loss        | -107     |\n",
      "|    reward             | -2.2e-05 |\n",
      "|    std                | 121      |\n",
      "|    value_loss         | 3.35     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 55688     |\n",
      "|    total_timesteps    | 1310000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | 56.4      |\n",
      "|    reward             | -0.000111 |\n",
      "|    std                | 121       |\n",
      "|    value_loss         | 18.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 56103     |\n",
      "|    total_timesteps    | 1320000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | 202       |\n",
      "|    reward             | -0.000538 |\n",
      "|    std                | 122       |\n",
      "|    value_loss         | 22.1      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 13300         |\n",
      "|    time_elapsed       | 56520         |\n",
      "|    total_timesteps    | 1330000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -62.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13299         |\n",
      "|    policy_loss        | -504          |\n",
      "|    reward             | -9.999991e-07 |\n",
      "|    std                | 123           |\n",
      "|    value_loss         | 94.1          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 56934    |\n",
      "|    total_timesteps    | 1340000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -211     |\n",
      "|    reward             | 6.916695 |\n",
      "|    std                | 123      |\n",
      "|    value_loss         | 36.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 57349     |\n",
      "|    total_timesteps    | 1350000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 23.4      |\n",
      "|    reward             | -0.000396 |\n",
      "|    std                | 124       |\n",
      "|    value_loss         | 0.161     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 13600    |\n",
      "|    time_elapsed       | 57764    |\n",
      "|    total_timesteps    | 1360000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13599    |\n",
      "|    policy_loss        | -11.9    |\n",
      "|    reward             | -9.4e-05 |\n",
      "|    std                | 126      |\n",
      "|    value_loss         | 0.303    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 58179     |\n",
      "|    total_timesteps    | 1370000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -238      |\n",
      "|    reward             | -0.000155 |\n",
      "|    std                | 128       |\n",
      "|    value_loss         | 18.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 58595     |\n",
      "|    total_timesteps    | 1380000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 140       |\n",
      "|    reward             | -0.000543 |\n",
      "|    std                | 128       |\n",
      "|    value_loss         | 6.19      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 59010     |\n",
      "|    total_timesteps    | 1390000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 127       |\n",
      "|    reward             | -2.321075 |\n",
      "|    std                | 129       |\n",
      "|    value_loss         | 6.13      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 14000          |\n",
      "|    time_elapsed       | 59425          |\n",
      "|    total_timesteps    | 1400000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -62.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 13999          |\n",
      "|    policy_loss        | 226            |\n",
      "|    reward             | -0.00037000002 |\n",
      "|    std                | 129            |\n",
      "|    value_loss         | 16             |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 59840    |\n",
      "|    total_timesteps    | 1410000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -295     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 129      |\n",
      "|    value_loss         | 37.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 60253    |\n",
      "|    total_timesteps    | 1420000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | -47.7    |\n",
      "|    reward             | 0.364109 |\n",
      "|    std                | 130      |\n",
      "|    value_loss         | 14.3     |\n",
      "------------------------------------\n",
      "Moment: 74871, episode: 20\n",
      "begin_total_asset: -620128229.84\n",
      "end_total_asset: -676122.14\n",
      "total_reward: -776122.14\n",
      "total_trades: 352511\n",
      "Sharpe: 0.015\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 14300          |\n",
      "|    time_elapsed       | 60668          |\n",
      "|    total_timesteps    | 1430000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -62.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 14299          |\n",
      "|    policy_loss        | 32.8           |\n",
      "|    reward             | -9.5999996e-05 |\n",
      "|    std                | 131            |\n",
      "|    value_loss         | 1.19           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 61084     |\n",
      "|    total_timesteps    | 1440000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63       |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | 118       |\n",
      "|    reward             | -0.000142 |\n",
      "|    std                | 133       |\n",
      "|    value_loss         | 4.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 61499     |\n",
      "|    total_timesteps    | 1450000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.1     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | 75.6      |\n",
      "|    reward             | -0.003711 |\n",
      "|    std                | 133       |\n",
      "|    value_loss         | 1.54      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 61916     |\n",
      "|    total_timesteps    | 1460000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | -48.9     |\n",
      "|    reward             | -0.001435 |\n",
      "|    std                | 133       |\n",
      "|    value_loss         | 3.76      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 62331     |\n",
      "|    total_timesteps    | 1470000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -54.8     |\n",
      "|    reward             | -0.000144 |\n",
      "|    std                | 134       |\n",
      "|    value_loss         | 2.96      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 62747    |\n",
      "|    total_timesteps    | 1480000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | -114     |\n",
      "|    reward             | -0.00021 |\n",
      "|    std                | 135      |\n",
      "|    value_loss         | 5.7      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 63163    |\n",
      "|    total_timesteps    | 1490000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -22      |\n",
      "|    reward             | -0.00101 |\n",
      "|    std                | 135      |\n",
      "|    value_loss         | 4.04     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 63579     |\n",
      "|    total_timesteps    | 1500000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -81.3     |\n",
      "|    reward             | -4.7e-05  |\n",
      "|    std                | 136       |\n",
      "|    value_loss         | 1.82      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 63994     |\n",
      "|    total_timesteps    | 1510000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.3     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -81.3     |\n",
      "|    reward             | -0.000303 |\n",
      "|    std                | 137       |\n",
      "|    value_loss         | 1.9       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 64411    |\n",
      "|    total_timesteps    | 1520000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -5.92    |\n",
      "|    reward             | -4.4e-05 |\n",
      "|    std                | 138      |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 64827     |\n",
      "|    total_timesteps    | 1530000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | 202       |\n",
      "|    reward             | -0.001033 |\n",
      "|    std                | 139       |\n",
      "|    value_loss         | 18.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 65242     |\n",
      "|    total_timesteps    | 1540000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | -415      |\n",
      "|    reward             | -1.3e-05  |\n",
      "|    std                | 139       |\n",
      "|    value_loss         | 44        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 65656    |\n",
      "|    total_timesteps    | 1550000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -9.86    |\n",
      "|    reward             | 0.288327 |\n",
      "|    std                | 140      |\n",
      "|    value_loss         | 2.36     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 15600          |\n",
      "|    time_elapsed       | 66072          |\n",
      "|    total_timesteps    | 1560000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -63.5          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 15599          |\n",
      "|    policy_loss        | 17.1           |\n",
      "|    reward             | -0.00019400002 |\n",
      "|    std                | 140            |\n",
      "|    value_loss         | 15.8           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 15700          |\n",
      "|    time_elapsed       | 66487          |\n",
      "|    total_timesteps    | 1570000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -63.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 15699          |\n",
      "|    policy_loss        | 636            |\n",
      "|    reward             | -0.00021500001 |\n",
      "|    std                | 140            |\n",
      "|    value_loss         | 135            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 66901     |\n",
      "|    total_timesteps    | 1580000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | 40.4      |\n",
      "|    reward             | -0.047758 |\n",
      "|    std                | 142       |\n",
      "|    value_loss         | 1.04      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 67316     |\n",
      "|    total_timesteps    | 1590000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | 19.3      |\n",
      "|    reward             | 0.113707  |\n",
      "|    std                | 143       |\n",
      "|    value_loss         | 1.54      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 16000          |\n",
      "|    time_elapsed       | 67732          |\n",
      "|    total_timesteps    | 1600000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -63.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 15999          |\n",
      "|    policy_loss        | -114           |\n",
      "|    reward             | -4.9000002e-05 |\n",
      "|    std                | 144            |\n",
      "|    value_loss         | 4.32           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 68148     |\n",
      "|    total_timesteps    | 1610000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 124       |\n",
      "|    reward             | -0.001118 |\n",
      "|    std                | 145       |\n",
      "|    value_loss         | 9.58      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 68565     |\n",
      "|    total_timesteps    | 1620000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | 219       |\n",
      "|    reward             | -0.001457 |\n",
      "|    std                | 146       |\n",
      "|    value_loss         | 17.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 68981    |\n",
      "|    total_timesteps    | 1630000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -259     |\n",
      "|    reward             | 2.663524 |\n",
      "|    std                | 146      |\n",
      "|    value_loss         | 23.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 69397     |\n",
      "|    total_timesteps    | 1640000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 76.4      |\n",
      "|    reward             | -0.000295 |\n",
      "|    std                | 147       |\n",
      "|    value_loss         | 17.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 69811    |\n",
      "|    total_timesteps    | 1650000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 30       |\n",
      "|    reward             | 0.033592 |\n",
      "|    std                | 147      |\n",
      "|    value_loss         | 0.344    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 70227     |\n",
      "|    total_timesteps    | 1660000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | 7.33      |\n",
      "|    reward             | 0.8605    |\n",
      "|    std                | 149       |\n",
      "|    value_loss         | 0.207     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 70642     |\n",
      "|    total_timesteps    | 1670000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.2     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -188      |\n",
      "|    reward             | 1.147465  |\n",
      "|    std                | 149       |\n",
      "|    value_loss         | 13.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 71059    |\n",
      "|    total_timesteps    | 1680000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.2    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -34.2    |\n",
      "|    reward             | 0.207873 |\n",
      "|    std                | 150      |\n",
      "|    value_loss         | 4.74     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 71474     |\n",
      "|    total_timesteps    | 1690000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | 165       |\n",
      "|    reward             | -0.002701 |\n",
      "|    std                | 150       |\n",
      "|    value_loss         | 10.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 71889     |\n",
      "|    total_timesteps    | 1700000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | -396      |\n",
      "|    reward             | -0.001008 |\n",
      "|    std                | 150       |\n",
      "|    value_loss         | 56.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 72303     |\n",
      "|    total_timesteps    | 1710000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | 70.4      |\n",
      "|    reward             | -0.001399 |\n",
      "|    std                | 151       |\n",
      "|    value_loss         | 6.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 72719     |\n",
      "|    total_timesteps    | 1720000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -394      |\n",
      "|    reward             | -0.000237 |\n",
      "|    std                | 151       |\n",
      "|    value_loss         | 287       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 73136     |\n",
      "|    total_timesteps    | 1730000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | -3.26     |\n",
      "|    reward             | -0.001296 |\n",
      "|    std                | 152       |\n",
      "|    value_loss         | 2.71      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 73551    |\n",
      "|    total_timesteps    | 1740000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -69.7    |\n",
      "|    reward             | -0.00159 |\n",
      "|    std                | 153      |\n",
      "|    value_loss         | 2.95     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 73966     |\n",
      "|    total_timesteps    | 1750000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 117       |\n",
      "|    reward             | -0.001425 |\n",
      "|    std                | 154       |\n",
      "|    value_loss         | 6.18      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 74383     |\n",
      "|    total_timesteps    | 1760000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | 13.6      |\n",
      "|    reward             | -0.001863 |\n",
      "|    std                | 155       |\n",
      "|    value_loss         | 15.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 17700    |\n",
      "|    time_elapsed       | 74798    |\n",
      "|    total_timesteps    | 1770000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17699    |\n",
      "|    policy_loss        | 129      |\n",
      "|    reward             | -4e-05   |\n",
      "|    std                | 155      |\n",
      "|    value_loss         | 5.97     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 75214    |\n",
      "|    total_timesteps    | 1780000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 178      |\n",
      "|    reward             | 1.951468 |\n",
      "|    std                | 156      |\n",
      "|    value_loss         | 52.3     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 17900          |\n",
      "|    time_elapsed       | 75628          |\n",
      "|    total_timesteps    | 1790000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -64.7          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 17899          |\n",
      "|    policy_loss        | -192           |\n",
      "|    reward             | -0.00021999999 |\n",
      "|    std                | 157            |\n",
      "|    value_loss         | 19.6           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 76043     |\n",
      "|    total_timesteps    | 1800000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | -47.8     |\n",
      "|    reward             | -0.002973 |\n",
      "|    std                | 158       |\n",
      "|    value_loss         | 0.631     |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 18100          |\n",
      "|    time_elapsed       | 76459          |\n",
      "|    total_timesteps    | 1810000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -64.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 18099          |\n",
      "|    policy_loss        | 92.3           |\n",
      "|    reward             | -3.1999996e-05 |\n",
      "|    std                | 159            |\n",
      "|    value_loss         | 3.55           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 76874     |\n",
      "|    total_timesteps    | 1820000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | -141      |\n",
      "|    reward             | -0.465912 |\n",
      "|    std                | 160       |\n",
      "|    value_loss         | 6.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 77291     |\n",
      "|    total_timesteps    | 1830000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 62.3      |\n",
      "|    reward             | -0.000294 |\n",
      "|    std                | 161       |\n",
      "|    value_loss         | 9.5       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 77707     |\n",
      "|    total_timesteps    | 1840000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -890      |\n",
      "|    reward             | -0.000437 |\n",
      "|    std                | 161       |\n",
      "|    value_loss         | 223       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 18500    |\n",
      "|    time_elapsed       | 78129    |\n",
      "|    total_timesteps    | 1850000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18499    |\n",
      "|    policy_loss        | 0.351    |\n",
      "|    reward             | -1.08615 |\n",
      "|    std                | 161      |\n",
      "|    value_loss         | 1.39     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 78553     |\n",
      "|    total_timesteps    | 1860000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | 183       |\n",
      "|    reward             | -0.001682 |\n",
      "|    std                | 162       |\n",
      "|    value_loss         | 29.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 78976     |\n",
      "|    total_timesteps    | 1870000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65       |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -99.2     |\n",
      "|    reward             | -0.000221 |\n",
      "|    std                | 161       |\n",
      "|    value_loss         | 14.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 79400     |\n",
      "|    total_timesteps    | 1880000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | -21.7     |\n",
      "|    reward             | -0.106933 |\n",
      "|    std                | 163       |\n",
      "|    value_loss         | 0.344     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 79824     |\n",
      "|    total_timesteps    | 1890000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | 240       |\n",
      "|    reward             | -0.133684 |\n",
      "|    std                | 165       |\n",
      "|    value_loss         | 15.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 80249     |\n",
      "|    total_timesteps    | 1900000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | -96.6     |\n",
      "|    reward             | -0.003217 |\n",
      "|    std                | 165       |\n",
      "|    value_loss         | 4.96      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 80672     |\n",
      "|    total_timesteps    | 1910000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | -47.5     |\n",
      "|    reward             | -0.001391 |\n",
      "|    std                | 166       |\n",
      "|    value_loss         | 2.69      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 19200          |\n",
      "|    time_elapsed       | 81096          |\n",
      "|    total_timesteps    | 1920000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -65.3          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 19199          |\n",
      "|    policy_loss        | -143           |\n",
      "|    reward             | -4.0999996e-05 |\n",
      "|    std                | 167            |\n",
      "|    value_loss         | 6.72           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 19300          |\n",
      "|    time_elapsed       | 81520          |\n",
      "|    total_timesteps    | 1930000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -65.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 19299          |\n",
      "|    policy_loss        | -506           |\n",
      "|    reward             | -1.7999995e-05 |\n",
      "|    std                | 167            |\n",
      "|    value_loss         | 117            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 81945     |\n",
      "|    total_timesteps    | 1940000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | 78.3      |\n",
      "|    reward             | -0.003546 |\n",
      "|    std                | 168       |\n",
      "|    value_loss         | 22.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 82368     |\n",
      "|    total_timesteps    | 1950000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | -32.4     |\n",
      "|    reward             | -0.007631 |\n",
      "|    std                | 169       |\n",
      "|    value_loss         | 0.325     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 82792     |\n",
      "|    total_timesteps    | 1960000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | -21.2     |\n",
      "|    reward             | -0.002849 |\n",
      "|    std                | 170       |\n",
      "|    value_loss         | 0.455     |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 19700          |\n",
      "|    time_elapsed       | 83217          |\n",
      "|    total_timesteps    | 1970000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -65.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 19699          |\n",
      "|    policy_loss        | -171           |\n",
      "|    reward             | -1.5000003e-05 |\n",
      "|    std                | 171            |\n",
      "|    value_loss         | 9.24           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 19800    |\n",
      "|    time_elapsed       | 83641    |\n",
      "|    total_timesteps    | 1980000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19799    |\n",
      "|    policy_loss        | 123      |\n",
      "|    reward             | -0.00057 |\n",
      "|    std                | 172      |\n",
      "|    value_loss         | 4.67     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 84065     |\n",
      "|    total_timesteps    | 1990000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.7     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | 130       |\n",
      "|    reward             | -0.001001 |\n",
      "|    std                | 173       |\n",
      "|    value_loss         | 28.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 84489     |\n",
      "|    total_timesteps    | 2000000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -306      |\n",
      "|    reward             | -0.000203 |\n",
      "|    std                | 174       |\n",
      "|    value_loss         | 81.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 23              |\n",
      "|    iterations         | 20100           |\n",
      "|    time_elapsed       | 84914           |\n",
      "|    total_timesteps    | 2010000         |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -65.7           |\n",
      "|    explained_variance | 0               |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 20099           |\n",
      "|    policy_loss        | 295             |\n",
      "|    reward             | -0.000120000004 |\n",
      "|    std                | 175             |\n",
      "|    value_loss         | 22.9            |\n",
      "-------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 20200    |\n",
      "|    time_elapsed       | 85337    |\n",
      "|    total_timesteps    | 2020000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20199    |\n",
      "|    policy_loss        | -146     |\n",
      "|    reward             | -5.1e-05 |\n",
      "|    std                | 175      |\n",
      "|    value_loss         | 14.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20300     |\n",
      "|    time_elapsed       | 85762     |\n",
      "|    total_timesteps    | 2030000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20299     |\n",
      "|    policy_loss        | -25.1     |\n",
      "|    reward             | -0.003769 |\n",
      "|    std                | 177       |\n",
      "|    value_loss         | 1.07      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20400     |\n",
      "|    time_elapsed       | 86187     |\n",
      "|    total_timesteps    | 2040000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20399     |\n",
      "|    policy_loss        | -33       |\n",
      "|    reward             | -0.002354 |\n",
      "|    std                | 178       |\n",
      "|    value_loss         | 2.17      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20500     |\n",
      "|    time_elapsed       | 86613     |\n",
      "|    total_timesteps    | 2050000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20499     |\n",
      "|    policy_loss        | 6.34      |\n",
      "|    reward             | -0.000113 |\n",
      "|    std                | 179       |\n",
      "|    value_loss         | 1.31      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20600     |\n",
      "|    time_elapsed       | 87037     |\n",
      "|    total_timesteps    | 2060000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20599     |\n",
      "|    policy_loss        | 303       |\n",
      "|    reward             | -0.000747 |\n",
      "|    std                | 180       |\n",
      "|    value_loss         | 36.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20700     |\n",
      "|    time_elapsed       | 87457     |\n",
      "|    total_timesteps    | 2070000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20699     |\n",
      "|    policy_loss        | 359       |\n",
      "|    reward             | -0.000554 |\n",
      "|    std                | 181       |\n",
      "|    value_loss         | 36.6      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 20800          |\n",
      "|    time_elapsed       | 87874          |\n",
      "|    total_timesteps    | 2080000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -66.1          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 20799          |\n",
      "|    policy_loss        | -925           |\n",
      "|    reward             | -6.1000002e-05 |\n",
      "|    std                | 181            |\n",
      "|    value_loss         | 269            |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 20900         |\n",
      "|    time_elapsed       | 88290         |\n",
      "|    total_timesteps    | 2090000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -66.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 20899         |\n",
      "|    policy_loss        | -249          |\n",
      "|    reward             | -9.999991e-07 |\n",
      "|    std                | 182           |\n",
      "|    value_loss         | 76.9          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 21000    |\n",
      "|    time_elapsed       | 88705    |\n",
      "|    total_timesteps    | 2100000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20999    |\n",
      "|    policy_loss        | -63.9    |\n",
      "|    reward             | 0.139858 |\n",
      "|    std                | 183      |\n",
      "|    value_loss         | 1.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 21100    |\n",
      "|    time_elapsed       | 89122    |\n",
      "|    total_timesteps    | 2110000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21099    |\n",
      "|    policy_loss        | 16.3     |\n",
      "|    reward             | 0.896385 |\n",
      "|    std                | 184      |\n",
      "|    value_loss         | 9.71     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 21200     |\n",
      "|    time_elapsed       | 89539     |\n",
      "|    total_timesteps    | 2120000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21199     |\n",
      "|    policy_loss        | 262       |\n",
      "|    reward             | -0.000169 |\n",
      "|    std                | 185       |\n",
      "|    value_loss         | 31.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 21300    |\n",
      "|    time_elapsed       | 89955    |\n",
      "|    total_timesteps    | 2130000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21299    |\n",
      "|    policy_loss        | -44      |\n",
      "|    reward             | -0.00331 |\n",
      "|    std                | 186      |\n",
      "|    value_loss         | 7.4      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 21400     |\n",
      "|    time_elapsed       | 90372     |\n",
      "|    total_timesteps    | 2140000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21399     |\n",
      "|    policy_loss        | 21.7      |\n",
      "|    reward             | -0.001726 |\n",
      "|    std                | 186       |\n",
      "|    value_loss         | 28.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 21500     |\n",
      "|    time_elapsed       | 90789     |\n",
      "|    total_timesteps    | 2150000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.4     |\n",
      "|    explained_variance | 2.98e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21499     |\n",
      "|    policy_loss        | -438      |\n",
      "|    reward             | -0.000158 |\n",
      "|    std                | 187       |\n",
      "|    value_loss         | 46        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 21600    |\n",
      "|    time_elapsed       | 91206    |\n",
      "|    total_timesteps    | 2160000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21599    |\n",
      "|    policy_loss        | 14.7     |\n",
      "|    reward             | 0.622463 |\n",
      "|    std                | 186      |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 21700    |\n",
      "|    time_elapsed       | 91623    |\n",
      "|    total_timesteps    | 2170000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21699    |\n",
      "|    policy_loss        | 299      |\n",
      "|    reward             | 1.16201  |\n",
      "|    std                | 187      |\n",
      "|    value_loss         | 30.6     |\n",
      "------------------------------------\n",
      "Moment: 74871, episode: 30\n",
      "begin_total_asset: -967392496.22\n",
      "end_total_asset: -898653.44\n",
      "total_reward: -998653.44\n",
      "total_trades: 358625\n",
      "Sharpe: 0.016\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 21800     |\n",
      "|    time_elapsed       | 92040     |\n",
      "|    total_timesteps    | 2180000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21799     |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    reward             | -0.005408 |\n",
      "|    std                | 189       |\n",
      "|    value_loss         | 0.328     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 21900     |\n",
      "|    time_elapsed       | 92457     |\n",
      "|    total_timesteps    | 2190000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21899     |\n",
      "|    policy_loss        | 29.1      |\n",
      "|    reward             | -0.002559 |\n",
      "|    std                | 190       |\n",
      "|    value_loss         | 1.93      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 22000          |\n",
      "|    time_elapsed       | 92873          |\n",
      "|    total_timesteps    | 2200000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -66.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 21999          |\n",
      "|    policy_loss        | 70.2           |\n",
      "|    reward             | -2.8999997e-05 |\n",
      "|    std                | 192            |\n",
      "|    value_loss         | 8.6            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22100     |\n",
      "|    time_elapsed       | 93289     |\n",
      "|    total_timesteps    | 2210000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22099     |\n",
      "|    policy_loss        | 574       |\n",
      "|    reward             | -0.000916 |\n",
      "|    std                | 192       |\n",
      "|    value_loss         | 87        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 22200    |\n",
      "|    time_elapsed       | 93707    |\n",
      "|    total_timesteps    | 2220000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22199    |\n",
      "|    policy_loss        | 284      |\n",
      "|    reward             | -0.00015 |\n",
      "|    std                | 192      |\n",
      "|    value_loss         | 47.3     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 22300          |\n",
      "|    time_elapsed       | 94124          |\n",
      "|    total_timesteps    | 2230000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -66.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 22299          |\n",
      "|    policy_loss        | -603           |\n",
      "|    reward             | -0.00016099999 |\n",
      "|    std                | 192            |\n",
      "|    value_loss         | 142            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22400     |\n",
      "|    time_elapsed       | 94540     |\n",
      "|    total_timesteps    | 2240000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22399     |\n",
      "|    policy_loss        | -774      |\n",
      "|    reward             | -0.002331 |\n",
      "|    std                | 193       |\n",
      "|    value_loss         | 242       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22500     |\n",
      "|    time_elapsed       | 94957     |\n",
      "|    total_timesteps    | 2250000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.8     |\n",
      "|    explained_variance | -5.02e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22499     |\n",
      "|    policy_loss        | -35.3     |\n",
      "|    reward             | 0.035909  |\n",
      "|    std                | 194       |\n",
      "|    value_loss         | 0.356     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22600     |\n",
      "|    time_elapsed       | 95373     |\n",
      "|    total_timesteps    | 2260000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22599     |\n",
      "|    policy_loss        | 50.8      |\n",
      "|    reward             | -0.000177 |\n",
      "|    std                | 195       |\n",
      "|    value_loss         | 4.01      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 22700         |\n",
      "|    time_elapsed       | 95789         |\n",
      "|    total_timesteps    | 2270000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -66.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 22699         |\n",
      "|    policy_loss        | -12.3         |\n",
      "|    reward             | -4.000001e-05 |\n",
      "|    std                | 195           |\n",
      "|    value_loss         | 18.2          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22800     |\n",
      "|    time_elapsed       | 96205     |\n",
      "|    total_timesteps    | 2280000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22799     |\n",
      "|    policy_loss        | 134       |\n",
      "|    reward             | -0.000483 |\n",
      "|    std                | 196       |\n",
      "|    value_loss         | 5.54      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22900     |\n",
      "|    time_elapsed       | 96623     |\n",
      "|    total_timesteps    | 2290000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22899     |\n",
      "|    policy_loss        | -81.5     |\n",
      "|    reward             | -0.000348 |\n",
      "|    std                | 196       |\n",
      "|    value_loss         | 7.41      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 23000     |\n",
      "|    time_elapsed       | 97038     |\n",
      "|    total_timesteps    | 2300000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22999     |\n",
      "|    policy_loss        | -11.4     |\n",
      "|    reward             | -0.001408 |\n",
      "|    std                | 197       |\n",
      "|    value_loss         | 2.34      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 23100    |\n",
      "|    time_elapsed       | 97454    |\n",
      "|    total_timesteps    | 2310000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23099    |\n",
      "|    policy_loss        | -142     |\n",
      "|    reward             | -0.00202 |\n",
      "|    std                | 198      |\n",
      "|    value_loss         | 42.6     |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 23200         |\n",
      "|    time_elapsed       | 97870         |\n",
      "|    total_timesteps    | 2320000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -67           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23199         |\n",
      "|    policy_loss        | 257           |\n",
      "|    reward             | -7.099998e-05 |\n",
      "|    std                | 199           |\n",
      "|    value_loss         | 32.4          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 23300     |\n",
      "|    time_elapsed       | 98287     |\n",
      "|    total_timesteps    | 2330000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23299     |\n",
      "|    policy_loss        | -117      |\n",
      "|    reward             | -0.001809 |\n",
      "|    std                | 201       |\n",
      "|    value_loss         | 4.48      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 23400     |\n",
      "|    time_elapsed       | 98703     |\n",
      "|    total_timesteps    | 2340000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23399     |\n",
      "|    policy_loss        | 68.4      |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 202       |\n",
      "|    value_loss         | 1.58      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 23500     |\n",
      "|    time_elapsed       | 99120     |\n",
      "|    total_timesteps    | 2350000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23499     |\n",
      "|    policy_loss        | -209      |\n",
      "|    reward             | -0.003971 |\n",
      "|    std                | 202       |\n",
      "|    value_loss         | 17.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 23              |\n",
      "|    iterations         | 23600           |\n",
      "|    time_elapsed       | 99537           |\n",
      "|    total_timesteps    | 2360000         |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -67.2           |\n",
      "|    explained_variance | 1.19e-07        |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 23599           |\n",
      "|    policy_loss        | 142             |\n",
      "|    reward             | -0.000122000005 |\n",
      "|    std                | 202             |\n",
      "|    value_loss         | 9.2             |\n",
      "-------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 23700    |\n",
      "|    time_elapsed       | 99953    |\n",
      "|    total_timesteps    | 2370000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23699    |\n",
      "|    policy_loss        | 325      |\n",
      "|    reward             | 3.396472 |\n",
      "|    std                | 203      |\n",
      "|    value_loss         | 38.4     |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 23800         |\n",
      "|    time_elapsed       | 100370        |\n",
      "|    total_timesteps    | 2380000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -67.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23799         |\n",
      "|    policy_loss        | -434          |\n",
      "|    reward             | -6.900001e-05 |\n",
      "|    std                | 203           |\n",
      "|    value_loss         | 68.3          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 23900          |\n",
      "|    time_elapsed       | 100787         |\n",
      "|    total_timesteps    | 2390000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -67.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 23899          |\n",
      "|    policy_loss        | -224           |\n",
      "|    reward             | -0.00021600001 |\n",
      "|    std                | 203            |\n",
      "|    value_loss         | 26             |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24000     |\n",
      "|    time_elapsed       | 101202    |\n",
      "|    total_timesteps    | 2400000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.3     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23999     |\n",
      "|    policy_loss        | -0.0335   |\n",
      "|    reward             | -0.004159 |\n",
      "|    std                | 204       |\n",
      "|    value_loss         | 0.0307    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24100     |\n",
      "|    time_elapsed       | 101620    |\n",
      "|    total_timesteps    | 2410000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24099     |\n",
      "|    policy_loss        | 17.7      |\n",
      "|    reward             | -0.001669 |\n",
      "|    std                | 206       |\n",
      "|    value_loss         | 0.774     |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 23              |\n",
      "|    iterations         | 24200           |\n",
      "|    time_elapsed       | 102035          |\n",
      "|    total_timesteps    | 2420000         |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -67.4           |\n",
      "|    explained_variance | 0               |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 24199           |\n",
      "|    policy_loss        | -389            |\n",
      "|    reward             | -1.00000025e-05 |\n",
      "|    std                | 206             |\n",
      "|    value_loss         | 42.4            |\n",
      "-------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 24300    |\n",
      "|    time_elapsed       | 102452   |\n",
      "|    total_timesteps    | 2430000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24299    |\n",
      "|    policy_loss        | -526     |\n",
      "|    reward             | 8.205588 |\n",
      "|    std                | 207      |\n",
      "|    value_loss         | 75.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24400     |\n",
      "|    time_elapsed       | 102870    |\n",
      "|    total_timesteps    | 2440000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24399     |\n",
      "|    policy_loss        | -417      |\n",
      "|    reward             | -0.001026 |\n",
      "|    std                | 208       |\n",
      "|    value_loss         | 54.2      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 24500         |\n",
      "|    time_elapsed       | 103287        |\n",
      "|    total_timesteps    | 2450000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -67.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24499         |\n",
      "|    policy_loss        | 952           |\n",
      "|    reward             | -5.400002e-05 |\n",
      "|    std                | 208           |\n",
      "|    value_loss         | 224           |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 24600          |\n",
      "|    time_elapsed       | 103703         |\n",
      "|    total_timesteps    | 2460000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -67.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 24599          |\n",
      "|    policy_loss        | 61.7           |\n",
      "|    reward             | -0.00020700002 |\n",
      "|    std                | 207            |\n",
      "|    value_loss         | 9.5            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24700     |\n",
      "|    time_elapsed       | 104118    |\n",
      "|    total_timesteps    | 2470000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24699     |\n",
      "|    policy_loss        | -172      |\n",
      "|    reward             | -0.001142 |\n",
      "|    std                | 208       |\n",
      "|    value_loss         | 16.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24800     |\n",
      "|    time_elapsed       | 104535    |\n",
      "|    total_timesteps    | 2480000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24799     |\n",
      "|    policy_loss        | -55.2     |\n",
      "|    reward             | -0.004316 |\n",
      "|    std                | 210       |\n",
      "|    value_loss         | 2.51      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 24900    |\n",
      "|    time_elapsed       | 104950   |\n",
      "|    total_timesteps    | 2490000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24899    |\n",
      "|    policy_loss        | -260     |\n",
      "|    reward             | -3.6e-05 |\n",
      "|    std                | 211      |\n",
      "|    value_loss         | 21       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25000     |\n",
      "|    time_elapsed       | 105368    |\n",
      "|    total_timesteps    | 2500000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24999     |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | -0.001916 |\n",
      "|    std                | 210       |\n",
      "|    value_loss         | 4.54      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25100     |\n",
      "|    time_elapsed       | 105784    |\n",
      "|    total_timesteps    | 2510000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25099     |\n",
      "|    policy_loss        | -89.2     |\n",
      "|    reward             | -0.000964 |\n",
      "|    std                | 211       |\n",
      "|    value_loss         | 16.6      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 25200          |\n",
      "|    time_elapsed       | 106200         |\n",
      "|    total_timesteps    | 2520000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -67.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 25199          |\n",
      "|    policy_loss        | -136           |\n",
      "|    reward             | -3.8999988e-05 |\n",
      "|    std                | 212            |\n",
      "|    value_loss         | 13.9           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 25300         |\n",
      "|    time_elapsed       | 106618        |\n",
      "|    total_timesteps    | 2530000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -67.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 25299         |\n",
      "|    policy_loss        | 778           |\n",
      "|    reward             | -0.0015659999 |\n",
      "|    std                | 212           |\n",
      "|    value_loss         | 158           |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 25400          |\n",
      "|    time_elapsed       | 107034         |\n",
      "|    total_timesteps    | 2540000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -67.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 25399          |\n",
      "|    policy_loss        | -55.1          |\n",
      "|    reward             | -7.0999995e-05 |\n",
      "|    std                | 213            |\n",
      "|    value_loss         | 6.28           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25500     |\n",
      "|    time_elapsed       | 107450    |\n",
      "|    total_timesteps    | 2550000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25499     |\n",
      "|    policy_loss        | 8.9       |\n",
      "|    reward             | -0.000128 |\n",
      "|    std                | 214       |\n",
      "|    value_loss         | 0.127     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25600     |\n",
      "|    time_elapsed       | 107866    |\n",
      "|    total_timesteps    | 2560000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25599     |\n",
      "|    policy_loss        | 158       |\n",
      "|    reward             | -0.000137 |\n",
      "|    std                | 216       |\n",
      "|    value_loss         | 9.6       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25700     |\n",
      "|    time_elapsed       | 108283    |\n",
      "|    total_timesteps    | 2570000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25699     |\n",
      "|    policy_loss        | -154      |\n",
      "|    reward             | -0.000172 |\n",
      "|    std                | 216       |\n",
      "|    value_loss         | 11.1      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 25800          |\n",
      "|    time_elapsed       | 108699         |\n",
      "|    total_timesteps    | 2580000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -67.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 25799          |\n",
      "|    policy_loss        | 87             |\n",
      "|    reward             | -4.0000003e-05 |\n",
      "|    std                | 217            |\n",
      "|    value_loss         | 7.28           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25900     |\n",
      "|    time_elapsed       | 109116    |\n",
      "|    total_timesteps    | 2590000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25899     |\n",
      "|    policy_loss        | 185       |\n",
      "|    reward             | -0.00204  |\n",
      "|    std                | 218       |\n",
      "|    value_loss         | 41.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26000     |\n",
      "|    time_elapsed       | 109539    |\n",
      "|    total_timesteps    | 2600000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25999     |\n",
      "|    policy_loss        | -118      |\n",
      "|    reward             | -0.001731 |\n",
      "|    std                | 218       |\n",
      "|    value_loss         | 15.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26100     |\n",
      "|    time_elapsed       | 109966    |\n",
      "|    total_timesteps    | 2610000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26099     |\n",
      "|    policy_loss        | -175      |\n",
      "|    reward             | -0.000445 |\n",
      "|    std                | 218       |\n",
      "|    value_loss         | 16.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26200     |\n",
      "|    time_elapsed       | 110390    |\n",
      "|    total_timesteps    | 2620000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26199     |\n",
      "|    policy_loss        | -153      |\n",
      "|    reward             | 0.711505  |\n",
      "|    std                | 219       |\n",
      "|    value_loss         | 60        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26300     |\n",
      "|    time_elapsed       | 110815    |\n",
      "|    total_timesteps    | 2630000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26299     |\n",
      "|    policy_loss        | -77.6     |\n",
      "|    reward             | -0.003274 |\n",
      "|    std                | 220       |\n",
      "|    value_loss         | 4.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26400     |\n",
      "|    time_elapsed       | 111239    |\n",
      "|    total_timesteps    | 2640000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26399     |\n",
      "|    policy_loss        | -61.5     |\n",
      "|    reward             | -0.001408 |\n",
      "|    std                | 221       |\n",
      "|    value_loss         | 2.21      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26500     |\n",
      "|    time_elapsed       | 111664    |\n",
      "|    total_timesteps    | 2650000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26499     |\n",
      "|    policy_loss        | 65.7      |\n",
      "|    reward             | -0.002772 |\n",
      "|    std                | 221       |\n",
      "|    value_loss         | 2.08      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26600     |\n",
      "|    time_elapsed       | 112089    |\n",
      "|    total_timesteps    | 2660000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26599     |\n",
      "|    policy_loss        | -90.8     |\n",
      "|    reward             | -0.003278 |\n",
      "|    std                | 223       |\n",
      "|    value_loss         | 4.97      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 26700    |\n",
      "|    time_elapsed       | 112513   |\n",
      "|    total_timesteps    | 2670000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26699    |\n",
      "|    policy_loss        | -61.4    |\n",
      "|    reward             | 4.881682 |\n",
      "|    std                | 223      |\n",
      "|    value_loss         | 15.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26800     |\n",
      "|    time_elapsed       | 112938    |\n",
      "|    total_timesteps    | 2680000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26799     |\n",
      "|    policy_loss        | -1.32e+03 |\n",
      "|    reward             | -0.000765 |\n",
      "|    std                | 223       |\n",
      "|    value_loss         | 600       |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 23              |\n",
      "|    iterations         | 26900           |\n",
      "|    time_elapsed       | 113362          |\n",
      "|    total_timesteps    | 2690000         |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -68.2           |\n",
      "|    explained_variance | 0               |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 26899           |\n",
      "|    policy_loss        | -1.03e+03       |\n",
      "|    reward             | -0.000119000004 |\n",
      "|    std                | 223             |\n",
      "|    value_loss         | 315             |\n",
      "-------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27000     |\n",
      "|    time_elapsed       | 113787    |\n",
      "|    total_timesteps    | 2700000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26999     |\n",
      "|    policy_loss        | 44.5      |\n",
      "|    reward             | -0.002807 |\n",
      "|    std                | 225       |\n",
      "|    value_loss         | 0.546     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 27100    |\n",
      "|    time_elapsed       | 114212   |\n",
      "|    total_timesteps    | 2710000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27099    |\n",
      "|    policy_loss        | 47.2     |\n",
      "|    reward             | -0.00491 |\n",
      "|    std                | 227      |\n",
      "|    value_loss         | 3.24     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27200     |\n",
      "|    time_elapsed       | 114637    |\n",
      "|    total_timesteps    | 2720000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27199     |\n",
      "|    policy_loss        | -550      |\n",
      "|    reward             | -0.002954 |\n",
      "|    std                | 228       |\n",
      "|    value_loss         | 88.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 27300    |\n",
      "|    time_elapsed       | 115062   |\n",
      "|    total_timesteps    | 2730000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 27299    |\n",
      "|    policy_loss        | 115      |\n",
      "|    reward             | -0.00364 |\n",
      "|    std                | 228      |\n",
      "|    value_loss         | 18.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27400     |\n",
      "|    time_elapsed       | 115486    |\n",
      "|    total_timesteps    | 2740000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27399     |\n",
      "|    policy_loss        | -218      |\n",
      "|    reward             | -0.445838 |\n",
      "|    std                | 228       |\n",
      "|    value_loss         | 37.5      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 27500          |\n",
      "|    time_elapsed       | 115911         |\n",
      "|    total_timesteps    | 2750000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -68.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 27499          |\n",
      "|    policy_loss        | -293           |\n",
      "|    reward             | -8.3000006e-05 |\n",
      "|    std                | 228            |\n",
      "|    value_loss         | 54.6           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27600     |\n",
      "|    time_elapsed       | 116336    |\n",
      "|    total_timesteps    | 2760000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27599     |\n",
      "|    policy_loss        | -665      |\n",
      "|    reward             | -0.001433 |\n",
      "|    std                | 229       |\n",
      "|    value_loss         | 418       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27700     |\n",
      "|    time_elapsed       | 116760    |\n",
      "|    total_timesteps    | 2770000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27699     |\n",
      "|    policy_loss        | -472      |\n",
      "|    reward             | -0.001867 |\n",
      "|    std                | 229       |\n",
      "|    value_loss         | 96.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27800     |\n",
      "|    time_elapsed       | 117185    |\n",
      "|    total_timesteps    | 2780000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27799     |\n",
      "|    policy_loss        | -73.1     |\n",
      "|    reward             | -0.00319  |\n",
      "|    std                | 231       |\n",
      "|    value_loss         | 2.04      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27900     |\n",
      "|    time_elapsed       | 117604    |\n",
      "|    total_timesteps    | 2790000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27899     |\n",
      "|    policy_loss        | 323       |\n",
      "|    reward             | -0.000606 |\n",
      "|    std                | 232       |\n",
      "|    value_loss         | 27.3      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 28000          |\n",
      "|    time_elapsed       | 118020         |\n",
      "|    total_timesteps    | 2800000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -68.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 27999          |\n",
      "|    policy_loss        | -300           |\n",
      "|    reward             | -4.6999998e-05 |\n",
      "|    std                | 233            |\n",
      "|    value_loss         | 22.5           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28100     |\n",
      "|    time_elapsed       | 118442    |\n",
      "|    total_timesteps    | 2810000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28099     |\n",
      "|    policy_loss        | -176      |\n",
      "|    reward             | -0.004029 |\n",
      "|    std                | 234       |\n",
      "|    value_loss         | 20.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28200     |\n",
      "|    time_elapsed       | 118867    |\n",
      "|    total_timesteps    | 2820000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28199     |\n",
      "|    policy_loss        | -10.6     |\n",
      "|    reward             | -0.000147 |\n",
      "|    std                | 235       |\n",
      "|    value_loss         | 5.58      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28300     |\n",
      "|    time_elapsed       | 119291    |\n",
      "|    total_timesteps    | 2830000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28299     |\n",
      "|    policy_loss        | 1.05e+03  |\n",
      "|    reward             | -0.005702 |\n",
      "|    std                | 235       |\n",
      "|    value_loss         | 367       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28400     |\n",
      "|    time_elapsed       | 119713    |\n",
      "|    total_timesteps    | 2840000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28399     |\n",
      "|    policy_loss        | 522       |\n",
      "|    reward             | -0.002205 |\n",
      "|    std                | 236       |\n",
      "|    value_loss         | 91.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28500     |\n",
      "|    time_elapsed       | 120134    |\n",
      "|    total_timesteps    | 2850000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28499     |\n",
      "|    policy_loss        | -48.1     |\n",
      "|    reward             | -0.001016 |\n",
      "|    std                | 238       |\n",
      "|    value_loss         | 0.587     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28600     |\n",
      "|    time_elapsed       | 120556    |\n",
      "|    total_timesteps    | 2860000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28599     |\n",
      "|    policy_loss        | 89.2      |\n",
      "|    reward             | -0.002712 |\n",
      "|    std                | 239       |\n",
      "|    value_loss         | 2.92      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28700     |\n",
      "|    time_elapsed       | 120980    |\n",
      "|    total_timesteps    | 2870000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28699     |\n",
      "|    policy_loss        | -140      |\n",
      "|    reward             | -0.000252 |\n",
      "|    std                | 240       |\n",
      "|    value_loss         | 5.82      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28800     |\n",
      "|    time_elapsed       | 121404    |\n",
      "|    total_timesteps    | 2880000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28799     |\n",
      "|    policy_loss        | -164      |\n",
      "|    reward             | -0.002537 |\n",
      "|    std                | 241       |\n",
      "|    value_loss         | 15.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28900     |\n",
      "|    time_elapsed       | 121828    |\n",
      "|    total_timesteps    | 2890000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28899     |\n",
      "|    policy_loss        | 0.543     |\n",
      "|    reward             | -1.827322 |\n",
      "|    std                | 242       |\n",
      "|    value_loss         | 44.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29000     |\n",
      "|    time_elapsed       | 122253    |\n",
      "|    total_timesteps    | 2900000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28999     |\n",
      "|    policy_loss        | 228       |\n",
      "|    reward             | -0.000816 |\n",
      "|    std                | 243       |\n",
      "|    value_loss         | 21.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29100     |\n",
      "|    time_elapsed       | 122677    |\n",
      "|    total_timesteps    | 2910000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29099     |\n",
      "|    policy_loss        | 428       |\n",
      "|    reward             | -0.000712 |\n",
      "|    std                | 242       |\n",
      "|    value_loss         | 72.5      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 29200          |\n",
      "|    time_elapsed       | 123100         |\n",
      "|    total_timesteps    | 2920000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -69            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 29199          |\n",
      "|    policy_loss        | 1.19e+03       |\n",
      "|    reward             | -0.00060800003 |\n",
      "|    std                | 242            |\n",
      "|    value_loss         | 404            |\n",
      "------------------------------------------\n",
      "Moment: 74871, episode: 40\n",
      "begin_total_asset: -1174193179.06\n",
      "end_total_asset: -1011048.80\n",
      "total_reward: -1111048.80\n",
      "total_trades: 362081\n",
      "Sharpe: 0.072\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 29300          |\n",
      "|    time_elapsed       | 123526         |\n",
      "|    total_timesteps    | 2930000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -69            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 29299          |\n",
      "|    policy_loss        | 215            |\n",
      "|    reward             | -0.00017500001 |\n",
      "|    std                | 243            |\n",
      "|    value_loss         | 15.9           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 29400    |\n",
      "|    time_elapsed       | 123950   |\n",
      "|    total_timesteps    | 2940000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29399    |\n",
      "|    policy_loss        | -61.3    |\n",
      "|    reward             | 1.478997 |\n",
      "|    std                | 245      |\n",
      "|    value_loss         | 5.9      |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 29500         |\n",
      "|    time_elapsed       | 124374        |\n",
      "|    total_timesteps    | 2950000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -69.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 29499         |\n",
      "|    policy_loss        | -68.9         |\n",
      "|    reward             | -0.0028279999 |\n",
      "|    std                | 246           |\n",
      "|    value_loss         | 3.59          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29600     |\n",
      "|    time_elapsed       | 124799    |\n",
      "|    total_timesteps    | 2960000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29599     |\n",
      "|    policy_loss        | -425      |\n",
      "|    reward             | -0.001802 |\n",
      "|    std                | 246       |\n",
      "|    value_loss         | 55.1      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 29700          |\n",
      "|    time_elapsed       | 125223         |\n",
      "|    total_timesteps    | 2970000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -69.2          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 29699          |\n",
      "|    policy_loss        | -6.39          |\n",
      "|    reward             | -2.8999997e-05 |\n",
      "|    std                | 247            |\n",
      "|    value_loss         | 5.02           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29800     |\n",
      "|    time_elapsed       | 125647    |\n",
      "|    total_timesteps    | 2980000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29799     |\n",
      "|    policy_loss        | -601      |\n",
      "|    reward             | -0.003378 |\n",
      "|    std                | 247       |\n",
      "|    value_loss         | 145       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29900     |\n",
      "|    time_elapsed       | 126070    |\n",
      "|    total_timesteps    | 2990000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29899     |\n",
      "|    policy_loss        | 364       |\n",
      "|    reward             | -0.001326 |\n",
      "|    std                | 247       |\n",
      "|    value_loss         | 35.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 30000    |\n",
      "|    time_elapsed       | 126494   |\n",
      "|    total_timesteps    | 3000000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29999    |\n",
      "|    policy_loss        | 45.4     |\n",
      "|    reward             | 1.284088 |\n",
      "|    std                | 250      |\n",
      "|    value_loss         | 0.726    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30100     |\n",
      "|    time_elapsed       | 126918    |\n",
      "|    total_timesteps    | 3010000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.3     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30099     |\n",
      "|    policy_loss        | -50.8     |\n",
      "|    reward             | -0.000542 |\n",
      "|    std                | 251       |\n",
      "|    value_loss         | 2.32      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30200     |\n",
      "|    time_elapsed       | 127334    |\n",
      "|    total_timesteps    | 3020000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30199     |\n",
      "|    policy_loss        | 114       |\n",
      "|    reward             | -0.001323 |\n",
      "|    std                | 253       |\n",
      "|    value_loss         | 22        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30300     |\n",
      "|    time_elapsed       | 127751    |\n",
      "|    total_timesteps    | 3030000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30299     |\n",
      "|    policy_loss        | 542       |\n",
      "|    reward             | -0.001012 |\n",
      "|    std                | 254       |\n",
      "|    value_loss         | 83.4      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 30400          |\n",
      "|    time_elapsed       | 128168         |\n",
      "|    total_timesteps    | 3040000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -69.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 30399          |\n",
      "|    policy_loss        | 123            |\n",
      "|    reward             | -0.00024499997 |\n",
      "|    std                | 255            |\n",
      "|    value_loss         | 12.8           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30500     |\n",
      "|    time_elapsed       | 128584    |\n",
      "|    total_timesteps    | 3050000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30499     |\n",
      "|    policy_loss        | -477      |\n",
      "|    reward             | -0.833263 |\n",
      "|    std                | 255       |\n",
      "|    value_loss         | 107       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30600     |\n",
      "|    time_elapsed       | 129001    |\n",
      "|    total_timesteps    | 3060000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30599     |\n",
      "|    policy_loss        | 1.13e+03  |\n",
      "|    reward             | -0.000273 |\n",
      "|    std                | 256       |\n",
      "|    value_loss         | 331       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30700     |\n",
      "|    time_elapsed       | 129417    |\n",
      "|    total_timesteps    | 3070000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.6     |\n",
      "|    explained_variance | 0.00683   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30699     |\n",
      "|    policy_loss        | -3.04     |\n",
      "|    reward             | -0.001659 |\n",
      "|    std                | 257       |\n",
      "|    value_loss         | 0.0161    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30800     |\n",
      "|    time_elapsed       | 129834    |\n",
      "|    total_timesteps    | 3080000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30799     |\n",
      "|    policy_loss        | 104       |\n",
      "|    reward             | -0.129179 |\n",
      "|    std                | 259       |\n",
      "|    value_loss         | 8.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30900     |\n",
      "|    time_elapsed       | 130251    |\n",
      "|    total_timesteps    | 3090000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30899     |\n",
      "|    policy_loss        | -11.2     |\n",
      "|    reward             | -0.001763 |\n",
      "|    std                | 259       |\n",
      "|    value_loss         | 3.93      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31000     |\n",
      "|    time_elapsed       | 130668    |\n",
      "|    total_timesteps    | 3100000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30999     |\n",
      "|    policy_loss        | -791      |\n",
      "|    reward             | -0.638401 |\n",
      "|    std                | 261       |\n",
      "|    value_loss         | 151       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31100     |\n",
      "|    time_elapsed       | 131086    |\n",
      "|    total_timesteps    | 3110000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31099     |\n",
      "|    policy_loss        | 196       |\n",
      "|    reward             | 2.785231  |\n",
      "|    std                | 260       |\n",
      "|    value_loss         | 12        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31200     |\n",
      "|    time_elapsed       | 131505    |\n",
      "|    total_timesteps    | 3120000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31199     |\n",
      "|    policy_loss        | -227      |\n",
      "|    reward             | -0.000903 |\n",
      "|    std                | 262       |\n",
      "|    value_loss         | 14.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31300     |\n",
      "|    time_elapsed       | 131921    |\n",
      "|    total_timesteps    | 3130000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31299     |\n",
      "|    policy_loss        | -592      |\n",
      "|    reward             | -0.001303 |\n",
      "|    std                | 263       |\n",
      "|    value_loss         | 98.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31400     |\n",
      "|    time_elapsed       | 132336    |\n",
      "|    total_timesteps    | 3140000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31399     |\n",
      "|    policy_loss        | 1.24e+03  |\n",
      "|    reward             | -0.001042 |\n",
      "|    std                | 264       |\n",
      "|    value_loss         | 385       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31500     |\n",
      "|    time_elapsed       | 132754    |\n",
      "|    total_timesteps    | 3150000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31499     |\n",
      "|    policy_loss        | 22.6      |\n",
      "|    reward             | -0.005207 |\n",
      "|    std                | 266       |\n",
      "|    value_loss         | 0.219     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31600     |\n",
      "|    time_elapsed       | 133173    |\n",
      "|    total_timesteps    | 3160000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31599     |\n",
      "|    policy_loss        | -285      |\n",
      "|    reward             | -0.000185 |\n",
      "|    std                | 267       |\n",
      "|    value_loss         | 19.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31700     |\n",
      "|    time_elapsed       | 133590    |\n",
      "|    total_timesteps    | 3170000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31699     |\n",
      "|    policy_loss        | 326       |\n",
      "|    reward             | -0.002719 |\n",
      "|    std                | 268       |\n",
      "|    value_loss         | 59.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31800     |\n",
      "|    time_elapsed       | 134007    |\n",
      "|    total_timesteps    | 3180000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31799     |\n",
      "|    policy_loss        | 948       |\n",
      "|    reward             | -0.003148 |\n",
      "|    std                | 268       |\n",
      "|    value_loss         | 282       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31900     |\n",
      "|    time_elapsed       | 134424    |\n",
      "|    total_timesteps    | 3190000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31899     |\n",
      "|    policy_loss        | -558      |\n",
      "|    reward             | 0.546772  |\n",
      "|    std                | 268       |\n",
      "|    value_loss         | 239       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32000     |\n",
      "|    time_elapsed       | 134842    |\n",
      "|    total_timesteps    | 3200000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31999     |\n",
      "|    policy_loss        | -435      |\n",
      "|    reward             | -0.000504 |\n",
      "|    std                | 268       |\n",
      "|    value_loss         | 250       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32100     |\n",
      "|    time_elapsed       | 135259    |\n",
      "|    total_timesteps    | 3210000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32099     |\n",
      "|    policy_loss        | -184      |\n",
      "|    reward             | -0.000645 |\n",
      "|    std                | 269       |\n",
      "|    value_loss         | 153       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32200     |\n",
      "|    time_elapsed       | 135674    |\n",
      "|    total_timesteps    | 3220000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.1     |\n",
      "|    explained_variance | 0.00278   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32199     |\n",
      "|    policy_loss        | -8.11     |\n",
      "|    reward             | -0.017792 |\n",
      "|    std                | 269       |\n",
      "|    value_loss         | 0.0308    |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 32300         |\n",
      "|    time_elapsed       | 136091        |\n",
      "|    total_timesteps    | 3230000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -70.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 32299         |\n",
      "|    policy_loss        | -159          |\n",
      "|    reward             | -0.0011539999 |\n",
      "|    std                | 271           |\n",
      "|    value_loss         | 11.5          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32400     |\n",
      "|    time_elapsed       | 136509    |\n",
      "|    total_timesteps    | 3240000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32399     |\n",
      "|    policy_loss        | -224      |\n",
      "|    reward             | -0.756399 |\n",
      "|    std                | 273       |\n",
      "|    value_loss         | 14.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32500     |\n",
      "|    time_elapsed       | 136926    |\n",
      "|    total_timesteps    | 3250000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32499     |\n",
      "|    policy_loss        | -89.8     |\n",
      "|    reward             | -0.002365 |\n",
      "|    std                | 273       |\n",
      "|    value_loss         | 4.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32600     |\n",
      "|    time_elapsed       | 137344    |\n",
      "|    total_timesteps    | 3260000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32599     |\n",
      "|    policy_loss        | 264       |\n",
      "|    reward             | -0.002286 |\n",
      "|    std                | 274       |\n",
      "|    value_loss         | 20        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32700     |\n",
      "|    time_elapsed       | 137761    |\n",
      "|    total_timesteps    | 3270000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32699     |\n",
      "|    policy_loss        | -359      |\n",
      "|    reward             | -0.001464 |\n",
      "|    std                | 274       |\n",
      "|    value_loss         | 45.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32800     |\n",
      "|    time_elapsed       | 138180    |\n",
      "|    total_timesteps    | 3280000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32799     |\n",
      "|    policy_loss        | -1.15e+03 |\n",
      "|    reward             | -1.331528 |\n",
      "|    std                | 275       |\n",
      "|    value_loss         | 293       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32900     |\n",
      "|    time_elapsed       | 138597    |\n",
      "|    total_timesteps    | 3290000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32899     |\n",
      "|    policy_loss        | -1.5e+03  |\n",
      "|    reward             | -0.001338 |\n",
      "|    std                | 276       |\n",
      "|    value_loss         | 991       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33000     |\n",
      "|    time_elapsed       | 139015    |\n",
      "|    total_timesteps    | 3300000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32999     |\n",
      "|    policy_loss        | 41.6      |\n",
      "|    reward             | -0.265652 |\n",
      "|    std                | 277       |\n",
      "|    value_loss         | 3.34      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33100     |\n",
      "|    time_elapsed       | 139432    |\n",
      "|    total_timesteps    | 3310000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33099     |\n",
      "|    policy_loss        | 19.2      |\n",
      "|    reward             | -0.006215 |\n",
      "|    std                | 279       |\n",
      "|    value_loss         | 0.537     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33200     |\n",
      "|    time_elapsed       | 139851    |\n",
      "|    total_timesteps    | 3320000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33199     |\n",
      "|    policy_loss        | 281       |\n",
      "|    reward             | -0.000771 |\n",
      "|    std                | 281       |\n",
      "|    value_loss         | 26.8      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 33300          |\n",
      "|    time_elapsed       | 140271         |\n",
      "|    total_timesteps    | 3330000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -70.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 33299          |\n",
      "|    policy_loss        | -183           |\n",
      "|    reward             | -0.00017699998 |\n",
      "|    std                | 282            |\n",
      "|    value_loss         | 7.95           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 33400    |\n",
      "|    time_elapsed       | 140689   |\n",
      "|    total_timesteps    | 3340000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33399    |\n",
      "|    policy_loss        | -70.4    |\n",
      "|    reward             | 0.505162 |\n",
      "|    std                | 282      |\n",
      "|    value_loss         | 6.07     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 33500          |\n",
      "|    time_elapsed       | 141107         |\n",
      "|    total_timesteps    | 3350000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -70.5          |\n",
      "|    explained_variance | 1.79e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 33499          |\n",
      "|    policy_loss        | 1.42e+03       |\n",
      "|    reward             | -4.4000004e-05 |\n",
      "|    std                | 282            |\n",
      "|    value_loss         | 579            |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 33600          |\n",
      "|    time_elapsed       | 141525         |\n",
      "|    total_timesteps    | 3360000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -70.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 33599          |\n",
      "|    policy_loss        | 400            |\n",
      "|    reward             | -0.00022299995 |\n",
      "|    std                | 284            |\n",
      "|    value_loss         | 41.9           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 33700    |\n",
      "|    time_elapsed       | 141943   |\n",
      "|    total_timesteps    | 3370000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.6    |\n",
      "|    explained_variance | -0.00198 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33699    |\n",
      "|    policy_loss        | -5.32    |\n",
      "|    reward             | -9.9e-05 |\n",
      "|    std                | 284      |\n",
      "|    value_loss         | 0.0422   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33800     |\n",
      "|    time_elapsed       | 142360    |\n",
      "|    total_timesteps    | 3380000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33799     |\n",
      "|    policy_loss        | 91.4      |\n",
      "|    reward             | -0.000124 |\n",
      "|    std                | 287       |\n",
      "|    value_loss         | 2.85      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33900     |\n",
      "|    time_elapsed       | 142777    |\n",
      "|    total_timesteps    | 3390000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33899     |\n",
      "|    policy_loss        | -380      |\n",
      "|    reward             | -0.000644 |\n",
      "|    std                | 287       |\n",
      "|    value_loss         | 64.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34000     |\n",
      "|    time_elapsed       | 143195    |\n",
      "|    total_timesteps    | 3400000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33999     |\n",
      "|    policy_loss        | 187       |\n",
      "|    reward             | -0.000605 |\n",
      "|    std                | 288       |\n",
      "|    value_loss         | 12.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34100     |\n",
      "|    time_elapsed       | 143612    |\n",
      "|    total_timesteps    | 3410000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34099     |\n",
      "|    policy_loss        | 81.3      |\n",
      "|    reward             | -0.002168 |\n",
      "|    std                | 288       |\n",
      "|    value_loss         | 6.24      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34200     |\n",
      "|    time_elapsed       | 144029    |\n",
      "|    total_timesteps    | 3420000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34199     |\n",
      "|    policy_loss        | -93.6     |\n",
      "|    reward             | -0.001311 |\n",
      "|    std                | 287       |\n",
      "|    value_loss         | 14.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34300     |\n",
      "|    time_elapsed       | 144446    |\n",
      "|    total_timesteps    | 3430000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34299     |\n",
      "|    policy_loss        | 2.6e+03   |\n",
      "|    reward             | -0.002839 |\n",
      "|    std                | 288       |\n",
      "|    value_loss         | 1.56e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34400     |\n",
      "|    time_elapsed       | 144862    |\n",
      "|    total_timesteps    | 3440000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34399     |\n",
      "|    policy_loss        | 59        |\n",
      "|    reward             | -0.001113 |\n",
      "|    std                | 288       |\n",
      "|    value_loss         | 66.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34500     |\n",
      "|    time_elapsed       | 145279    |\n",
      "|    total_timesteps    | 3450000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34499     |\n",
      "|    policy_loss        | 104       |\n",
      "|    reward             | -0.688516 |\n",
      "|    std                | 290       |\n",
      "|    value_loss         | 2.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34600     |\n",
      "|    time_elapsed       | 145696    |\n",
      "|    total_timesteps    | 3460000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34599     |\n",
      "|    policy_loss        | 186       |\n",
      "|    reward             | -0.001447 |\n",
      "|    std                | 292       |\n",
      "|    value_loss         | 11.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34700     |\n",
      "|    time_elapsed       | 146118    |\n",
      "|    total_timesteps    | 3470000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34699     |\n",
      "|    policy_loss        | -107      |\n",
      "|    reward             | -1.032936 |\n",
      "|    std                | 294       |\n",
      "|    value_loss         | 6.87      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34800     |\n",
      "|    time_elapsed       | 146543    |\n",
      "|    total_timesteps    | 3480000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34799     |\n",
      "|    policy_loss        | 466       |\n",
      "|    reward             | -0.000845 |\n",
      "|    std                | 295       |\n",
      "|    value_loss         | 66.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34900     |\n",
      "|    time_elapsed       | 146969    |\n",
      "|    total_timesteps    | 3490000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34899     |\n",
      "|    policy_loss        | -506      |\n",
      "|    reward             | -6.585357 |\n",
      "|    std                | 295       |\n",
      "|    value_loss         | 61.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35000     |\n",
      "|    time_elapsed       | 147394    |\n",
      "|    total_timesteps    | 3500000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34999     |\n",
      "|    policy_loss        | 1.33e+03  |\n",
      "|    reward             | -0.001266 |\n",
      "|    std                | 295       |\n",
      "|    value_loss         | 495       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35100     |\n",
      "|    time_elapsed       | 147819    |\n",
      "|    total_timesteps    | 3510000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35099     |\n",
      "|    policy_loss        | 658       |\n",
      "|    reward             | -0.003658 |\n",
      "|    std                | 296       |\n",
      "|    value_loss         | 112       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35200     |\n",
      "|    time_elapsed       | 148244    |\n",
      "|    total_timesteps    | 3520000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35199     |\n",
      "|    policy_loss        | -41       |\n",
      "|    reward             | -0.118204 |\n",
      "|    std                | 295       |\n",
      "|    value_loss         | 0.611     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 35300    |\n",
      "|    time_elapsed       | 148669   |\n",
      "|    total_timesteps    | 3530000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35299    |\n",
      "|    policy_loss        | -52.5    |\n",
      "|    reward             | 0.407918 |\n",
      "|    std                | 297      |\n",
      "|    value_loss         | 5.15     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 35400          |\n",
      "|    time_elapsed       | 149094         |\n",
      "|    total_timesteps    | 3540000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71            |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 35399          |\n",
      "|    policy_loss        | 175            |\n",
      "|    reward             | -1.9999982e-06 |\n",
      "|    std                | 297            |\n",
      "|    value_loss         | 14.4           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 35500    |\n",
      "|    time_elapsed       | 149519   |\n",
      "|    total_timesteps    | 3550000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35499    |\n",
      "|    policy_loss        | -56.1    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 298      |\n",
      "|    value_loss         | 11.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35600     |\n",
      "|    time_elapsed       | 149944    |\n",
      "|    total_timesteps    | 3560000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35599     |\n",
      "|    policy_loss        | -22.4     |\n",
      "|    reward             | -0.002211 |\n",
      "|    std                | 298       |\n",
      "|    value_loss         | 21.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35700     |\n",
      "|    time_elapsed       | 150370    |\n",
      "|    total_timesteps    | 3570000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35699     |\n",
      "|    policy_loss        | 1.81e+03  |\n",
      "|    reward             | -0.004091 |\n",
      "|    std                | 298       |\n",
      "|    value_loss         | 746       |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 35800         |\n",
      "|    time_elapsed       | 150795        |\n",
      "|    total_timesteps    | 3580000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -71.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 35799         |\n",
      "|    policy_loss        | -789          |\n",
      "|    reward             | -4.599998e-05 |\n",
      "|    std                | 299           |\n",
      "|    value_loss         | 157           |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35900     |\n",
      "|    time_elapsed       | 151220    |\n",
      "|    total_timesteps    | 3590000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35899     |\n",
      "|    policy_loss        | -736      |\n",
      "|    reward             | -0.000654 |\n",
      "|    std                | 300       |\n",
      "|    value_loss         | 151       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36000     |\n",
      "|    time_elapsed       | 151645    |\n",
      "|    total_timesteps    | 3600000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35999     |\n",
      "|    policy_loss        | -19.1     |\n",
      "|    reward             | -0.002276 |\n",
      "|    std                | 301       |\n",
      "|    value_loss         | 3.24      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36100     |\n",
      "|    time_elapsed       | 152070    |\n",
      "|    total_timesteps    | 3610000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36099     |\n",
      "|    policy_loss        | -141      |\n",
      "|    reward             | -0.002817 |\n",
      "|    std                | 302       |\n",
      "|    value_loss         | 5.96      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 36200    |\n",
      "|    time_elapsed       | 152495   |\n",
      "|    total_timesteps    | 3620000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36199    |\n",
      "|    policy_loss        | 117      |\n",
      "|    reward             | 0.309175 |\n",
      "|    std                | 303      |\n",
      "|    value_loss         | 8.11     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 36300          |\n",
      "|    time_elapsed       | 152920         |\n",
      "|    total_timesteps    | 3630000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 36299          |\n",
      "|    policy_loss        | -142           |\n",
      "|    reward             | -0.00010899999 |\n",
      "|    std                | 303            |\n",
      "|    value_loss         | 9.58           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 36400    |\n",
      "|    time_elapsed       | 153342   |\n",
      "|    total_timesteps    | 3640000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36399    |\n",
      "|    policy_loss        | 13.3     |\n",
      "|    reward             | -0.00139 |\n",
      "|    std                | 302      |\n",
      "|    value_loss         | 1.93     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36500     |\n",
      "|    time_elapsed       | 153759    |\n",
      "|    total_timesteps    | 3650000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36499     |\n",
      "|    policy_loss        | -746      |\n",
      "|    reward             | -0.001224 |\n",
      "|    std                | 302       |\n",
      "|    value_loss         | 142       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36600     |\n",
      "|    time_elapsed       | 154176    |\n",
      "|    total_timesteps    | 3660000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36599     |\n",
      "|    policy_loss        | -515      |\n",
      "|    reward             | -0.001514 |\n",
      "|    std                | 303       |\n",
      "|    value_loss         | 60.2      |\n",
      "-------------------------------------\n",
      "Moment: 74871, episode: 50\n",
      "begin_total_asset: -1349113975.96\n",
      "end_total_asset: -1130820.37\n",
      "total_reward: -1230820.37\n",
      "total_trades: 364278\n",
      "Sharpe: 0.009\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36700     |\n",
      "|    time_elapsed       | 154593    |\n",
      "|    total_timesteps    | 3670000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36699     |\n",
      "|    policy_loss        | -2.19     |\n",
      "|    reward             | -0.000212 |\n",
      "|    std                | 304       |\n",
      "|    value_loss         | 0.0362    |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 36800         |\n",
      "|    time_elapsed       | 155010        |\n",
      "|    total_timesteps    | 3680000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -71.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 36799         |\n",
      "|    policy_loss        | 174           |\n",
      "|    reward             | -8.399999e-05 |\n",
      "|    std                | 305           |\n",
      "|    value_loss         | 6.81          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36900     |\n",
      "|    time_elapsed       | 155427    |\n",
      "|    total_timesteps    | 3690000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36899     |\n",
      "|    policy_loss        | 24.9      |\n",
      "|    reward             | -0.002622 |\n",
      "|    std                | 305       |\n",
      "|    value_loss         | 7.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37000     |\n",
      "|    time_elapsed       | 155844    |\n",
      "|    total_timesteps    | 3700000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36999     |\n",
      "|    policy_loss        | 1.11      |\n",
      "|    reward             | -1.093185 |\n",
      "|    std                | 306       |\n",
      "|    value_loss         | 6.28      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37100     |\n",
      "|    time_elapsed       | 156260    |\n",
      "|    total_timesteps    | 3710000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37099     |\n",
      "|    policy_loss        | -390      |\n",
      "|    reward             | -0.982543 |\n",
      "|    std                | 305       |\n",
      "|    value_loss         | 48.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37200     |\n",
      "|    time_elapsed       | 156679    |\n",
      "|    total_timesteps    | 3720000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37199     |\n",
      "|    policy_loss        | 500       |\n",
      "|    reward             | -0.000241 |\n",
      "|    std                | 305       |\n",
      "|    value_loss         | 95.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37300     |\n",
      "|    time_elapsed       | 157096    |\n",
      "|    total_timesteps    | 3730000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37299     |\n",
      "|    policy_loss        | -218      |\n",
      "|    reward             | -0.000188 |\n",
      "|    std                | 306       |\n",
      "|    value_loss         | 48.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37400     |\n",
      "|    time_elapsed       | 157514    |\n",
      "|    total_timesteps    | 3740000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37399     |\n",
      "|    policy_loss        | -2.36e+03 |\n",
      "|    reward             | -0.003981 |\n",
      "|    std                | 306       |\n",
      "|    value_loss         | 1.41e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 37500    |\n",
      "|    time_elapsed       | 157931   |\n",
      "|    total_timesteps    | 3750000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37499    |\n",
      "|    policy_loss        | 14       |\n",
      "|    reward             | -0.00632 |\n",
      "|    std                | 308      |\n",
      "|    value_loss         | 0.427    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 37600    |\n",
      "|    time_elapsed       | 158348   |\n",
      "|    total_timesteps    | 3760000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37599    |\n",
      "|    policy_loss        | -187     |\n",
      "|    reward             | 0.809673 |\n",
      "|    std                | 310      |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 37700          |\n",
      "|    time_elapsed       | 158765         |\n",
      "|    total_timesteps    | 3770000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 37699          |\n",
      "|    policy_loss        | -166           |\n",
      "|    reward             | -0.00020899999 |\n",
      "|    std                | 311            |\n",
      "|    value_loss         | 11.2           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37800     |\n",
      "|    time_elapsed       | 159182    |\n",
      "|    total_timesteps    | 3780000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37799     |\n",
      "|    policy_loss        | -858      |\n",
      "|    reward             | -0.003327 |\n",
      "|    std                | 313       |\n",
      "|    value_loss         | 211       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 37900    |\n",
      "|    time_elapsed       | 159600   |\n",
      "|    total_timesteps    | 3790000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37899    |\n",
      "|    policy_loss        | 834      |\n",
      "|    reward             | 0.545885 |\n",
      "|    std                | 314      |\n",
      "|    value_loss         | 227      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38000     |\n",
      "|    time_elapsed       | 160017    |\n",
      "|    total_timesteps    | 3800000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37999     |\n",
      "|    policy_loss        | -1.61e+03 |\n",
      "|    reward             | -0.001182 |\n",
      "|    std                | 313       |\n",
      "|    value_loss         | 645       |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 38100         |\n",
      "|    time_elapsed       | 160433        |\n",
      "|    total_timesteps    | 3810000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -71.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 38099         |\n",
      "|    policy_loss        | -39.4         |\n",
      "|    reward             | -0.0022790001 |\n",
      "|    std                | 313           |\n",
      "|    value_loss         | 8.5           |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38200     |\n",
      "|    time_elapsed       | 160852    |\n",
      "|    total_timesteps    | 3820000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38199     |\n",
      "|    policy_loss        | -21       |\n",
      "|    reward             | -0.030122 |\n",
      "|    std                | 314       |\n",
      "|    value_loss         | 0.161     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38300     |\n",
      "|    time_elapsed       | 161270    |\n",
      "|    total_timesteps    | 3830000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38299     |\n",
      "|    policy_loss        | 29.1      |\n",
      "|    reward             | -0.003221 |\n",
      "|    std                | 317       |\n",
      "|    value_loss         | 0.639     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 38400    |\n",
      "|    time_elapsed       | 161688   |\n",
      "|    total_timesteps    | 3840000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38399    |\n",
      "|    policy_loss        | 275      |\n",
      "|    reward             | -2.5e-05 |\n",
      "|    std                | 318      |\n",
      "|    value_loss         | 22.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38500     |\n",
      "|    time_elapsed       | 162107    |\n",
      "|    total_timesteps    | 3850000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38499     |\n",
      "|    policy_loss        | -14.8     |\n",
      "|    reward             | -0.381538 |\n",
      "|    std                | 318       |\n",
      "|    value_loss         | 266       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38600     |\n",
      "|    time_elapsed       | 162524    |\n",
      "|    total_timesteps    | 3860000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38599     |\n",
      "|    policy_loss        | 515       |\n",
      "|    reward             | -0.003137 |\n",
      "|    std                | 318       |\n",
      "|    value_loss         | 56.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38700     |\n",
      "|    time_elapsed       | 162942    |\n",
      "|    total_timesteps    | 3870000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38699     |\n",
      "|    policy_loss        | -56.4     |\n",
      "|    reward             | -0.001845 |\n",
      "|    std                | 318       |\n",
      "|    value_loss         | 7.76      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 38800          |\n",
      "|    time_elapsed       | 163361         |\n",
      "|    total_timesteps    | 3880000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71.7          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 38799          |\n",
      "|    policy_loss        | 543            |\n",
      "|    reward             | -5.2999996e-05 |\n",
      "|    std                | 319            |\n",
      "|    value_loss         | 106            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38900     |\n",
      "|    time_elapsed       | 163779    |\n",
      "|    total_timesteps    | 3890000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38899     |\n",
      "|    policy_loss        | -153      |\n",
      "|    reward             | -0.002617 |\n",
      "|    std                | 319       |\n",
      "|    value_loss         | 183       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39000     |\n",
      "|    time_elapsed       | 164196    |\n",
      "|    total_timesteps    | 3900000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38999     |\n",
      "|    policy_loss        | 141       |\n",
      "|    reward             | -0.005328 |\n",
      "|    std                | 321       |\n",
      "|    value_loss         | 4.62      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39100     |\n",
      "|    time_elapsed       | 164615    |\n",
      "|    total_timesteps    | 3910000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39099     |\n",
      "|    policy_loss        | 54.8      |\n",
      "|    reward             | -0.000953 |\n",
      "|    std                | 322       |\n",
      "|    value_loss         | 1.51      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39200     |\n",
      "|    time_elapsed       | 165033    |\n",
      "|    total_timesteps    | 3920000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39199     |\n",
      "|    policy_loss        | -32.7     |\n",
      "|    reward             | -0.001131 |\n",
      "|    std                | 324       |\n",
      "|    value_loss         | 3.16      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 39300          |\n",
      "|    time_elapsed       | 165452         |\n",
      "|    total_timesteps    | 3930000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71.9          |\n",
      "|    explained_variance | 1.79e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 39299          |\n",
      "|    policy_loss        | 114            |\n",
      "|    reward             | -0.00011099999 |\n",
      "|    std                | 325            |\n",
      "|    value_loss         | 4.42           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39400     |\n",
      "|    time_elapsed       | 165871    |\n",
      "|    total_timesteps    | 3940000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72       |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39399     |\n",
      "|    policy_loss        | -1.88e+03 |\n",
      "|    reward             | 5.59944   |\n",
      "|    std                | 326       |\n",
      "|    value_loss         | 801       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39500     |\n",
      "|    time_elapsed       | 166289    |\n",
      "|    total_timesteps    | 3950000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39499     |\n",
      "|    policy_loss        | -5        |\n",
      "|    reward             | -0.001051 |\n",
      "|    std                | 327       |\n",
      "|    value_loss         | 25.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 23         |\n",
      "|    iterations         | 39600      |\n",
      "|    time_elapsed       | 166706     |\n",
      "|    total_timesteps    | 3960000    |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -72        |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39599      |\n",
      "|    policy_loss        | 652        |\n",
      "|    reward             | -10.144928 |\n",
      "|    std                | 328        |\n",
      "|    value_loss         | 90.2       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 39700    |\n",
      "|    time_elapsed       | 167123   |\n",
      "|    total_timesteps    | 3970000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39699    |\n",
      "|    policy_loss        | 20.9     |\n",
      "|    reward             | 0.201732 |\n",
      "|    std                | 329      |\n",
      "|    value_loss         | 0.345    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39800     |\n",
      "|    time_elapsed       | 167541    |\n",
      "|    total_timesteps    | 3980000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39799     |\n",
      "|    policy_loss        | -10.4     |\n",
      "|    reward             | -0.000766 |\n",
      "|    std                | 331       |\n",
      "|    value_loss         | 2.68      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 39900          |\n",
      "|    time_elapsed       | 167959         |\n",
      "|    total_timesteps    | 3990000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -72.1          |\n",
      "|    explained_variance | -2.38e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 39899          |\n",
      "|    policy_loss        | -189           |\n",
      "|    reward             | -6.1000006e-05 |\n",
      "|    std                | 332            |\n",
      "|    value_loss         | 12.2           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40000     |\n",
      "|    time_elapsed       | 168378    |\n",
      "|    total_timesteps    | 4000000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39999     |\n",
      "|    policy_loss        | 207       |\n",
      "|    reward             | -0.000563 |\n",
      "|    std                | 333       |\n",
      "|    value_loss         | 14.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 40100    |\n",
      "|    time_elapsed       | 168796   |\n",
      "|    total_timesteps    | 4010000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.2    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40099    |\n",
      "|    policy_loss        | -183     |\n",
      "|    reward             | -0.00215 |\n",
      "|    std                | 333      |\n",
      "|    value_loss         | 24.6     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 40200          |\n",
      "|    time_elapsed       | 169213         |\n",
      "|    total_timesteps    | 4020000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -72.2          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 40199          |\n",
      "|    policy_loss        | 291            |\n",
      "|    reward             | -3.3000015e-05 |\n",
      "|    std                | 334            |\n",
      "|    value_loss         | 19.2           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40300     |\n",
      "|    time_elapsed       | 169631    |\n",
      "|    total_timesteps    | 4030000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40299     |\n",
      "|    policy_loss        | 283       |\n",
      "|    reward             | -0.001235 |\n",
      "|    std                | 334       |\n",
      "|    value_loss         | 28.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 40400    |\n",
      "|    time_elapsed       | 170049   |\n",
      "|    total_timesteps    | 4040000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40399    |\n",
      "|    policy_loss        | 27.8     |\n",
      "|    reward             | -0.00034 |\n",
      "|    std                | 333      |\n",
      "|    value_loss         | 16.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40500     |\n",
      "|    time_elapsed       | 170466    |\n",
      "|    total_timesteps    | 4050000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40499     |\n",
      "|    policy_loss        | 3.68      |\n",
      "|    reward             | -0.000224 |\n",
      "|    std                | 337       |\n",
      "|    value_loss         | 2.03      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40600     |\n",
      "|    time_elapsed       | 170885    |\n",
      "|    total_timesteps    | 4060000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40599     |\n",
      "|    policy_loss        | -80       |\n",
      "|    reward             | -0.003702 |\n",
      "|    std                | 340       |\n",
      "|    value_loss         | 5.06      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40700     |\n",
      "|    time_elapsed       | 171303    |\n",
      "|    total_timesteps    | 4070000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.4     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40699     |\n",
      "|    policy_loss        | -123      |\n",
      "|    reward             | -0.003622 |\n",
      "|    std                | 341       |\n",
      "|    value_loss         | 8.86      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40800     |\n",
      "|    time_elapsed       | 171721    |\n",
      "|    total_timesteps    | 4080000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40799     |\n",
      "|    policy_loss        | -1.77e+03 |\n",
      "|    reward             | -0.001392 |\n",
      "|    std                | 342       |\n",
      "|    value_loss         | 938       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40900     |\n",
      "|    time_elapsed       | 172139    |\n",
      "|    total_timesteps    | 4090000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40899     |\n",
      "|    policy_loss        | 270       |\n",
      "|    reward             | -0.000642 |\n",
      "|    std                | 343       |\n",
      "|    value_loss         | 43.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41000     |\n",
      "|    time_elapsed       | 172558    |\n",
      "|    total_timesteps    | 4100000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40999     |\n",
      "|    policy_loss        | 29.7      |\n",
      "|    reward             | -0.003326 |\n",
      "|    std                | 343       |\n",
      "|    value_loss         | 25.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 41100    |\n",
      "|    time_elapsed       | 172976   |\n",
      "|    total_timesteps    | 4110000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41099    |\n",
      "|    policy_loss        | -493     |\n",
      "|    reward             | 1.175749 |\n",
      "|    std                | 343      |\n",
      "|    value_loss         | 80.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41200     |\n",
      "|    time_elapsed       | 173393    |\n",
      "|    total_timesteps    | 4120000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.5     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41199     |\n",
      "|    policy_loss        | -60.8     |\n",
      "|    reward             | -0.006805 |\n",
      "|    std                | 344       |\n",
      "|    value_loss         | 0.791     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41300     |\n",
      "|    time_elapsed       | 173812    |\n",
      "|    total_timesteps    | 4130000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41299     |\n",
      "|    policy_loss        | -26.6     |\n",
      "|    reward             | -0.002627 |\n",
      "|    std                | 347       |\n",
      "|    value_loss         | 1.62      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 41400    |\n",
      "|    time_elapsed       | 174231   |\n",
      "|    total_timesteps    | 4140000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41399    |\n",
      "|    policy_loss        | 100      |\n",
      "|    reward             | 0.841691 |\n",
      "|    std                | 348      |\n",
      "|    value_loss         | 25.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41500     |\n",
      "|    time_elapsed       | 174648    |\n",
      "|    total_timesteps    | 4150000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41499     |\n",
      "|    policy_loss        | 115       |\n",
      "|    reward             | -0.004035 |\n",
      "|    std                | 349       |\n",
      "|    value_loss         | 3.28      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 41600    |\n",
      "|    time_elapsed       | 175067   |\n",
      "|    total_timesteps    | 4160000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41599    |\n",
      "|    policy_loss        | -585     |\n",
      "|    reward             | 0.55654  |\n",
      "|    std                | 349      |\n",
      "|    value_loss         | 93.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41700     |\n",
      "|    time_elapsed       | 175485    |\n",
      "|    total_timesteps    | 4170000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41699     |\n",
      "|    policy_loss        | -282      |\n",
      "|    reward             | -0.001122 |\n",
      "|    std                | 350       |\n",
      "|    value_loss         | 44.2      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 41800          |\n",
      "|    time_elapsed       | 175905         |\n",
      "|    total_timesteps    | 4180000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -72.7          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 41799          |\n",
      "|    policy_loss        | 273            |\n",
      "|    reward             | -0.00016599994 |\n",
      "|    std                | 351            |\n",
      "|    value_loss         | 44.5           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41900     |\n",
      "|    time_elapsed       | 176323    |\n",
      "|    total_timesteps    | 4190000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41899     |\n",
      "|    policy_loss        | 736       |\n",
      "|    reward             | -0.000743 |\n",
      "|    std                | 353       |\n",
      "|    value_loss         | 161       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42000     |\n",
      "|    time_elapsed       | 176740    |\n",
      "|    total_timesteps    | 4200000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41999     |\n",
      "|    policy_loss        | -59.7     |\n",
      "|    reward             | -0.004833 |\n",
      "|    std                | 356       |\n",
      "|    value_loss         | 1.47      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42100     |\n",
      "|    time_elapsed       | 177158    |\n",
      "|    total_timesteps    | 4210000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42099     |\n",
      "|    policy_loss        | 244       |\n",
      "|    reward             | -0.001145 |\n",
      "|    std                | 356       |\n",
      "|    value_loss         | 19.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 42200    |\n",
      "|    time_elapsed       | 177576   |\n",
      "|    total_timesteps    | 4220000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42199    |\n",
      "|    policy_loss        | -35      |\n",
      "|    reward             | -0.00198 |\n",
      "|    std                | 357      |\n",
      "|    value_loss         | 2.65     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42300     |\n",
      "|    time_elapsed       | 177994    |\n",
      "|    total_timesteps    | 4230000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42299     |\n",
      "|    policy_loss        | 48        |\n",
      "|    reward             | -0.000212 |\n",
      "|    std                | 358       |\n",
      "|    value_loss         | 133       |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 42400         |\n",
      "|    time_elapsed       | 178412        |\n",
      "|    total_timesteps    | 4240000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -72.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 42399         |\n",
      "|    policy_loss        | 736           |\n",
      "|    reward             | -4.300002e-05 |\n",
      "|    std                | 358           |\n",
      "|    value_loss         | 175           |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42500     |\n",
      "|    time_elapsed       | 178831    |\n",
      "|    total_timesteps    | 4250000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42499     |\n",
      "|    policy_loss        | -1.61e+03 |\n",
      "|    reward             | -0.000318 |\n",
      "|    std                | 359       |\n",
      "|    value_loss         | 598       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 42600    |\n",
      "|    time_elapsed       | 179249   |\n",
      "|    total_timesteps    | 4260000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42599    |\n",
      "|    policy_loss        | -749     |\n",
      "|    reward             | 3.533534 |\n",
      "|    std                | 359      |\n",
      "|    value_loss         | 264      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42700     |\n",
      "|    time_elapsed       | 179667    |\n",
      "|    total_timesteps    | 4270000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42699     |\n",
      "|    policy_loss        | 56.4      |\n",
      "|    reward             | -0.001809 |\n",
      "|    std                | 361       |\n",
      "|    value_loss         | 0.807     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42800     |\n",
      "|    time_elapsed       | 180087    |\n",
      "|    total_timesteps    | 4280000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73       |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42799     |\n",
      "|    policy_loss        | 75.9      |\n",
      "|    reward             | -0.000155 |\n",
      "|    std                | 362       |\n",
      "|    value_loss         | 1.78      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42900     |\n",
      "|    time_elapsed       | 180504    |\n",
      "|    total_timesteps    | 4290000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42899     |\n",
      "|    policy_loss        | -686      |\n",
      "|    reward             | -0.003842 |\n",
      "|    std                | 363       |\n",
      "|    value_loss         | 103       |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 43000          |\n",
      "|    time_elapsed       | 180922         |\n",
      "|    total_timesteps    | 4300000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -73.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 42999          |\n",
      "|    policy_loss        | 123            |\n",
      "|    reward             | -0.00013399997 |\n",
      "|    std                | 364            |\n",
      "|    value_loss         | 5.57           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43100     |\n",
      "|    time_elapsed       | 181342    |\n",
      "|    total_timesteps    | 4310000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43099     |\n",
      "|    policy_loss        | 372       |\n",
      "|    reward             | -0.001194 |\n",
      "|    std                | 364       |\n",
      "|    value_loss         | 38.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43200     |\n",
      "|    time_elapsed       | 181762    |\n",
      "|    total_timesteps    | 4320000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.1     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43199     |\n",
      "|    policy_loss        | 684       |\n",
      "|    reward             | -0.002333 |\n",
      "|    std                | 366       |\n",
      "|    value_loss         | 99.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43300     |\n",
      "|    time_elapsed       | 182181    |\n",
      "|    total_timesteps    | 4330000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43299     |\n",
      "|    policy_loss        | -581      |\n",
      "|    reward             | -0.001846 |\n",
      "|    std                | 367       |\n",
      "|    value_loss         | 154       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43400     |\n",
      "|    time_elapsed       | 182599    |\n",
      "|    total_timesteps    | 4340000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43399     |\n",
      "|    policy_loss        | -277      |\n",
      "|    reward             | -0.002555 |\n",
      "|    std                | 366       |\n",
      "|    value_loss         | 79.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43500     |\n",
      "|    time_elapsed       | 183016    |\n",
      "|    total_timesteps    | 4350000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43499     |\n",
      "|    policy_loss        | 114       |\n",
      "|    reward             | -0.391108 |\n",
      "|    std                | 371       |\n",
      "|    value_loss         | 7.63      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43600     |\n",
      "|    time_elapsed       | 183432    |\n",
      "|    total_timesteps    | 4360000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43599     |\n",
      "|    policy_loss        | 396       |\n",
      "|    reward             | -2.327085 |\n",
      "|    std                | 373       |\n",
      "|    value_loss         | 37.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43700     |\n",
      "|    time_elapsed       | 183857    |\n",
      "|    total_timesteps    | 4370000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43699     |\n",
      "|    policy_loss        | 22.7      |\n",
      "|    reward             | -0.004833 |\n",
      "|    std                | 375       |\n",
      "|    value_loss         | 0.301     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43800     |\n",
      "|    time_elapsed       | 184283    |\n",
      "|    total_timesteps    | 4380000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43799     |\n",
      "|    policy_loss        | -202      |\n",
      "|    reward             | -0.002127 |\n",
      "|    std                | 377       |\n",
      "|    value_loss         | 28.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43900     |\n",
      "|    time_elapsed       | 184709    |\n",
      "|    total_timesteps    | 4390000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43899     |\n",
      "|    policy_loss        | 99.5      |\n",
      "|    reward             | -0.003301 |\n",
      "|    std                | 377       |\n",
      "|    value_loss         | 8.72      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44000     |\n",
      "|    time_elapsed       | 185135    |\n",
      "|    total_timesteps    | 4400000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43999     |\n",
      "|    policy_loss        | -55.6     |\n",
      "|    reward             | -0.001417 |\n",
      "|    std                | 378       |\n",
      "|    value_loss         | 7.86      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44100     |\n",
      "|    time_elapsed       | 185559    |\n",
      "|    total_timesteps    | 4410000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44099     |\n",
      "|    policy_loss        | -366      |\n",
      "|    reward             | -0.002326 |\n",
      "|    std                | 376       |\n",
      "|    value_loss         | 50        |\n",
      "-------------------------------------\n",
      "Moment: 74871, episode: 60\n",
      "begin_total_asset: -1460096123.98\n",
      "end_total_asset: -1215769.08\n",
      "total_reward: -1315769.08\n",
      "total_trades: 366225\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 44200          |\n",
      "|    time_elapsed       | 185983         |\n",
      "|    total_timesteps    | 4420000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -73.4          |\n",
      "|    explained_variance | 1.79e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 44199          |\n",
      "|    policy_loss        | -111           |\n",
      "|    reward             | -0.00012900001 |\n",
      "|    std                | 378            |\n",
      "|    value_loss         | 2.92           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44300     |\n",
      "|    time_elapsed       | 186408    |\n",
      "|    total_timesteps    | 4430000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44299     |\n",
      "|    policy_loss        | 36.1      |\n",
      "|    reward             | -0.003564 |\n",
      "|    std                | 381       |\n",
      "|    value_loss         | 0.672     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 44400    |\n",
      "|    time_elapsed       | 186835   |\n",
      "|    total_timesteps    | 4440000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44399    |\n",
      "|    policy_loss        | -103     |\n",
      "|    reward             | -0.00143 |\n",
      "|    std                | 382      |\n",
      "|    value_loss         | 6.8      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44500     |\n",
      "|    time_elapsed       | 187260    |\n",
      "|    total_timesteps    | 4450000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44499     |\n",
      "|    policy_loss        | 558       |\n",
      "|    reward             | -0.000228 |\n",
      "|    std                | 384       |\n",
      "|    value_loss         | 90.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44600     |\n",
      "|    time_elapsed       | 187685    |\n",
      "|    total_timesteps    | 4460000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44599     |\n",
      "|    policy_loss        | -205      |\n",
      "|    reward             | -0.001337 |\n",
      "|    std                | 383       |\n",
      "|    value_loss         | 15.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44700     |\n",
      "|    time_elapsed       | 188111    |\n",
      "|    total_timesteps    | 4470000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44699     |\n",
      "|    policy_loss        | -106      |\n",
      "|    reward             | -0.001336 |\n",
      "|    std                | 385       |\n",
      "|    value_loss         | 18.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44800     |\n",
      "|    time_elapsed       | 188537    |\n",
      "|    total_timesteps    | 4480000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44799     |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | -0.001707 |\n",
      "|    std                | 385       |\n",
      "|    value_loss         | 107       |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 44900          |\n",
      "|    time_elapsed       | 188960         |\n",
      "|    total_timesteps    | 4490000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -73.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 44899          |\n",
      "|    policy_loss        | 2.49e+03       |\n",
      "|    reward             | -0.00014699998 |\n",
      "|    std                | 387            |\n",
      "|    value_loss         | 1.25e+03       |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 45000    |\n",
      "|    time_elapsed       | 189383   |\n",
      "|    total_timesteps    | 4500000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44999    |\n",
      "|    policy_loss        | 150      |\n",
      "|    reward             | 0.220455 |\n",
      "|    std                | 389      |\n",
      "|    value_loss         | 6.46     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 45100     |\n",
      "|    time_elapsed       | 189807    |\n",
      "|    total_timesteps    | 4510000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.7     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45099     |\n",
      "|    policy_loss        | -157      |\n",
      "|    reward             | -1.493008 |\n",
      "|    std                | 390       |\n",
      "|    value_loss         | 9.68      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 45200     |\n",
      "|    time_elapsed       | 190231    |\n",
      "|    total_timesteps    | 4520000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45199     |\n",
      "|    policy_loss        | -198      |\n",
      "|    reward             | -0.000324 |\n",
      "|    std                | 391       |\n",
      "|    value_loss         | 13.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 45300     |\n",
      "|    time_elapsed       | 190657    |\n",
      "|    total_timesteps    | 4530000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45299     |\n",
      "|    policy_loss        | 48.3      |\n",
      "|    reward             | -0.001289 |\n",
      "|    std                | 393       |\n",
      "|    value_loss         | 26.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 45400    |\n",
      "|    time_elapsed       | 191079   |\n",
      "|    total_timesteps    | 4540000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45399    |\n",
      "|    policy_loss        | 194      |\n",
      "|    reward             | -0.00049 |\n",
      "|    std                | 393      |\n",
      "|    value_loss         | 38.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 45500     |\n",
      "|    time_elapsed       | 191497    |\n",
      "|    total_timesteps    | 4550000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45499     |\n",
      "|    policy_loss        | -571      |\n",
      "|    reward             | -0.000638 |\n",
      "|    std                | 394       |\n",
      "|    value_loss         | 86.1      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 45600          |\n",
      "|    time_elapsed       | 191913         |\n",
      "|    total_timesteps    | 4560000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -73.9          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 45599          |\n",
      "|    policy_loss        | 250            |\n",
      "|    reward             | -0.00033200003 |\n",
      "|    std                | 395            |\n",
      "|    value_loss         | 78.9           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 45700     |\n",
      "|    time_elapsed       | 192330    |\n",
      "|    total_timesteps    | 4570000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45699     |\n",
      "|    policy_loss        | 80.4      |\n",
      "|    reward             | -0.003246 |\n",
      "|    std                | 397       |\n",
      "|    value_loss         | 1.83      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 45800    |\n",
      "|    time_elapsed       | 192746   |\n",
      "|    total_timesteps    | 4580000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45799    |\n",
      "|    policy_loss        | -4.75    |\n",
      "|    reward             | 0.34935  |\n",
      "|    std                | 398      |\n",
      "|    value_loss         | 0.621    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 45900    |\n",
      "|    time_elapsed       | 193162   |\n",
      "|    total_timesteps    | 4590000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45899    |\n",
      "|    policy_loss        | -448     |\n",
      "|    reward             | -0.00018 |\n",
      "|    std                | 397      |\n",
      "|    value_loss         | 52.8     |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 46000         |\n",
      "|    time_elapsed       | 193579        |\n",
      "|    total_timesteps    | 4600000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -74           |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 45999         |\n",
      "|    policy_loss        | -82.9         |\n",
      "|    reward             | -0.0019339999 |\n",
      "|    std                | 399           |\n",
      "|    value_loss         | 18.8          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46100     |\n",
      "|    time_elapsed       | 193997    |\n",
      "|    total_timesteps    | 4610000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46099     |\n",
      "|    policy_loss        | -127      |\n",
      "|    reward             | -0.001213 |\n",
      "|    std                | 400       |\n",
      "|    value_loss         | 12.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46200     |\n",
      "|    time_elapsed       | 194414    |\n",
      "|    total_timesteps    | 4620000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46199     |\n",
      "|    policy_loss        | -874      |\n",
      "|    reward             | 0.765276  |\n",
      "|    std                | 399       |\n",
      "|    value_loss         | 198       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46300     |\n",
      "|    time_elapsed       | 194833    |\n",
      "|    total_timesteps    | 4630000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46299     |\n",
      "|    policy_loss        | 166       |\n",
      "|    reward             | -0.000302 |\n",
      "|    std                | 399       |\n",
      "|    value_loss         | 25.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46400     |\n",
      "|    time_elapsed       | 195250    |\n",
      "|    total_timesteps    | 4640000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46399     |\n",
      "|    policy_loss        | -1.05e+03 |\n",
      "|    reward             | -0.00245  |\n",
      "|    std                | 399       |\n",
      "|    value_loss         | 1.11e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 46500    |\n",
      "|    time_elapsed       | 195669   |\n",
      "|    total_timesteps    | 4650000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46499    |\n",
      "|    policy_loss        | -210     |\n",
      "|    reward             | 0.642493 |\n",
      "|    std                | 403      |\n",
      "|    value_loss         | 16.2     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 46600          |\n",
      "|    time_elapsed       | 196087         |\n",
      "|    total_timesteps    | 4660000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -74.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 46599          |\n",
      "|    policy_loss        | -127           |\n",
      "|    reward             | -5.0000006e-05 |\n",
      "|    std                | 404            |\n",
      "|    value_loss         | 9.92           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 46700    |\n",
      "|    time_elapsed       | 196504   |\n",
      "|    total_timesteps    | 4670000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46699    |\n",
      "|    policy_loss        | 197      |\n",
      "|    reward             | -0.00272 |\n",
      "|    std                | 406      |\n",
      "|    value_loss         | 16.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 46800    |\n",
      "|    time_elapsed       | 196920   |\n",
      "|    total_timesteps    | 4680000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46799    |\n",
      "|    policy_loss        | 18       |\n",
      "|    reward             | 0.486487 |\n",
      "|    std                | 407      |\n",
      "|    value_loss         | 54       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46900     |\n",
      "|    time_elapsed       | 197336    |\n",
      "|    total_timesteps    | 4690000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46899     |\n",
      "|    policy_loss        | 249       |\n",
      "|    reward             | -0.004002 |\n",
      "|    std                | 407       |\n",
      "|    value_loss         | 16.8      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 47000         |\n",
      "|    time_elapsed       | 197752        |\n",
      "|    total_timesteps    | 4700000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -74.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 46999         |\n",
      "|    policy_loss        | 503           |\n",
      "|    reward             | -0.0028259999 |\n",
      "|    std                | 408           |\n",
      "|    value_loss         | 241           |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 47100          |\n",
      "|    time_elapsed       | 198167         |\n",
      "|    total_timesteps    | 4710000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -74.2          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 47099          |\n",
      "|    policy_loss        | -220           |\n",
      "|    reward             | -3.2000018e-05 |\n",
      "|    std                | 409            |\n",
      "|    value_loss         | 78.5           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 47200    |\n",
      "|    time_elapsed       | 198582   |\n",
      "|    total_timesteps    | 4720000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47199    |\n",
      "|    policy_loss        | -116     |\n",
      "|    reward             | 0.004542 |\n",
      "|    std                | 411      |\n",
      "|    value_loss         | 2.56     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47300     |\n",
      "|    time_elapsed       | 199000    |\n",
      "|    total_timesteps    | 4730000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.3     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47299     |\n",
      "|    policy_loss        | 185       |\n",
      "|    reward             | -0.004617 |\n",
      "|    std                | 412       |\n",
      "|    value_loss         | 10.7      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 47400          |\n",
      "|    time_elapsed       | 199416         |\n",
      "|    total_timesteps    | 4740000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -74.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 47399          |\n",
      "|    policy_loss        | -119           |\n",
      "|    reward             | -3.1999993e-05 |\n",
      "|    std                | 414            |\n",
      "|    value_loss         | 6.51           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 47500    |\n",
      "|    time_elapsed       | 199832   |\n",
      "|    total_timesteps    | 4750000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47499    |\n",
      "|    policy_loss        | 304      |\n",
      "|    reward             | 0.420257 |\n",
      "|    std                | 414      |\n",
      "|    value_loss         | 52.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47600     |\n",
      "|    time_elapsed       | 200249    |\n",
      "|    total_timesteps    | 4760000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47599     |\n",
      "|    policy_loss        | -2.16e+03 |\n",
      "|    reward             | -0.001849 |\n",
      "|    std                | 415       |\n",
      "|    value_loss         | 882       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47700     |\n",
      "|    time_elapsed       | 200664    |\n",
      "|    total_timesteps    | 4770000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47699     |\n",
      "|    policy_loss        | -12.6     |\n",
      "|    reward             | -0.000118 |\n",
      "|    std                | 415       |\n",
      "|    value_loss         | 6.84      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47800     |\n",
      "|    time_elapsed       | 201082    |\n",
      "|    total_timesteps    | 4780000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47799     |\n",
      "|    policy_loss        | 57.2      |\n",
      "|    reward             | -0.001362 |\n",
      "|    std                | 414       |\n",
      "|    value_loss         | 68.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47900     |\n",
      "|    time_elapsed       | 201510    |\n",
      "|    total_timesteps    | 4790000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47899     |\n",
      "|    policy_loss        | 582       |\n",
      "|    reward             | -0.000443 |\n",
      "|    std                | 416       |\n",
      "|    value_loss         | 194       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 48000    |\n",
      "|    time_elapsed       | 201938   |\n",
      "|    total_timesteps    | 4800000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47999    |\n",
      "|    policy_loss        | 72.9     |\n",
      "|    reward             | 0.896814 |\n",
      "|    std                | 418      |\n",
      "|    value_loss         | 1.12     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48100     |\n",
      "|    time_elapsed       | 202363    |\n",
      "|    total_timesteps    | 4810000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48099     |\n",
      "|    policy_loss        | 339       |\n",
      "|    reward             | -0.000175 |\n",
      "|    std                | 420       |\n",
      "|    value_loss         | 24.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48200     |\n",
      "|    time_elapsed       | 202794    |\n",
      "|    total_timesteps    | 4820000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48199     |\n",
      "|    policy_loss        | -284      |\n",
      "|    reward             | -0.001779 |\n",
      "|    std                | 422       |\n",
      "|    value_loss         | 21.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48300     |\n",
      "|    time_elapsed       | 203220    |\n",
      "|    total_timesteps    | 4830000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48299     |\n",
      "|    policy_loss        | -159      |\n",
      "|    reward             | -0.004919 |\n",
      "|    std                | 424       |\n",
      "|    value_loss         | 10.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48400     |\n",
      "|    time_elapsed       | 203645    |\n",
      "|    total_timesteps    | 4840000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48399     |\n",
      "|    policy_loss        | -226      |\n",
      "|    reward             | -0.000874 |\n",
      "|    std                | 425       |\n",
      "|    value_loss         | 14.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48500     |\n",
      "|    time_elapsed       | 204073    |\n",
      "|    total_timesteps    | 4850000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48499     |\n",
      "|    policy_loss        | -1.07e+03 |\n",
      "|    reward             | -0.003462 |\n",
      "|    std                | 427       |\n",
      "|    value_loss         | 361       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48600     |\n",
      "|    time_elapsed       | 204489    |\n",
      "|    total_timesteps    | 4860000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48599     |\n",
      "|    policy_loss        | -100      |\n",
      "|    reward             | -0.003588 |\n",
      "|    std                | 427       |\n",
      "|    value_loss         | 56.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48700     |\n",
      "|    time_elapsed       | 204905    |\n",
      "|    total_timesteps    | 4870000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48699     |\n",
      "|    policy_loss        | 3.31      |\n",
      "|    reward             | -1.095035 |\n",
      "|    std                | 428       |\n",
      "|    value_loss         | 0.301     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48800     |\n",
      "|    time_elapsed       | 205321    |\n",
      "|    total_timesteps    | 4880000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48799     |\n",
      "|    policy_loss        | -51.9     |\n",
      "|    reward             | -0.003228 |\n",
      "|    std                | 430       |\n",
      "|    value_loss         | 1.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48900     |\n",
      "|    time_elapsed       | 205737    |\n",
      "|    total_timesteps    | 4890000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48899     |\n",
      "|    policy_loss        | -340      |\n",
      "|    reward             | 2.021815  |\n",
      "|    std                | 430       |\n",
      "|    value_loss         | 26.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49000     |\n",
      "|    time_elapsed       | 206153    |\n",
      "|    total_timesteps    | 4900000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48999     |\n",
      "|    policy_loss        | 224       |\n",
      "|    reward             | -0.001191 |\n",
      "|    std                | 430       |\n",
      "|    value_loss         | 11.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49100     |\n",
      "|    time_elapsed       | 206569    |\n",
      "|    total_timesteps    | 4910000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49099     |\n",
      "|    policy_loss        | 262       |\n",
      "|    reward             | -1.165292 |\n",
      "|    std                | 431       |\n",
      "|    value_loss         | 96.3      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 49200          |\n",
      "|    time_elapsed       | 206985         |\n",
      "|    total_timesteps    | 4920000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -74.8          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 49199          |\n",
      "|    policy_loss        | -753           |\n",
      "|    reward             | -2.1999978e-05 |\n",
      "|    std                | 431            |\n",
      "|    value_loss         | 321            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49300     |\n",
      "|    time_elapsed       | 207401    |\n",
      "|    total_timesteps    | 4930000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49299     |\n",
      "|    policy_loss        | 213       |\n",
      "|    reward             | -0.000247 |\n",
      "|    std                | 432       |\n",
      "|    value_loss         | 18.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49400     |\n",
      "|    time_elapsed       | 207814    |\n",
      "|    total_timesteps    | 4940000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49399     |\n",
      "|    policy_loss        | -400      |\n",
      "|    reward             | -0.000247 |\n",
      "|    std                | 432       |\n",
      "|    value_loss         | 73.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49500     |\n",
      "|    time_elapsed       | 208231    |\n",
      "|    total_timesteps    | 4950000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49499     |\n",
      "|    policy_loss        | -96.1     |\n",
      "|    reward             | -0.001179 |\n",
      "|    std                | 435       |\n",
      "|    value_loss         | 3.64      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 49600          |\n",
      "|    time_elapsed       | 208647         |\n",
      "|    total_timesteps    | 4960000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -74.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 49599          |\n",
      "|    policy_loss        | -91.9          |\n",
      "|    reward             | -0.00022999999 |\n",
      "|    std                | 436            |\n",
      "|    value_loss         | 8.24           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49700     |\n",
      "|    time_elapsed       | 209063    |\n",
      "|    total_timesteps    | 4970000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49699     |\n",
      "|    policy_loss        | 35        |\n",
      "|    reward             | -0.001806 |\n",
      "|    std                | 438       |\n",
      "|    value_loss         | 9.06      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49800     |\n",
      "|    time_elapsed       | 209479    |\n",
      "|    total_timesteps    | 4980000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75       |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49799     |\n",
      "|    policy_loss        | 716       |\n",
      "|    reward             | -0.000775 |\n",
      "|    std                | 441       |\n",
      "|    value_loss         | 136       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49900     |\n",
      "|    time_elapsed       | 209894    |\n",
      "|    total_timesteps    | 4990000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75       |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49899     |\n",
      "|    policy_loss        | 106       |\n",
      "|    reward             | -0.001563 |\n",
      "|    std                | 441       |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50000     |\n",
      "|    time_elapsed       | 210310    |\n",
      "|    total_timesteps    | 5000000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49999     |\n",
      "|    policy_loss        | -2.03e+03 |\n",
      "|    reward             | -0.003731 |\n",
      "|    std                | 442       |\n",
      "|    value_loss         | 879       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50100     |\n",
      "|    time_elapsed       | 210725    |\n",
      "|    total_timesteps    | 5010000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50099     |\n",
      "|    policy_loss        | -583      |\n",
      "|    reward             | -0.002724 |\n",
      "|    std                | 442       |\n",
      "|    value_loss         | 243       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 50200    |\n",
      "|    time_elapsed       | 211139   |\n",
      "|    total_timesteps    | 5020000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50199    |\n",
      "|    policy_loss        | -47.7    |\n",
      "|    reward             | 0.071949 |\n",
      "|    std                | 445      |\n",
      "|    value_loss         | 0.638    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50300     |\n",
      "|    time_elapsed       | 211555    |\n",
      "|    total_timesteps    | 5030000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50299     |\n",
      "|    policy_loss        | -209      |\n",
      "|    reward             | -0.187764 |\n",
      "|    std                | 447       |\n",
      "|    value_loss         | 38        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50400     |\n",
      "|    time_elapsed       | 211971    |\n",
      "|    total_timesteps    | 5040000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50399     |\n",
      "|    policy_loss        | 600       |\n",
      "|    reward             | -0.000858 |\n",
      "|    std                | 448       |\n",
      "|    value_loss         | 100       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50500     |\n",
      "|    time_elapsed       | 212387    |\n",
      "|    total_timesteps    | 5050000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50499     |\n",
      "|    policy_loss        | -85.6     |\n",
      "|    reward             | -0.000433 |\n",
      "|    std                | 449       |\n",
      "|    value_loss         | 20.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 50600    |\n",
      "|    time_elapsed       | 212802   |\n",
      "|    total_timesteps    | 5060000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50599    |\n",
      "|    policy_loss        | -297     |\n",
      "|    reward             | 0.628005 |\n",
      "|    std                | 449      |\n",
      "|    value_loss         | 82.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50700     |\n",
      "|    time_elapsed       | 213218    |\n",
      "|    total_timesteps    | 5070000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50699     |\n",
      "|    policy_loss        | -336      |\n",
      "|    reward             | -0.000519 |\n",
      "|    std                | 449       |\n",
      "|    value_loss         | 22.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50800     |\n",
      "|    time_elapsed       | 213634    |\n",
      "|    total_timesteps    | 5080000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50799     |\n",
      "|    policy_loss        | -103      |\n",
      "|    reward             | -0.001529 |\n",
      "|    std                | 450       |\n",
      "|    value_loss         | 34.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50900     |\n",
      "|    time_elapsed       | 214048    |\n",
      "|    total_timesteps    | 5090000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50899     |\n",
      "|    policy_loss        | 657       |\n",
      "|    reward             | -3.902802 |\n",
      "|    std                | 452       |\n",
      "|    value_loss         | 93.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51000     |\n",
      "|    time_elapsed       | 214464    |\n",
      "|    total_timesteps    | 5100000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50999     |\n",
      "|    policy_loss        | -14       |\n",
      "|    reward             | -0.257969 |\n",
      "|    std                | 455       |\n",
      "|    value_loss         | 0.54      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51100     |\n",
      "|    time_elapsed       | 214880    |\n",
      "|    total_timesteps    | 5110000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51099     |\n",
      "|    policy_loss        | 37.9      |\n",
      "|    reward             | -0.000587 |\n",
      "|    std                | 454       |\n",
      "|    value_loss         | 4.13      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 51200          |\n",
      "|    time_elapsed       | 215297         |\n",
      "|    total_timesteps    | 5120000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 51199          |\n",
      "|    policy_loss        | 515            |\n",
      "|    reward             | -1.6000009e-05 |\n",
      "|    std                | 453            |\n",
      "|    value_loss         | 58.2           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 51300          |\n",
      "|    time_elapsed       | 215712         |\n",
      "|    total_timesteps    | 5130000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 51299          |\n",
      "|    policy_loss        | 271            |\n",
      "|    reward             | -0.00016000001 |\n",
      "|    std                | 455            |\n",
      "|    value_loss         | 38.1           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 51400          |\n",
      "|    time_elapsed       | 216128         |\n",
      "|    total_timesteps    | 5140000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.3          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 51399          |\n",
      "|    policy_loss        | 773            |\n",
      "|    reward             | -0.00069400005 |\n",
      "|    std                | 457            |\n",
      "|    value_loss         | 171            |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 51500          |\n",
      "|    time_elapsed       | 216544         |\n",
      "|    total_timesteps    | 5150000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.4          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 51499          |\n",
      "|    policy_loss        | -1.11e+03      |\n",
      "|    reward             | -5.6999994e-05 |\n",
      "|    std                | 457            |\n",
      "|    value_loss         | 340            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51600     |\n",
      "|    time_elapsed       | 216960    |\n",
      "|    total_timesteps    | 5160000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51599     |\n",
      "|    policy_loss        | -1.49e+03 |\n",
      "|    reward             | -0.003128 |\n",
      "|    std                | 460       |\n",
      "|    value_loss         | 622       |\n",
      "-------------------------------------\n",
      "Moment: 74871, episode: 70\n",
      "begin_total_asset: -1570104550.72\n",
      "end_total_asset: -1323170.89\n",
      "total_reward: -1423170.89\n",
      "total_trades: 367500\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 51700    |\n",
      "|    time_elapsed       | 217374   |\n",
      "|    total_timesteps    | 5170000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 51699    |\n",
      "|    policy_loss        | -37.6    |\n",
      "|    reward             | 0.052194 |\n",
      "|    std                | 461      |\n",
      "|    value_loss         | 0.581    |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 51800          |\n",
      "|    time_elapsed       | 217789         |\n",
      "|    total_timesteps    | 5180000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.5          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 51799          |\n",
      "|    policy_loss        | 90.5           |\n",
      "|    reward             | -0.00017300001 |\n",
      "|    std                | 464            |\n",
      "|    value_loss         | 10.2           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51900     |\n",
      "|    time_elapsed       | 218204    |\n",
      "|    total_timesteps    | 5190000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51899     |\n",
      "|    policy_loss        | -442      |\n",
      "|    reward             | -1.948951 |\n",
      "|    std                | 467       |\n",
      "|    value_loss         | 64.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52000     |\n",
      "|    time_elapsed       | 218620    |\n",
      "|    total_timesteps    | 5200000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51999     |\n",
      "|    policy_loss        | 130       |\n",
      "|    reward             | -0.000569 |\n",
      "|    std                | 468       |\n",
      "|    value_loss         | 8.91      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52100     |\n",
      "|    time_elapsed       | 219036    |\n",
      "|    total_timesteps    | 5210000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.6     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52099     |\n",
      "|    policy_loss        | 501       |\n",
      "|    reward             | -0.003018 |\n",
      "|    std                | 467       |\n",
      "|    value_loss         | 57.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52200     |\n",
      "|    time_elapsed       | 219452    |\n",
      "|    total_timesteps    | 5220000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52199     |\n",
      "|    policy_loss        | -129      |\n",
      "|    reward             | -0.004259 |\n",
      "|    std                | 470       |\n",
      "|    value_loss         | 24.6      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 52300          |\n",
      "|    time_elapsed       | 219867         |\n",
      "|    total_timesteps    | 5230000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 52299          |\n",
      "|    policy_loss        | -2.56          |\n",
      "|    reward             | -0.00023699999 |\n",
      "|    std                | 470            |\n",
      "|    value_loss         | 112            |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 52400          |\n",
      "|    time_elapsed       | 220283         |\n",
      "|    total_timesteps    | 5240000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 52399          |\n",
      "|    policy_loss        | 325            |\n",
      "|    reward             | -4.3000007e-05 |\n",
      "|    std                | 470            |\n",
      "|    value_loss         | 66.2           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52500     |\n",
      "|    time_elapsed       | 220698    |\n",
      "|    total_timesteps    | 5250000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52499     |\n",
      "|    policy_loss        | -258      |\n",
      "|    reward             | -0.128879 |\n",
      "|    std                | 473       |\n",
      "|    value_loss         | 13.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52600     |\n",
      "|    time_elapsed       | 221113    |\n",
      "|    total_timesteps    | 5260000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52599     |\n",
      "|    policy_loss        | 150       |\n",
      "|    reward             | -0.002531 |\n",
      "|    std                | 475       |\n",
      "|    value_loss         | 5.16      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52700     |\n",
      "|    time_elapsed       | 221529    |\n",
      "|    total_timesteps    | 5270000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52699     |\n",
      "|    policy_loss        | -373      |\n",
      "|    reward             | -0.003518 |\n",
      "|    std                | 477       |\n",
      "|    value_loss         | 39.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52800     |\n",
      "|    time_elapsed       | 221945    |\n",
      "|    total_timesteps    | 5280000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52799     |\n",
      "|    policy_loss        | 101       |\n",
      "|    reward             | -0.003635 |\n",
      "|    std                | 475       |\n",
      "|    value_loss         | 9.66      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52900     |\n",
      "|    time_elapsed       | 222359    |\n",
      "|    total_timesteps    | 5290000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52899     |\n",
      "|    policy_loss        | 712       |\n",
      "|    reward             | -0.003321 |\n",
      "|    std                | 476       |\n",
      "|    value_loss         | 116       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53000     |\n",
      "|    time_elapsed       | 222776    |\n",
      "|    total_timesteps    | 5300000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52999     |\n",
      "|    policy_loss        | 227       |\n",
      "|    reward             | -0.001885 |\n",
      "|    std                | 475       |\n",
      "|    value_loss         | 40.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53100     |\n",
      "|    time_elapsed       | 223192    |\n",
      "|    total_timesteps    | 5310000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53099     |\n",
      "|    policy_loss        | -549      |\n",
      "|    reward             | -0.003307 |\n",
      "|    std                | 476       |\n",
      "|    value_loss         | 130       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 53200    |\n",
      "|    time_elapsed       | 223606   |\n",
      "|    total_timesteps    | 5320000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53199    |\n",
      "|    policy_loss        | -1.85    |\n",
      "|    reward             | -6.9e-05 |\n",
      "|    std                | 477      |\n",
      "|    value_loss         | 0.0852   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53300     |\n",
      "|    time_elapsed       | 224022    |\n",
      "|    total_timesteps    | 5330000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53299     |\n",
      "|    policy_loss        | 96        |\n",
      "|    reward             | -0.004404 |\n",
      "|    std                | 480       |\n",
      "|    value_loss         | 4.1       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53400     |\n",
      "|    time_elapsed       | 224438    |\n",
      "|    total_timesteps    | 5340000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53399     |\n",
      "|    policy_loss        | -666      |\n",
      "|    reward             | -0.000684 |\n",
      "|    std                | 479       |\n",
      "|    value_loss         | 91.1      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 53500          |\n",
      "|    time_elapsed       | 224856         |\n",
      "|    total_timesteps    | 5350000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.9          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 53499          |\n",
      "|    policy_loss        | -897           |\n",
      "|    reward             | -0.00017199999 |\n",
      "|    std                | 481            |\n",
      "|    value_loss         | 165            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53600     |\n",
      "|    time_elapsed       | 225271    |\n",
      "|    total_timesteps    | 5360000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53599     |\n",
      "|    policy_loss        | -761      |\n",
      "|    reward             | -0.000653 |\n",
      "|    std                | 482       |\n",
      "|    value_loss         | 126       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53700     |\n",
      "|    time_elapsed       | 225688    |\n",
      "|    total_timesteps    | 5370000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53699     |\n",
      "|    policy_loss        | 1.16e+03  |\n",
      "|    reward             | -0.001768 |\n",
      "|    std                | 483       |\n",
      "|    value_loss         | 274       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53800     |\n",
      "|    time_elapsed       | 226105    |\n",
      "|    total_timesteps    | 5380000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53799     |\n",
      "|    policy_loss        | 164       |\n",
      "|    reward             | -0.002534 |\n",
      "|    std                | 482       |\n",
      "|    value_loss         | 33.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53900     |\n",
      "|    time_elapsed       | 226520    |\n",
      "|    total_timesteps    | 5390000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.9     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53899     |\n",
      "|    policy_loss        | -251      |\n",
      "|    reward             | -0.004015 |\n",
      "|    std                | 482       |\n",
      "|    value_loss         | 34.4      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 54000          |\n",
      "|    time_elapsed       | 226936         |\n",
      "|    total_timesteps    | 5400000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -76            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 53999          |\n",
      "|    policy_loss        | -41            |\n",
      "|    reward             | -8.8999994e-05 |\n",
      "|    std                | 485            |\n",
      "|    value_loss         | 10.6           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 54100    |\n",
      "|    time_elapsed       | 227353   |\n",
      "|    total_timesteps    | 5410000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54099    |\n",
      "|    policy_loss        | -432     |\n",
      "|    reward             | 0.302501 |\n",
      "|    std                | 488      |\n",
      "|    value_loss         | 44.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54200     |\n",
      "|    time_elapsed       | 227768    |\n",
      "|    total_timesteps    | 5420000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54199     |\n",
      "|    policy_loss        | 35.2      |\n",
      "|    reward             | -0.002935 |\n",
      "|    std                | 490       |\n",
      "|    value_loss         | 0.776     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54300     |\n",
      "|    time_elapsed       | 228184    |\n",
      "|    total_timesteps    | 5430000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.1     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54299     |\n",
      "|    policy_loss        | -240      |\n",
      "|    reward             | -0.003902 |\n",
      "|    std                | 491       |\n",
      "|    value_loss         | 52.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54400     |\n",
      "|    time_elapsed       | 228601    |\n",
      "|    total_timesteps    | 5440000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54399     |\n",
      "|    policy_loss        | -391      |\n",
      "|    reward             | -0.003217 |\n",
      "|    std                | 492       |\n",
      "|    value_loss         | 68.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 54500    |\n",
      "|    time_elapsed       | 229016   |\n",
      "|    total_timesteps    | 5450000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54499    |\n",
      "|    policy_loss        | 783      |\n",
      "|    reward             | 5.558701 |\n",
      "|    std                | 491      |\n",
      "|    value_loss         | 199      |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 54600          |\n",
      "|    time_elapsed       | 229431         |\n",
      "|    total_timesteps    | 5460000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -76.1          |\n",
      "|    explained_variance | 1.79e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 54599          |\n",
      "|    policy_loss        | -100           |\n",
      "|    reward             | -0.00023899999 |\n",
      "|    std                | 493            |\n",
      "|    value_loss         | 13.4           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54700     |\n",
      "|    time_elapsed       | 229847    |\n",
      "|    total_timesteps    | 5470000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54699     |\n",
      "|    policy_loss        | 36        |\n",
      "|    reward             | -0.000251 |\n",
      "|    std                | 495       |\n",
      "|    value_loss         | 0.459     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54800     |\n",
      "|    time_elapsed       | 230262    |\n",
      "|    total_timesteps    | 5480000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54799     |\n",
      "|    policy_loss        | 314       |\n",
      "|    reward             | -0.003601 |\n",
      "|    std                | 497       |\n",
      "|    value_loss         | 25.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 54900    |\n",
      "|    time_elapsed       | 230678   |\n",
      "|    total_timesteps    | 5490000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54899    |\n",
      "|    policy_loss        | -445     |\n",
      "|    reward             | 1.111175 |\n",
      "|    std                | 497      |\n",
      "|    value_loss         | 43.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55000     |\n",
      "|    time_elapsed       | 231095    |\n",
      "|    total_timesteps    | 5500000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54999     |\n",
      "|    policy_loss        | 240       |\n",
      "|    reward             | -0.001162 |\n",
      "|    std                | 498       |\n",
      "|    value_loss         | 21.5      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 55100          |\n",
      "|    time_elapsed       | 231511         |\n",
      "|    total_timesteps    | 5510000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -76.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 55099          |\n",
      "|    policy_loss        | 186            |\n",
      "|    reward             | -4.7000016e-05 |\n",
      "|    std                | 497            |\n",
      "|    value_loss         | 113            |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 55200    |\n",
      "|    time_elapsed       | 231926   |\n",
      "|    total_timesteps    | 5520000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55199    |\n",
      "|    policy_loss        | -126     |\n",
      "|    reward             | -0.00242 |\n",
      "|    std                | 496      |\n",
      "|    value_loss         | 40.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55300     |\n",
      "|    time_elapsed       | 232342    |\n",
      "|    total_timesteps    | 5530000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55299     |\n",
      "|    policy_loss        | 240       |\n",
      "|    reward             | -0.001335 |\n",
      "|    std                | 495       |\n",
      "|    value_loss         | 24.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55400     |\n",
      "|    time_elapsed       | 232758    |\n",
      "|    total_timesteps    | 5540000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55399     |\n",
      "|    policy_loss        | -450      |\n",
      "|    reward             | -0.002525 |\n",
      "|    std                | 496       |\n",
      "|    value_loss         | 160       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55500     |\n",
      "|    time_elapsed       | 233174    |\n",
      "|    total_timesteps    | 5550000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55499     |\n",
      "|    policy_loss        | -157      |\n",
      "|    reward             | -0.000419 |\n",
      "|    std                | 500       |\n",
      "|    value_loss         | 11.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55600     |\n",
      "|    time_elapsed       | 233591    |\n",
      "|    total_timesteps    | 5560000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55599     |\n",
      "|    policy_loss        | -101      |\n",
      "|    reward             | -0.004111 |\n",
      "|    std                | 504       |\n",
      "|    value_loss         | 4.53      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 55700          |\n",
      "|    time_elapsed       | 234007         |\n",
      "|    total_timesteps    | 5570000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -76.4          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 55699          |\n",
      "|    policy_loss        | 114            |\n",
      "|    reward             | -0.00015100001 |\n",
      "|    std                | 504            |\n",
      "|    value_loss         | 4.46           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55800     |\n",
      "|    time_elapsed       | 234423    |\n",
      "|    total_timesteps    | 5580000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55799     |\n",
      "|    policy_loss        | -145      |\n",
      "|    reward             | -3.814253 |\n",
      "|    std                | 504       |\n",
      "|    value_loss         | 10.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 55900    |\n",
      "|    time_elapsed       | 234839   |\n",
      "|    total_timesteps    | 5590000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55899    |\n",
      "|    policy_loss        | -89.4    |\n",
      "|    reward             | 0.632814 |\n",
      "|    std                | 505      |\n",
      "|    value_loss         | 32.1     |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 56000         |\n",
      "|    time_elapsed       | 235255        |\n",
      "|    total_timesteps    | 5600000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -76.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 55999         |\n",
      "|    policy_loss        | -2.35e+03     |\n",
      "|    reward             | -0.0018130001 |\n",
      "|    std                | 503           |\n",
      "|    value_loss         | 1.35e+03      |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 56100     |\n",
      "|    time_elapsed       | 235670    |\n",
      "|    total_timesteps    | 5610000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56099     |\n",
      "|    policy_loss        | -1.69e+03 |\n",
      "|    reward             | -0.002128 |\n",
      "|    std                | 503       |\n",
      "|    value_loss         | 639       |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=train.date.unique().shape[0]*75\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c.save('./trained_models/a2cLOB1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c67HYoXYN1vR"
   },
   "source": [
    "###**Trade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pq0Q3iCBNyx2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_daily_return, df_actions = DRL_prediction(model=trained_a2c,environment= e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "N2htLNjQN3gy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2012-06-21T14:41:59.000000000]</td>\n",
       "      <td>100000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2012-06-21T14:41:59.250000000]</td>\n",
       "      <td>99999.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2012-06-21T14:41:59.500000000]</td>\n",
       "      <td>99969.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2012-06-21T14:41:59.750000000]</td>\n",
       "      <td>99961.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2012-06-21T14:42:00.000000000]</td>\n",
       "      <td>99959.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18715</th>\n",
       "      <td>[2012-06-21T15:59:57.750000000]</td>\n",
       "      <td>-136241.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18716</th>\n",
       "      <td>[2012-06-21T15:59:58.000000000]</td>\n",
       "      <td>-133897.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18717</th>\n",
       "      <td>[2012-06-21T15:59:58.250000000]</td>\n",
       "      <td>-113868.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18718</th>\n",
       "      <td>[2012-06-21T15:59:58.500000000]</td>\n",
       "      <td>-111941.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18719</th>\n",
       "      <td>[2012-06-21T15:59:58.750000000]</td>\n",
       "      <td>-172193.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18720 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  date  account_value\n",
       "0      [2012-06-21T14:41:59.000000000]      100000.00\n",
       "1      [2012-06-21T14:41:59.250000000]       99999.30\n",
       "2      [2012-06-21T14:41:59.500000000]       99969.87\n",
       "3      [2012-06-21T14:41:59.750000000]       99961.52\n",
       "4      [2012-06-21T14:42:00.000000000]       99959.94\n",
       "...                                ...            ...\n",
       "18715  [2012-06-21T15:59:57.750000000]     -136241.57\n",
       "18716  [2012-06-21T15:59:58.000000000]     -133897.71\n",
       "18717  [2012-06-21T15:59:58.250000000]     -113868.77\n",
       "18718  [2012-06-21T15:59:58.500000000]     -111941.24\n",
       "18719  [2012-06-21T15:59:58.750000000]     -172193.00\n",
       "\n",
       "[18720 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ImeW9Wwz1RNe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>INTC</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-06-21 14:41:59.000</th>\n",
       "      <td>LB1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>LB1</td>\n",
       "      <td>LB1</td>\n",
       "      <td>LB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 14:41:59.250</th>\n",
       "      <td>LB100</td>\n",
       "      <td>LB100</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>LB100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 14:41:59.500</th>\n",
       "      <td>LB25.0</td>\n",
       "      <td>SS21.0</td>\n",
       "      <td>SS1</td>\n",
       "      <td>SS100</td>\n",
       "      <td>SS73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 14:41:59.750</th>\n",
       "      <td>LB1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SS100</td>\n",
       "      <td>LS100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 14:42:00.000</th>\n",
       "      <td>LB1</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>SS100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 15:59:57.500</th>\n",
       "      <td>LB1</td>\n",
       "      <td>SS100</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>LS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 15:59:57.750</th>\n",
       "      <td>SS100</td>\n",
       "      <td>LB1</td>\n",
       "      <td>LB42.0</td>\n",
       "      <td>SS100</td>\n",
       "      <td>SS100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 15:59:58.000</th>\n",
       "      <td>LB100</td>\n",
       "      <td>SS100</td>\n",
       "      <td>SS100</td>\n",
       "      <td>LB100</td>\n",
       "      <td>LB100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 15:59:58.250</th>\n",
       "      <td>SS1</td>\n",
       "      <td>LB1</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SS42</td>\n",
       "      <td>LB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 15:59:58.500</th>\n",
       "      <td>LB100</td>\n",
       "      <td>LB1</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SB1</td>\n",
       "      <td>LB1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18719 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AAPL    AMZN    GOOG   INTC   MSFT\n",
       "date                                                         \n",
       "2012-06-21 14:41:59.000     LB1     SS1     LB1    LB1    LB1\n",
       "2012-06-21 14:41:59.250   LB100   LB100     LB1    SS1  LB100\n",
       "2012-06-21 14:41:59.500  LB25.0  SS21.0     SS1  SS100   SS73\n",
       "2012-06-21 14:41:59.750     LB1     SS1     LB1  SS100  LS100\n",
       "2012-06-21 14:42:00.000     LB1     LB1     SS1    SS1  SS100\n",
       "...                         ...     ...     ...    ...    ...\n",
       "2012-06-21 15:59:57.500     LB1   SS100     LB1    SS1    LS1\n",
       "2012-06-21 15:59:57.750   SS100     LB1  LB42.0  SS100  SS100\n",
       "2012-06-21 15:59:58.000   LB100   SS100   SS100  LB100  LB100\n",
       "2012-06-21 15:59:58.250     SS1     LB1     LB1   SS42    LB1\n",
       "2012-06-21 15:59:58.500   LB100     LB1     LB1    SB1    LB1\n",
       "\n",
       "[18719 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions\n",
    "#df_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KfL8CF5E1bjl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LB1', 'LB1', 'SS1', ..., 'SS100', 'LB1', 'LB1'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions['GOOG'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3py3WDAhN8Dh"
   },
   "source": [
    "###**BackTest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aKdudIieN6UV"
   },
   "outputs": [],
   "source": [
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from finrl.plot import backtest_plot, convert_daily_return_to_pyfolio_ts, get_daily_return\n",
    "from pyfolio import timeseries\n",
    "import pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "3eOzDmc3HsSr"
   },
   "outputs": [],
   "source": [
    "df_daily_return['date']=pd.DataFrame(np.concatenate(df_daily_return.date.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "fxH88JjNOA5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============A2C Strategy Stats===========\n",
      "Annual return                NaN\n",
      "Cumulative returns     -2.721930\n",
      "Annual volatility      45.626816\n",
      "Sharpe ratio           -0.048493\n",
      "Calmar ratio                 NaN\n",
      "Stability                    NaN\n",
      "Max drawdown           -3.295523\n",
      "Omega ratio             0.855219\n",
      "Sortino ratio          -0.050743\n",
      "Skew                         NaN\n",
      "Kurtosis                     NaN\n",
      "Tail ratio              1.070354\n",
      "Daily value at risk    -5.757219\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelmoez/.local/lib/python3.8/site-packages/empyrical/stats.py:447: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return ending_value ** (1 / num_years) - 1\n",
      "/home/abdelmoez/.local/lib/python3.8/site-packages/empyrical/stats.py:1494: RuntimeWarning: invalid value encountered in log1p\n",
      "  cum_log_returns = np.log1p(returns).cumsum()\n"
     ]
    }
   ],
   "source": [
    "print(\"==============A2C Strategy Stats===========\")\n",
    "perf_stats_all = backtest_stats(df_daily_return)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GPU_DRLinLOB_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
