{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9p3-S92lKExR"
   },
   "source": [
    "#**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BIlu8fyTWLSS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "def rescale_data(data_order, data_message, data_level, time_window=0.1):\n",
    "    start_time = 34201\n",
    "    end_time = 57599\n",
    "    data = np.concatenate((data_message[:-1, 0].reshape([-1, 1]), data_order[1:, :]), axis=1)\n",
    "    data_new = np.empty([int((end_time - start_time) / time_window) + 1, int(4 * data_level)])\n",
    "    time_scale = np.arange(start_time, end_time, time_window)\n",
    "    k = 0\n",
    "    for i in range(time_scale.shape[0]):\n",
    "        while k < data.shape[0] and data[k, 0] < time_scale[i]:\n",
    "            k = k + 1\n",
    "        \n",
    "        data_new[i] = data[k - 1, 1:]\n",
    "\n",
    "    n, m = data_new.shape\n",
    "    for i in range(int(m / 2)):\n",
    "        data_new[:, 2 * i] = data_new[:, 2 * i] / 10000\n",
    "\n",
    "    return data_new,time_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0-_fVQCoMq79"
   },
   "outputs": [],
   "source": [
    "#level_5\n",
    "columns = ['L1_ask_price','L1_ask_quantity','L1_bid_price','L1_bid_quantity','L2_ask_price','L2_ask_quantity','L2_bid_price','L2_bid_quantity','L3_ask_price','L3_ask_quantity','L3_bid_price','L3_bid_quantity','L4_ask_price','L4_ask_quantity','L4_bid_price','L4_bid_quantity','L5_ask_price','L5_ask_quantity','L5_bid_price','L5_bid_quantity']\n",
    "\n",
    "#level_10\n",
    "#columns = ['L1_ask_price','L1_ask_quantity','L1_bid_price','L1_bid_quantity','L2_ask_price','L2_ask_quantity','L2_bid_price','L2_bid_quantity','L3_ask_price','L3_ask_quantity','L3_bid_price','L3_bid_quantity','L4_ask_price','L4_ask_quantity','L4_bid_price','L4_bid_quantity','L5_ask_price','L5_ask_quantity','L5_bid_price','L5_bid_quantity','L6_ask_price','L6_ask_quantity','L6_bid_price','L6_bid_quantity','L7_ask_price','L7_ask_quantity','L7_bid_price','L7_bid_quantity','L8_ask_price','L8_ask_quantity','L8_bid_price','L8_bid_quantity','L9_ask_price','L9_ask_quantity','L9_bid_price','L9_bid_quantity','L10_ask_price','L10_ask_quantity','L10_bid_price','L10_bid_quantity']\n",
    "\n",
    "def get_dataframe(name):\n",
    "  # load the order and message book. We use the level 5 limit order book data.\n",
    "  file_path = './'\n",
    "  data_name = '{}_2012-06-21_34200000_57600000_'.format(name)\n",
    "  data_level = 5\n",
    "  data_order = np.loadtxt(file_path + data_name + 'orderbook_' + str(data_level) + '.csv', delimiter=',')\n",
    "  data_message = np.loadtxt(file_path + data_name + 'message_' + str(data_level) + '.csv', delimiter=',')\n",
    "\n",
    "  # set time window, forecast size, and look back range.\n",
    "  time_window = 0.25\n",
    "\n",
    "  # turn data into evenly spaced, then split the one day dataset into two half day datasets.\n",
    "  evenly_spaced_data,time_scale = rescale_data(data_order, data_message, data_level, time_window)\n",
    "\n",
    "  even_df = pd.DataFrame(evenly_spaced_data,columns=columns)\n",
    "  date  = pd.DataFrame(time_scale,columns=['date'])\n",
    "\n",
    "  #mid = (even_df['L1_ask_price'] + even_df['L1_bid_price']) /2\n",
    "  #mid_price = pd.DataFrame(mid,columns=['mid_price'])\n",
    "\n",
    "  #ask_bid = pd.DataFrame((even_df['L1_ask_price'],even_df['L1_bid_price']),columns=['ask_bid'])\n",
    "  #ask_bid_q = pd.DataFrame((even_df['L1_ask_quantity'],even_df['L1_bid_quantity']),columns=['ask_bid_quantity'])\n",
    "  \n",
    "  #even_df['ask_bid_price'] = list(zip(even_df['L1_ask_price'],even_df['L1_bid_price']))\n",
    "  #even_df['ask_bid_quantity'] = list(zip(even_df['L1_ask_quantity'],even_df['L1_bid_quantity']))\n",
    "  #new_df = even_df[['ask_bid_price','ask_bid_quantity']]\n",
    "  #even_df.drop(['ask_bid_price', 'ask_bid_quantity'], axis=1,inplace=True)\n",
    "\n",
    "  df = pd.concat([date,even_df],axis=1)\n",
    "  df.dropna(inplace=True)\n",
    "  day = '2012-6-21 '\n",
    "  df.date =[(day + str(datetime.timedelta(seconds=i))) for i in df.date.values]\n",
    "  df['date']= pd.to_datetime(df['date'])\n",
    "  df['tic'] = name\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cjSdPb4COOdv"
   },
   "outputs": [],
   "source": [
    "AAPL_df = get_dataframe('AAPL')\n",
    "AMZN_df = get_dataframe('AMZN')\n",
    "GOOG_df = get_dataframe('GOOG')\n",
    "INTC_df = get_dataframe('INTC')\n",
    "MSFT_df = get_dataframe('MSFT')\n",
    "\n",
    "data = pd.concat([AAPL_df,AMZN_df,GOOG_df,INTC_df,MSFT_df], ignore_index=True)\n",
    "\n",
    "data = data.sort_values(['date','tic'],ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IAwU0H5U_74i",
    "outputId": "9a41df38-8760-482d-8790-23cef7500db3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467960, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "lJUJEqLRG7mh",
    "outputId": "ee9a2e2d-08d6-48e8-e69d-7ce1aa068754"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>L1_ask_price</th>\n",
       "      <th>L1_ask_quantity</th>\n",
       "      <th>L1_bid_price</th>\n",
       "      <th>L1_bid_quantity</th>\n",
       "      <th>L2_ask_price</th>\n",
       "      <th>L2_ask_quantity</th>\n",
       "      <th>L2_bid_price</th>\n",
       "      <th>L2_bid_quantity</th>\n",
       "      <th>L3_ask_price</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_bid_quantity</th>\n",
       "      <th>L4_ask_price</th>\n",
       "      <th>L4_ask_quantity</th>\n",
       "      <th>L4_bid_price</th>\n",
       "      <th>L4_bid_quantity</th>\n",
       "      <th>L5_ask_price</th>\n",
       "      <th>L5_ask_quantity</th>\n",
       "      <th>L5_bid_price</th>\n",
       "      <th>L5_bid_quantity</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-21 09:30:01</td>\n",
       "      <td>585.87</td>\n",
       "      <td>100.0</td>\n",
       "      <td>585.74</td>\n",
       "      <td>100.0</td>\n",
       "      <td>585.89</td>\n",
       "      <td>100.0</td>\n",
       "      <td>585.71</td>\n",
       "      <td>18.0</td>\n",
       "      <td>585.93</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>585.94</td>\n",
       "      <td>300.0</td>\n",
       "      <td>585.69</td>\n",
       "      <td>20.0</td>\n",
       "      <td>585.98</td>\n",
       "      <td>400.0</td>\n",
       "      <td>585.65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-06-21 09:30:01</td>\n",
       "      <td>223.86</td>\n",
       "      <td>100.0</td>\n",
       "      <td>223.84</td>\n",
       "      <td>100.0</td>\n",
       "      <td>223.95</td>\n",
       "      <td>60.0</td>\n",
       "      <td>223.75</td>\n",
       "      <td>74.0</td>\n",
       "      <td>224.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>224.24</td>\n",
       "      <td>20.0</td>\n",
       "      <td>223.60</td>\n",
       "      <td>15.0</td>\n",
       "      <td>224.25</td>\n",
       "      <td>100.0</td>\n",
       "      <td>223.51</td>\n",
       "      <td>100.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-06-21 09:30:01</td>\n",
       "      <td>579.79</td>\n",
       "      <td>210.0</td>\n",
       "      <td>579.19</td>\n",
       "      <td>75.0</td>\n",
       "      <td>579.89</td>\n",
       "      <td>25.0</td>\n",
       "      <td>579.12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>579.95</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>579.98</td>\n",
       "      <td>5.0</td>\n",
       "      <td>578.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>580.00</td>\n",
       "      <td>2937.0</td>\n",
       "      <td>578.70</td>\n",
       "      <td>400.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-06-21 09:30:01</td>\n",
       "      <td>27.53</td>\n",
       "      <td>326.0</td>\n",
       "      <td>27.52</td>\n",
       "      <td>200.0</td>\n",
       "      <td>27.54</td>\n",
       "      <td>673.0</td>\n",
       "      <td>27.51</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>27.55</td>\n",
       "      <td>...</td>\n",
       "      <td>11781.0</td>\n",
       "      <td>27.56</td>\n",
       "      <td>200.0</td>\n",
       "      <td>27.49</td>\n",
       "      <td>400.0</td>\n",
       "      <td>27.57</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>27.48</td>\n",
       "      <td>3761.0</td>\n",
       "      <td>INTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-06-21 09:30:01</td>\n",
       "      <td>31.00</td>\n",
       "      <td>28256.0</td>\n",
       "      <td>30.98</td>\n",
       "      <td>100.0</td>\n",
       "      <td>31.01</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>30.97</td>\n",
       "      <td>353.0</td>\n",
       "      <td>31.02</td>\n",
       "      <td>...</td>\n",
       "      <td>218.0</td>\n",
       "      <td>31.03</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>30.95</td>\n",
       "      <td>8261.0</td>\n",
       "      <td>31.04</td>\n",
       "      <td>6767.0</td>\n",
       "      <td>30.94</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  L1_ask_price  L1_ask_quantity  L1_bid_price  \\\n",
       "0 2012-06-21 09:30:01        585.87            100.0        585.74   \n",
       "1 2012-06-21 09:30:01        223.86            100.0        223.84   \n",
       "2 2012-06-21 09:30:01        579.79            210.0        579.19   \n",
       "3 2012-06-21 09:30:01         27.53            326.0         27.52   \n",
       "4 2012-06-21 09:30:01         31.00          28256.0         30.98   \n",
       "\n",
       "   L1_bid_quantity  L2_ask_price  L2_ask_quantity  L2_bid_price  \\\n",
       "0            100.0        585.89            100.0        585.71   \n",
       "1            100.0        223.95             60.0        223.75   \n",
       "2             75.0        579.89             25.0        579.12   \n",
       "3            200.0         27.54            673.0         27.51   \n",
       "4            100.0         31.01           1599.0         30.97   \n",
       "\n",
       "   L2_bid_quantity  L3_ask_price  ...  L3_bid_quantity  L4_ask_price  \\\n",
       "0             18.0        585.93  ...             44.0        585.94   \n",
       "1             74.0        224.00  ...              2.0        224.24   \n",
       "2            100.0        579.95  ...             41.0        579.98   \n",
       "3           3215.0         27.55  ...          11781.0         27.56   \n",
       "4            353.0         31.02  ...            218.0         31.03   \n",
       "\n",
       "   L4_ask_quantity  L4_bid_price  L4_bid_quantity  L5_ask_price  \\\n",
       "0            300.0        585.69             20.0        585.98   \n",
       "1             20.0        223.60             15.0        224.25   \n",
       "2              5.0        578.99              1.0        580.00   \n",
       "3            200.0         27.49            400.0         27.57   \n",
       "4           3400.0         30.95           8261.0         31.04   \n",
       "\n",
       "   L5_ask_quantity  L5_bid_price  L5_bid_quantity   tic  \n",
       "0            400.0        585.65              5.0  AAPL  \n",
       "1            100.0        223.51            100.0  AMZN  \n",
       "2           2937.0        578.70            400.0  GOOG  \n",
       "3           1100.0         27.48           3761.0  INTC  \n",
       "4           6767.0         30.94           1573.0  MSFT  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.set_index('date',inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QNMLdZVGpkQ"
   },
   "source": [
    "#**installing & Importing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35ZOExzqMWM5",
    "outputId": "b1133689-4820-4153-aeef-988635be9639"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelmoez/.local/lib/python3.8/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "\n",
    "from finrl.apps import config\n",
    "# from finrl.neo_finrl.preprocessor.preprocessors import data_split\n",
    "#from finrl.neo_finrl.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.drl_agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "elPwGMhEMYOW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3GmpJmRMeCr"
   },
   "source": [
    "#**Feautre Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Nf34PH_NP49"
   },
   "source": [
    "#**Design Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ssqMrDu1696K"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from copy import deepcopy\n",
    "%matplotlib inline\n",
    "\n",
    "# from stable_baselines3.common import logger\n",
    "\n",
    "\n",
    "class StockTradingEnv(gym.Env):\n",
    "    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        stock_dim,\n",
    "        #hmax,\n",
    "        initial_amount,\n",
    "        #buy_cost_pct,\n",
    "        #sell_cost_pct,\n",
    "        reward_scaling,\n",
    "        state_space,\n",
    "        action_space,\n",
    "        depth_list,\n",
    "        #turbulence_threshold=None,\n",
    "        #risk_indicator_col=\"turbulence\",\n",
    "        debt_amount = 0,\n",
    "        make_plots=False,\n",
    "        print_verbosity=10,\n",
    "        time_frame=0,\n",
    "        initial=True,\n",
    "        previous_state=[],\n",
    "        model_name=\"\",\n",
    "        mode=\"\",\n",
    "        shares_limit=500,\n",
    "        position_limit=500,\n",
    "        no_limit=1,\n",
    "        iteration=\"\"):\n",
    "        self.shares_limit = shares_limit\n",
    "        self.position_limit = position_limit\n",
    "        self.no_limit = no_limit\n",
    "        self.time_frame = time_frame\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        #self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.debt_amount = debt_amount\n",
    "        #self.buy_cost_pct = buy_cost_pct\n",
    "        #self.sell_cost_pct = sell_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.depth_list = depth_list\n",
    "        self.action_space = spaces.Box(low= 1, high= 100, shape=(self.stock_dim*2,))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.state_space,))\n",
    "        self.data = self.df.loc[self.stock_dim*self.time_frame : self.stock_dim*(self.time_frame + 1)-1,:]\n",
    "        self.terminal = False\n",
    "        self.make_plots = make_plots\n",
    "        self.print_verbosity = print_verbosity\n",
    "        #self.turbulence_threshold = turbulence_threshold\n",
    "        #self.risk_indicator_col = risk_indicator_col\n",
    "        self.initial = initial\n",
    "        self.previous_state = previous_state\n",
    "        self.model_name = model_name\n",
    "        self.mode = mode\n",
    "        self.iteration = iteration\n",
    "        # initalize state\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        # initialize reward\n",
    "        self.reward = 0\n",
    "        #self.turbulence = 0\n",
    "        #self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.episode = 0\n",
    "        # memorize all the total balance change\n",
    "        self.asset_memory = [self.initial_amount-self.debt_amount]\n",
    "        self.rewards_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "        # self.reset()\n",
    "        self._seed()\n",
    "          \n",
    "    def _sell_short_stock(self, index, action):\n",
    "\n",
    "        sell_num_shares = min(action, self.state[index + 2 + 5 * self.stock_dim])\n",
    "\n",
    "        sell_amount = (\n",
    "            self.state[index + 2 + 4*self.stock_dim]\n",
    "            * sell_num_shares\n",
    "            )\n",
    "        debt = (\n",
    "            self.state[index + 2 + 2*self.stock_dim]\n",
    "            * sell_num_shares\n",
    "            )\n",
    "        # update balance\n",
    "        self.state[0] += sell_amount\n",
    "        self.state[1] += debt\n",
    "        self.state[index + 2+self.stock_dim] += sell_num_shares    \n",
    "        self.trades += 1\n",
    "\n",
    "        return sell_num_shares\n",
    "            \n",
    "    def _buy_short_stock(self, index, action):\n",
    "        \n",
    "        if self.state[2+index+self.stock_dim] <= 0:\n",
    "            return 0\n",
    "            \n",
    "        else:\n",
    "            available_amount = (self.state[0] // self.state[index + 2 + self.stock_dim*2])\n",
    "            # print('available_amount:{}'.format(available_amount))\n",
    "\n",
    "            # update balance\n",
    "            buy_num_shares = min(action,available_amount, self.state[index+2+self.stock_dim],self.state[index + 2 + 3*self.stock_dim])\n",
    "\n",
    "            buy_amount = (\n",
    "                  self.state[index + 2 + self.stock_dim*2] * buy_num_shares \n",
    "                )\n",
    "            \n",
    "            self.state[0] -= buy_amount\n",
    "            self.state[1] -= buy_amount\n",
    "            self.state[index + 2+self.stock_dim] -= buy_num_shares\n",
    "            self.trades += 1\n",
    "\n",
    "            return buy_num_shares\n",
    "            \n",
    "    def _sell_stock(self, index, action):\n",
    "\n",
    "            if self.state[2+index] <= 0:\n",
    "              return 0\n",
    "            \n",
    "            else:\n",
    "              sell_num_shares = min(action,self.state[2+index], self.state[index + 2 + 5 * self.stock_dim])\n",
    "\n",
    "            sell_amount = (\n",
    "                  self.state[index + 2 + 4*self.stock_dim]\n",
    "                  * sell_num_shares\n",
    "                )\n",
    "            # update balance\n",
    "            self.state[0] += sell_amount\n",
    "            self.state[index + 2] -= sell_num_shares    \n",
    "            self.trades += 1\n",
    "\n",
    "            return sell_num_shares\n",
    "            \n",
    "    def _buy_stock(self, index, action):\n",
    "\n",
    "            available_amount = (self.state[0] // self.state[index + 2 + self.stock_dim*2])\n",
    "            # print('available_amount:{}'.format(available_amount))\n",
    "\n",
    "            # update balance\n",
    "            buy_num_shares = min(action,available_amount, self.state[index + 2 + 3*self.stock_dim])\n",
    "\n",
    "            buy_amount = (\n",
    "                  self.state[index + 2 + self.stock_dim*2] * buy_num_shares \n",
    "                )\n",
    "            \n",
    "            self.state[0] -= buy_amount\n",
    "            self.state[index + 2] += buy_num_shares\n",
    "            self.trades += 1\n",
    "\n",
    "            return buy_num_shares\n",
    "\n",
    "\n",
    "\n",
    "    def _make_plot(self):\n",
    "        plt.plot(self.asset_memory, \"r\")\n",
    "        plt.savefig(\"results/account_value_trade_{}.png\".format(self.episode))\n",
    "        plt.close()\n",
    "\n",
    "    def step(self, actions):\n",
    "        self.terminal = self.time_frame >= (len(self.df.date.unique())-1)\n",
    "        self.debt_amount = sum(\n",
    "            np.array(self.state[(self.stock_dim + 2):(self.stock_dim*2 + 2)])\n",
    "            * np.array(self.state[(self.stock_dim * 2 + 2) : (self.stock_dim * 3 + 2)]))\n",
    "        self.state[1] = self.debt_amount\n",
    "\n",
    "        if self.terminal:\n",
    "            # print(len(self.state))\n",
    "            # print(len(self.state[1 : (self.stock_dim + 1)]))\n",
    "            # print(len(self.state[(self.stock_dim * 3 + 1) : (self.stock_dim * 4 + 1)]))\n",
    "            # print(f\"Episode: {self.episode}\")\n",
    "            if self.make_plots:\n",
    "                self._make_plot()\n",
    "            end_total_asset = self.state[0] - self.state[1] + sum(\n",
    "                np.array(self.state[2 : (self.stock_dim + 2)])\n",
    "                * np.array(self.state[(self.stock_dim * 4 + 2) : (self.stock_dim * 5 + 2)])\n",
    "            )\n",
    "            df_total_value = pd.DataFrame(self.asset_memory)\n",
    "            tot_reward = ( end_total_asset - self.initial_amount)\n",
    "            df_total_value.columns = [\"account_value\"]\n",
    "            df_total_value[\"date\"] = self.date_memory\n",
    "            df_total_value[\"daily_return\"] = df_total_value[\"account_value\"].pct_change(\n",
    "                1\n",
    "            )\n",
    "            if df_total_value[\"daily_return\"].std() != 0:\n",
    "                sharpe = (\n",
    "                    (252 ** 0.5)\n",
    "                    * df_total_value[\"daily_return\"].mean()\n",
    "                    / df_total_value[\"daily_return\"].std()\n",
    "                )\n",
    "            df_rewards = pd.DataFrame(self.rewards_memory)\n",
    "            df_rewards.columns = [\"account_rewards\"]\n",
    "            df_rewards[\"date\"] = self.date_memory[:-1]\n",
    "            if self.episode % self.print_verbosity == 0:\n",
    "                print(f\"Moment: {self.time_frame}, episode: {self.episode}\")\n",
    "                print(f\"begin_total_asset: {self.asset_memory[0]:0.2f}\")\n",
    "                print(f\"end_total_asset: {end_total_asset:0.2f}\")\n",
    "                print(f\"total_reward: {tot_reward:0.2f}\")\n",
    "                #print(f\"total_cost: {self.cost:0.2f}\")\n",
    "                print(f\"total_trades: {self.trades}\")\n",
    "                if df_total_value[\"daily_return\"].std() != 0:\n",
    "                    print(f\"Sharpe: {sharpe:0.3f}\")\n",
    "                print(\"=================================\")\n",
    "\n",
    "            if (self.model_name != \"\") and (self.mode != \"\"):\n",
    "                df_actions = self.save_action_memory()\n",
    "                df_actions.to_csv(\n",
    "                    \"results/actions_{}_{}_{}.csv\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    )\n",
    "                )\n",
    "                df_total_value.to_csv(\n",
    "                    \"results/account_value_{}_{}_{}.csv\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    ),\n",
    "                    index=False,\n",
    "                )\n",
    "                df_rewards.to_csv(\n",
    "                    \"results/account_rewards_{}_{}_{}.csv\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    ),\n",
    "                    index=False,\n",
    "                )\n",
    "                plt.plot(self.asset_memory, \"r\")\n",
    "                plt.savefig(\n",
    "                    \"results/account_value_{}_{}_{}.png\".format(\n",
    "                        self.mode, self.model_name, self.iteration\n",
    "                    ),\n",
    "                    index=False,\n",
    "                )\n",
    "                plt.close()\n",
    "\n",
    "            # Add outputs to logger interface\n",
    "            # logger.record(\"environment/portfolio_value\", end_total_asset)\n",
    "            # logger.record(\"environment/total_reward\", tot_reward)\n",
    "            # logger.record(\"environment/total_reward_pct\", (tot_reward / (end_total_asset - tot_reward)) * 100)\n",
    "            # logger.record(\"environment/total_cost\", self.cost)\n",
    "            # logger.record(\"environment/total_trades\", self.trades)\n",
    "            # print(self.state[0:self.stock_dim+1])\n",
    "            return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "        else:\n",
    "            limit_dict = {\n",
    "                'S_Stock' : 0,\n",
    "                'S_Pos' : 0,\n",
    "                'L_Stock' : 0,\n",
    "                'L_Pos' : 0}\n",
    "            limit_list = [limit_dict]*self.stock_dim\n",
    "            \n",
    "            #actions = actions * self.hmax  # actions initially is scaled between 0 to 1\n",
    "            actions = actions.astype(\n",
    "                int\n",
    "            )  # convert into integer because we can't by fraction of shares\n",
    "            # print(actions.shape)\n",
    "            # print(actions)\n",
    "            begin_total_asset = self.state[0] - self.state[1]+ sum(\n",
    "                np.array(self.state[2 : (self.stock_dim + 2)])\n",
    "                * np.array(self.state[(self.stock_dim * 4 + 2) : (self.stock_dim * 5 + 2)])\n",
    "            )\n",
    "            # print(\"begin_total_asset:{}\".format(begin_total_asset))\n",
    "\n",
    "            \n",
    "            sell_index = np.intersect1d(np.where(actions[:self.stock_dim] > 60),np.where(actions[:self.stock_dim]<81)).tolist()\n",
    "            buy_index = np.intersect1d(np.where(actions[:self.stock_dim] > 0),np.where(actions[:self.stock_dim]<21)).tolist()\n",
    "            short_sell_id = np.intersect1d(np.where(actions[:self.stock_dim] > 80),np.where(actions[:self.stock_dim]<101)).tolist()\n",
    "            short_buy_id = np.intersect1d(np.where(actions[:self.stock_dim] > 20),np.where(actions[:self.stock_dim]<41)).tolist()\n",
    "            new_action = ['None']*self.stock_dim\n",
    "            # print(buy_index)\n",
    "            # print(sell_index)\n",
    "            \n",
    "            if not self.no_limit:\n",
    "                for i in range(self.stock_dim):\n",
    "                  if limit_list[i]['L_Stock'] >= 0:\n",
    "                    limit_list[i]['L_Pos'] +=1\n",
    "                  if limit_list[i]['S_Stock'] >= 0:\n",
    "                    limit_list[i]['S_Pos'] +=1\n",
    "                  if limit_list[i]['L_Stock']>=self.shares_limit:\n",
    "                    if i in buy_index:\n",
    "                      buy_index.remove(i)\n",
    "                  if limit_list[i]['S_Stock']>=self.shares_limit:\n",
    "                    if i in short_sell_id:\n",
    "                      short_sell_id.remove(i)\n",
    "                  if limit_list[i]['L_Pos']>=self.position_limit:\n",
    "                    val = self._sell_stock(i, self.state[i+2])\n",
    "                    new_action[i] = 'LS'+str(val)\n",
    "                    limit_list[i][\"L_Stock\"] -= val\n",
    "                    if limit_list[i][\"L_Stock\"] <= 0: \n",
    "                      limit_list[i][\"L_Pos\"] = 0\n",
    "                    if i in buy_index:\n",
    "                      buy_index.remove(i)\n",
    "                  if limit_list[i]['L_Pos']>=self.position_limit:\n",
    "                    val = self._buy_short_stock(i, self.state[i+2+self.stock_dim])\n",
    "                    new_action[i] = 'SB'+str(val)\n",
    "                    limit_list[i][\"S_Stock\"] -= val\n",
    "                    if limit_list[i][\"S_Stock\"] <= 0: \n",
    "                      limit_list[i][\"S_Pos\"] = 0\n",
    "                    if i in short_sell_id:\n",
    "                      short_sell_id.remove(i)\n",
    "\n",
    "            for index in sell_index:\n",
    "                # print(f\"Num shares before: {self.state[index+self.stock_dim+1]}\")\n",
    "                # print(f'take sell action before : {actions[index]}')\n",
    "                val = self._sell_stock(index, actions[self.stock_dim:][index])\n",
    "                new_action[index] = 'LS'+str(val)\n",
    "                limit_list[index][\"L_Stock\"] -= val\n",
    "                if limit_list[index][\"L_Stock\"] <= 0: \n",
    "                  limit_list[index][\"L_Pos\"] = 0\n",
    "                # print(f'take sell action after : {actions[index]}')\n",
    "                # print(f\"Num shares after: {self.state[index+self.stock_dim+1]}\")\n",
    "\n",
    "            for index in buy_index:\n",
    "                # print('take buy action: {}'.format(actions[index]))\n",
    "                val = self._buy_stock(index, actions[self.stock_dim:][index])                                                                                      \n",
    "                new_action[index] = 'LB'+str(val)\n",
    "                limit_list[index][\"L_Stock\"] += val\n",
    "            for index in short_sell_id:\n",
    "                            # print('take buy action: {}'.format(actions[index]))\n",
    "                val = self._sell_short_stock(index, actions[self.stock_dim:][index])\n",
    "                new_action[index] = 'SS'+str(val)\n",
    "                limit_list[index][\"S_Stock\"] += val\n",
    "            for index in short_buy_id:\n",
    "                            # print('take buy action: {}'.format(actions[index]))\n",
    "                val = self._buy_short_stock(index, actions[self.stock_dim:][index])\n",
    "                new_action[index] = 'SB'+str(val)\n",
    "                limit_list[index][\"S_Stock\"] -= val\n",
    "                if limit_list[index][\"S_Stock\"] <= 0: \n",
    "                  limit_list[index][\"S_Pos\"] = 0\n",
    "\n",
    "            self.actions_memory.append(new_action)\n",
    "\n",
    "            # state: s -> s+1\n",
    "            self.time_frame += 1\n",
    "            self.data = self.df.loc[self.stock_dim*self.time_frame : self.stock_dim*(self.time_frame + 1)-1,:]\n",
    "            self.state = self._update_state()\n",
    "\n",
    "            # print(len(self.state))\n",
    "            # print(len(self.state[1 : (self.stock_dim + 1)]))\n",
    "            # print(len(self.state[(self.stock_dim * 3 + 1) : (self.stock_dim * 4 + 1)]))\n",
    "\n",
    "            end_total_asset = self.state[0] - self.state[1]+ sum(\n",
    "                np.array(self.state[2 : (self.stock_dim + 2)])\n",
    "                * np.array(self.state[(self.stock_dim * 4 + 2) : (self.stock_dim * 5 + 2)])\n",
    "            )\n",
    "            self.asset_memory.append(end_total_asset)\n",
    "            self.date_memory.append(self._get_date())\n",
    "            self.reward = end_total_asset - begin_total_asset\n",
    "            self.rewards_memory.append(self.reward)\n",
    "            self.reward = (self.reward * self.reward_scaling)\n",
    "        # print(len(self.state))\n",
    "        # print(self.state[1:self.stock_dim+1])\n",
    "        # print(self.state[0])\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def reset(self):\n",
    "        # initiate state\n",
    "        self.state = self._initiate_state()\n",
    "\n",
    "        if self.initial:\n",
    "            self.asset_memory = [self.initial_amount-self.debt_amount]\n",
    "        else:\n",
    "            if self.stock_dim>1:\n",
    "              previous_total_asset = self.previous_state[0] - self.state[1] + sum(\n",
    "               np.array(self.state[2 : (self.stock_dim + 2)])\n",
    "                * np.array(self.state[(self.stock_dim * 4+ 2) : (self.stock_dim * 5 + 2)])\n",
    "                )\n",
    "            else:\n",
    "              previous_total_asset = self.previous_state[0] -self.state[1]+ self.state[2]*self.state[5]\n",
    "            \n",
    "            self.asset_memory = [previous_total_asset]\n",
    "\n",
    "        self.time_frame = 0\n",
    "        self.data = self.df.loc[self.stock_dim*self.time_frame : self.stock_dim*(self.time_frame + 1)-1,:]\n",
    "        #self.turbulence = 0\n",
    "        #self.cost = 0\n",
    "        self.trades = 0\n",
    "        self.terminal = False\n",
    "        # self.iteration=self.iteration\n",
    "        self.rewards_memory = []\n",
    "        self.actions_memory = []\n",
    "        self.date_memory = [self._get_date()]\n",
    "\n",
    "        self.episode += 1\n",
    "        return self.state\n",
    "\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        return self.state\n",
    "\n",
    "    def _initiate_state(self):\n",
    "        if self.initial:\n",
    "            # For Initial State\n",
    "            if len(self.df.tic.unique()) > 1:\n",
    "                # for multiple stock\n",
    "                state = (\n",
    "                    [self.initial_amount]\n",
    "                    + [self.debt_amount]\n",
    "                    #+ self.data.close.values.tolist()\n",
    "                    + [0] * self.stock_dim\n",
    "                    + [0] * self.stock_dim\n",
    "                    + sum(\n",
    "                        [\n",
    "                            self.data[depth].values.tolist()\n",
    "                            for depth in self.depth_list\n",
    "                        ],\n",
    "                        [],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # for single stock\n",
    "                state = (\n",
    "                    [self.initial_amount]\n",
    "                    + [self.debt_amount]\n",
    "                    #+ self.data.close.values.tolist()\n",
    "                    + [0] * self.stock_dim\n",
    "                    + [0] * self.stock_dim\n",
    "                    + sum([[self.data[depth]] for depth in self.depth_list], [])\n",
    "                )\n",
    "        else:\n",
    "            # Using Previous State\n",
    "            if len(self.df.tic.unique()) > 1:\n",
    "                # for multiple stock\n",
    "                state = (\n",
    "                    [self.previous_state[0]]\n",
    "                    +[self.previous_state[1]]\n",
    "                    #+ self.data.close.values.tolist()\n",
    "                    + self.previous_state[\n",
    "                        2 : (self.stock_dim*2 + 2)\n",
    "                    ]\n",
    "                    + sum(\n",
    "                        [\n",
    "                            self.data[depth].values.tolist()\n",
    "                            for depth in self.depth_list\n",
    "                        ],\n",
    "                        [],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # for single stock\n",
    "                state = (\n",
    "                    [self.previous_state[0]]\n",
    "                    + [self.previous_state[1]]\n",
    "                    + self.previous_state[\n",
    "                        2 : (self.stock_dim*2 + 2)\n",
    "                    ]\n",
    "                    + sum([[self.data[depth]] for depth in self.depth_list], [])\n",
    "                )\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _update_state(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            # for multiple stock\n",
    "            state = (\n",
    "                [self.state[0]]\n",
    "                +[self.state[1]]\n",
    "                + self.state[2 : (self.stock_dim*2 + 2)]\n",
    "                + sum(\n",
    "                    [\n",
    "                        self.data[depth].values.tolist()\n",
    "                        for depth in self.depth_list\n",
    "                    ],\n",
    "                    [],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # for single stock\n",
    "            state = (\n",
    "                [self.state[0]]\n",
    "                + [self.state[1]]\n",
    "                + self.state[2 : (self.stock_dim + 2)]\n",
    "                + sum([[self.data[depth]] for depth in self.depth_list], [])\n",
    "            )\n",
    "\n",
    "        return state\n",
    "\n",
    "    def _get_date(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            date = self.data.date.unique()\n",
    "        else:\n",
    "            date = self.data.date\n",
    "        return date\n",
    " \n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        asset_list = self.asset_memory\n",
    "        # print(len(date_list))\n",
    "        # print(len(asset_list))\n",
    "        df_account_value = pd.DataFrame(\n",
    "            {\"date\": date_list, \"account_value\": asset_list}\n",
    "        )\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        if len(self.df.tic.unique()) > 1:\n",
    "            # date and close price length must match actions length\n",
    "            date_list = self.date_memory[:-1]\n",
    "            df_date = pd.DataFrame(date_list)\n",
    "            df_date.columns = [\"date\"]\n",
    "\n",
    "            action_list = self.actions_memory\n",
    "            df_actions = pd.DataFrame(action_list)\n",
    "            df_actions.columns = self.data.tic.values\n",
    "            df_actions.index = df_date.date\n",
    "            # df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        else:\n",
    "            date_list = self.date_memory[:-1]\n",
    "            action_list = self.actions_memory\n",
    "            df_actions = pd.DataFrame({\"date\": date_list, \"actions\": action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "      def get_self():\n",
    "          return deepcopy(self)\n",
    "      e = DummyVecEnv([get_self])\n",
    "      obs = e.reset()\n",
    "      return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aZYeJwzReazA"
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "split = 0.80\n",
    "split_date = data.date.unique()[:floor(split*data.date.unique().shape[0])]\n",
    "train = data[data.date<split_date[-1]]\n",
    "trade = data[data.date>split_date[-2]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIUUYJpgNeoL"
   },
   "source": [
    "##**Environment for Portfolio Allocation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "981i4t3jNVep",
    "outputId": "21a1e4f2-7996-478d-8de8-35e23f4d6964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 5, State Space: 112\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 2 + (len(columns)+2)*(stock_dimension)\n",
    "#state_space = 1 + 2*stock_dimension + len(tech_indicator_list)*stock_dimension\n",
    "#state_space = 1 + 2*(stock_dimension+2) + (len(tech_indicator_list)-2)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PoQilxkcNgcS"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"initial_amount\": 100000,\n",
    "    #\"buy_cost_pct\": 0.001,\n",
    "    #\"sell_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"depth_list\": columns, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"shares_limit\":100,\n",
    "    \"position_limit\":100,\n",
    "    \"no_limit\":1\n",
    "}\n",
    "e_train_gym = StockTradingEnv(df = train ,**env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSB0olPMNhqc",
    "outputId": "f43629d3-2b21-4b38-97b4-c4a3e2020158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "f-KAKzIVNjoo"
   },
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOBMeQykNkow",
    "outputId": "25cb2abd-3712-45ab-ebcc-405c36e171f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_trade, _ = e_trade_gym.get_sb_env()\n",
    "print(type(env_trade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yw-y8Yf5NoH3"
   },
   "source": [
    "#**DRL Algorithms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kvlKwFOkcabE"
   },
   "outputs": [],
   "source": [
    "def DRL_prediction(model, environment):\n",
    "        test_env, test_obs = environment.get_sb_env()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "        test_env.reset()\n",
    "        for i in range(len(environment.df.date.unique())):\n",
    "            action, _states = model.predict(test_obs)\n",
    "            # account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "            # actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "            test_obs, rewards, dones, info = test_env.step(action)\n",
    "            if i == (len(environment.df.date.unique()) - 2):\n",
    "                account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        return account_memory[0], actions_memory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Ay8ffH9tNlwI"
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "agent = DRLAgent(env = env_train)\n",
    "trade_agent = DRLAgent(env = env_trade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR6KgltjNuGk"
   },
   "source": [
    "##**A2C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAS0rLX_mtkm",
    "outputId": "23288eb0-d1c3-4ee3-9741-2ee13a67d8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 100, 'ent_coef': 0.02, 'learning_rate': 0.0007}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "A2C_PARAMS = {'n_steps': 100, 'ent_coef': 0.02, 'learning_rate': 0.0007}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tWcvHTRNxIa"
   },
   "source": [
    "###**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRNx-XICNscs",
    "outputId": "e8974cc8-2874-40b1-a41c-d256938067a6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 432      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.9    |\n",
      "|    explained_variance | -173     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.377    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.00442  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 866      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | -0.938   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.435    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.00143  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 1310     |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.299   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 0.00532  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 1751     |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -17      |\n",
      "|    explained_variance | -35.3    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.0732   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.33     |\n",
      "|    value_loss         | 0.000254 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 22        |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 2192      |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -17.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -0.109    |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.42      |\n",
      "|    value_loss         | 4.64e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 2635     |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -18.4    |\n",
      "|    explained_variance | -55.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.394   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.52     |\n",
      "|    value_loss         | 0.00168  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 3076     |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -19      |\n",
      "|    explained_variance | -2.26    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.933   |\n",
      "|    reward             | 6.9e-05  |\n",
      "|    std                | 1.62     |\n",
      "|    value_loss         | 0.00354  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 3520     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -19.6    |\n",
      "|    explained_variance | -14.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.0447   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 0.000305 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 3960     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -20.3    |\n",
      "|    explained_variance | -10.9    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.144   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.84     |\n",
      "|    value_loss         | 6.11e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 4387     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -21      |\n",
      "|    explained_variance | -0.722   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.566    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.98     |\n",
      "|    value_loss         | 0.00145  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 4811     |\n",
      "|    total_timesteps    | 110000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -21.7    |\n",
      "|    explained_variance | -13.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.293   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.12     |\n",
      "|    value_loss         | 0.000228 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 5236     |\n",
      "|    total_timesteps    | 120000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -22.4    |\n",
      "|    explained_variance | -109     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.191    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.27     |\n",
      "|    value_loss         | 0.000199 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 22       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 5660     |\n",
      "|    total_timesteps    | 130000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -23.1    |\n",
      "|    explained_variance | 0.639    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.135   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.43     |\n",
      "|    value_loss         | 4.96e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 6085      |\n",
      "|    total_timesteps    | 140000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -23.7     |\n",
      "|    explained_variance | -2        |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -0.106    |\n",
      "|    reward             | -0.000192 |\n",
      "|    std                | 2.6       |\n",
      "|    value_loss         | 5.17e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 6508      |\n",
      "|    total_timesteps    | 150000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -24.4     |\n",
      "|    explained_variance | -7.85     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 1.72      |\n",
      "|    reward             | -0.000186 |\n",
      "|    std                | 2.79      |\n",
      "|    value_loss         | 0.0299    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 6933     |\n",
      "|    total_timesteps    | 160000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -25      |\n",
      "|    explained_variance | -6.14    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.0804  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.96     |\n",
      "|    value_loss         | 1.83e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 7358     |\n",
      "|    total_timesteps    | 170000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -25.7    |\n",
      "|    explained_variance | -7.58    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.141    |\n",
      "|    reward             | 0.001054 |\n",
      "|    std                | 3.18     |\n",
      "|    value_loss         | 5.07e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 7783     |\n",
      "|    total_timesteps    | 180000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -26.4    |\n",
      "|    explained_variance | -116     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.435   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.41     |\n",
      "|    value_loss         | 0.000449 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 8208     |\n",
      "|    total_timesteps    | 190000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.1    |\n",
      "|    explained_variance | -0.00764 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.025    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.66     |\n",
      "|    value_loss         | 1.15e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 8632     |\n",
      "|    total_timesteps    | 200000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -27.8    |\n",
      "|    explained_variance | -14.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.0377  |\n",
      "|    reward             | -6.2e-05 |\n",
      "|    std                | 3.92     |\n",
      "|    value_loss         | 4.17e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 9056     |\n",
      "|    total_timesteps    | 210000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -28.5    |\n",
      "|    explained_variance | -0.841   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.167   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.2      |\n",
      "|    value_loss         | 4.2e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 9479     |\n",
      "|    total_timesteps    | 220000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.2    |\n",
      "|    explained_variance | -0.163   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.00547 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.51     |\n",
      "|    value_loss         | 6.39e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 9902     |\n",
      "|    total_timesteps    | 230000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -29.9    |\n",
      "|    explained_variance | -9.52    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.00415  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.8      |\n",
      "|    value_loss         | 2.01e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 10326    |\n",
      "|    total_timesteps    | 240000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -30.6    |\n",
      "|    explained_variance | -0.285   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.0385  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.15     |\n",
      "|    value_loss         | 2.27e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 10749    |\n",
      "|    total_timesteps    | 250000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -31.3    |\n",
      "|    explained_variance | -1.88    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.0885  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.53     |\n",
      "|    value_loss         | 1.49e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 11172    |\n",
      "|    total_timesteps    | 260000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32      |\n",
      "|    explained_variance | -0.318   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.0889   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.93     |\n",
      "|    value_loss         | 9.54e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 11595    |\n",
      "|    total_timesteps    | 270000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -32.7    |\n",
      "|    explained_variance | 0.00155  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.445   |\n",
      "|    reward             | 7.2e-05  |\n",
      "|    std                | 6.35     |\n",
      "|    value_loss         | 0.000237 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 12012    |\n",
      "|    total_timesteps    | 280000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -33.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.0699  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 6.81     |\n",
      "|    value_loss         | 9.23e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 12427    |\n",
      "|    total_timesteps    | 290000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.1    |\n",
      "|    explained_variance | 0.181    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.0371  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 7.31     |\n",
      "|    value_loss         | 1.73e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 12842    |\n",
      "|    total_timesteps    | 300000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -34.8    |\n",
      "|    explained_variance | -180     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -1.96    |\n",
      "|    reward             | 0.00088  |\n",
      "|    std                | 7.83     |\n",
      "|    value_loss         | 0.00632  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 13259    |\n",
      "|    total_timesteps    | 310000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -35.4    |\n",
      "|    explained_variance | -1.11    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.0659  |\n",
      "|    reward             | 0.000165 |\n",
      "|    std                | 8.35     |\n",
      "|    value_loss         | 6.76e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 13675    |\n",
      "|    total_timesteps    | 320000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.1    |\n",
      "|    explained_variance | -0.431   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.405    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 8.95     |\n",
      "|    value_loss         | 0.00015  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 14091    |\n",
      "|    total_timesteps    | 330000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -36.8    |\n",
      "|    explained_variance | -2.92    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0.00326 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 9.6      |\n",
      "|    value_loss         | 3.44e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 14508    |\n",
      "|    total_timesteps    | 340000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -37.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0.0356  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 10.3     |\n",
      "|    value_loss         | 1.02e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 14924    |\n",
      "|    total_timesteps    | 350000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.2    |\n",
      "|    explained_variance | -12.2    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.0654  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 11       |\n",
      "|    value_loss         | 7.25e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 15340    |\n",
      "|    total_timesteps    | 360000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -38.9    |\n",
      "|    explained_variance | -0.361   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.0754  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 11.8     |\n",
      "|    value_loss         | 4.53e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 15756    |\n",
      "|    total_timesteps    | 370000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -39.6    |\n",
      "|    explained_variance | -0.0389  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.0142   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 12.7     |\n",
      "|    value_loss         | 2.68e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 16178    |\n",
      "|    total_timesteps    | 380000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.3    |\n",
      "|    explained_variance | -14      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.188   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 13.6     |\n",
      "|    value_loss         | 7.39e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 16603    |\n",
      "|    total_timesteps    | 390000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41      |\n",
      "|    explained_variance | -1.23    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.0259  |\n",
      "|    reward             | 0.000492 |\n",
      "|    std                | 14.5     |\n",
      "|    value_loss         | 8.99e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 17028    |\n",
      "|    total_timesteps    | 400000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.6    |\n",
      "|    explained_variance | 0.0542   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.035    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 15.6     |\n",
      "|    value_loss         | 2.64e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 17453    |\n",
      "|    total_timesteps    | 410000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.3    |\n",
      "|    explained_variance | -0.215   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.0872  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 16.7     |\n",
      "|    value_loss         | 4.81e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 17878    |\n",
      "|    total_timesteps    | 420000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | 0.482    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.298    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 17.9     |\n",
      "|    value_loss         | 6.24e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 18302    |\n",
      "|    total_timesteps    | 430000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.688   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.515    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 19.2     |\n",
      "|    value_loss         | 0.000183 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 18725    |\n",
      "|    total_timesteps    | 440000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.149   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 20.6     |\n",
      "|    value_loss         | 1.39e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 19148    |\n",
      "|    total_timesteps    | 450000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.1    |\n",
      "|    explained_variance | -6.83    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 3.47     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 22.1     |\n",
      "|    value_loss         | 0.011    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 19571    |\n",
      "|    total_timesteps    | 460000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.8    |\n",
      "|    explained_variance | 0.211    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.169    |\n",
      "|    reward             | 0.000808 |\n",
      "|    std                | 23.6     |\n",
      "|    value_loss         | 1.52e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 19995    |\n",
      "|    total_timesteps    | 470000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.5    |\n",
      "|    explained_variance | 0.454    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.156   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 25.4     |\n",
      "|    value_loss         | 1.5e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 20418    |\n",
      "|    total_timesteps    | 480000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.2    |\n",
      "|    explained_variance | -3.08    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -1.67    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 27.1     |\n",
      "|    value_loss         | 0.00172  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 20842    |\n",
      "|    total_timesteps    | 490000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.9    |\n",
      "|    explained_variance | -0.0973  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.114    |\n",
      "|    reward             | -2e-06   |\n",
      "|    std                | 29.1     |\n",
      "|    value_loss         | 7.01e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 21265    |\n",
      "|    total_timesteps    | 500000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -48.5    |\n",
      "|    explained_variance | -846     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 31.1     |\n",
      "|    value_loss         | 0.00262  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 21689    |\n",
      "|    total_timesteps    | 510000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.2    |\n",
      "|    explained_variance | -0.726   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 0.858    |\n",
      "|    reward             | 0.001058 |\n",
      "|    std                | 33.3     |\n",
      "|    value_loss         | 0.0006   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 22113    |\n",
      "|    total_timesteps    | 520000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -49.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.412    |\n",
      "|    reward             | -2e-06   |\n",
      "|    std                | 35.6     |\n",
      "|    value_loss         | 8.22e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 22537     |\n",
      "|    total_timesteps    | 530000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 0.761     |\n",
      "|    reward             | -0.000679 |\n",
      "|    std                | 37.9      |\n",
      "|    value_loss         | 0.000241  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 22976     |\n",
      "|    total_timesteps    | 540000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -51.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 1.68      |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 40.6      |\n",
      "|    value_loss         | 0.00137   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 23414    |\n",
      "|    total_timesteps    | 550000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -51.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | -4.37    |\n",
      "|    reward             | 0.00948  |\n",
      "|    std                | 43.3     |\n",
      "|    value_loss         | 0.0108   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 23852     |\n",
      "|    total_timesteps    | 560000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.5     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 2.15      |\n",
      "|    reward             | -0.001609 |\n",
      "|    std                | 46        |\n",
      "|    value_loss         | 0.00309   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 24290    |\n",
      "|    total_timesteps    | 570000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -6.22    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 48.5     |\n",
      "|    value_loss         | 0.0218   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 24725    |\n",
      "|    total_timesteps    | 580000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -53.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 25.2     |\n",
      "|    reward             | -4e-05   |\n",
      "|    std                | 51       |\n",
      "|    value_loss         | 0.327    |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 5900          |\n",
      "|    time_elapsed       | 25158         |\n",
      "|    total_timesteps    | 590000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -53.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5899          |\n",
      "|    policy_loss        | 14.3          |\n",
      "|    reward             | -9.999998e-07 |\n",
      "|    std                | 53            |\n",
      "|    value_loss         | 0.111         |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 25595     |\n",
      "|    total_timesteps    | 600000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.2     |\n",
      "|    explained_variance | 0.00975   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -2.06     |\n",
      "|    reward             | -0.007369 |\n",
      "|    std                | 54.9      |\n",
      "|    value_loss         | 0.00383   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 26031     |\n",
      "|    total_timesteps    | 610000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -54.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -1.53     |\n",
      "|    reward             | -0.000241 |\n",
      "|    std                | 57.8      |\n",
      "|    value_loss         | 0.0224    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 26469    |\n",
      "|    total_timesteps    | 620000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 10.8     |\n",
      "|    reward             | 0.002675 |\n",
      "|    std                | 60.1     |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 26907    |\n",
      "|    total_timesteps    | 630000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -55.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -3.4     |\n",
      "|    reward             | -7e-05   |\n",
      "|    std                | 61.9     |\n",
      "|    value_loss         | 0.109    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 27346     |\n",
      "|    total_timesteps    | 640000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -51       |\n",
      "|    reward             | -0.000205 |\n",
      "|    std                | 63.4      |\n",
      "|    value_loss         | 1.05      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 27784     |\n",
      "|    total_timesteps    | 650000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -55.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 124       |\n",
      "|    reward             | -0.000742 |\n",
      "|    std                | 64.8      |\n",
      "|    value_loss         | 6.06      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 28221     |\n",
      "|    total_timesteps    | 660000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -68.7     |\n",
      "|    reward             | -0.000257 |\n",
      "|    std                | 65.6      |\n",
      "|    value_loss         | 2.24      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 28659    |\n",
      "|    total_timesteps    | 670000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | -106     |\n",
      "|    reward             | -0.00138 |\n",
      "|    std                | 66.4     |\n",
      "|    value_loss         | 4.36     |\n",
      "------------------------------------\n",
      "Moment: 74871, episode: 10\n",
      "begin_total_asset: -41058742.46\n",
      "end_total_asset: -144608.58\n",
      "total_reward: -244608.58\n",
      "total_trades: 339894\n",
      "Sharpe: 0.150\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 29097     |\n",
      "|    total_timesteps    | 680000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -3.12     |\n",
      "|    reward             | -0.014873 |\n",
      "|    std                | 68.2      |\n",
      "|    value_loss         | 0.0775    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 29536    |\n",
      "|    total_timesteps    | 690000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -56.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -21      |\n",
      "|    reward             | -6.8e-05 |\n",
      "|    std                | 69.7     |\n",
      "|    value_loss         | 0.237    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 29974     |\n",
      "|    total_timesteps    | 700000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.8     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 11        |\n",
      "|    reward             | -0.144663 |\n",
      "|    std                | 70.8      |\n",
      "|    value_loss         | 0.239     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 30412     |\n",
      "|    total_timesteps    | 710000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -56.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -29.4     |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 71.8      |\n",
      "|    value_loss         | 0.504     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 30850    |\n",
      "|    total_timesteps    | 720000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 12.3     |\n",
      "|    reward             | -3.1e-05 |\n",
      "|    std                | 72.7     |\n",
      "|    value_loss         | 0.0921   |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 7300           |\n",
      "|    time_elapsed       | 31288          |\n",
      "|    total_timesteps    | 730000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -57.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7299           |\n",
      "|    policy_loss        | -75.4          |\n",
      "|    reward             | -2.2999999e-05 |\n",
      "|    std                | 73.9           |\n",
      "|    value_loss         | 2.79           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 31723     |\n",
      "|    total_timesteps    | 740000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -69.9     |\n",
      "|    reward             | -0.000391 |\n",
      "|    std                | 74.3      |\n",
      "|    value_loss         | 1.94      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 32161    |\n",
      "|    total_timesteps    | 750000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -57.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -5.21    |\n",
      "|    reward             | -9.6e-05 |\n",
      "|    std                | 74.9     |\n",
      "|    value_loss         | 0.0126   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 32600     |\n",
      "|    total_timesteps    | 760000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 37.3      |\n",
      "|    reward             | -0.000689 |\n",
      "|    std                | 76.9      |\n",
      "|    value_loss         | 0.455     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 33038     |\n",
      "|    total_timesteps    | 770000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 20.3      |\n",
      "|    reward             | -0.004626 |\n",
      "|    std                | 78.1      |\n",
      "|    value_loss         | 0.311     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 33476     |\n",
      "|    total_timesteps    | 780000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -57.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -19       |\n",
      "|    reward             | -0.000451 |\n",
      "|    std                | 79        |\n",
      "|    value_loss         | 0.436     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 33914    |\n",
      "|    total_timesteps    | 790000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | -160     |\n",
      "|    reward             | 0.148231 |\n",
      "|    std                | 79.9     |\n",
      "|    value_loss         | 8.33     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 34353     |\n",
      "|    total_timesteps    | 800000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 78.6      |\n",
      "|    reward             | -0.001077 |\n",
      "|    std                | 80.2      |\n",
      "|    value_loss         | 3.95      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 34791     |\n",
      "|    total_timesteps    | 810000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -17.6     |\n",
      "|    reward             | -0.000826 |\n",
      "|    std                | 80.8      |\n",
      "|    value_loss         | 1.17      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 35228     |\n",
      "|    total_timesteps    | 820000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -344      |\n",
      "|    reward             | -0.000379 |\n",
      "|    std                | 81.1      |\n",
      "|    value_loss         | 51        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 35666     |\n",
      "|    total_timesteps    | 830000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -8.43     |\n",
      "|    reward             | -0.000159 |\n",
      "|    std                | 82.9      |\n",
      "|    value_loss         | 0.0542    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 36104     |\n",
      "|    total_timesteps    | 840000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -58.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -38.3     |\n",
      "|    reward             | -0.000558 |\n",
      "|    std                | 84.5      |\n",
      "|    value_loss         | 0.718     |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 8500           |\n",
      "|    time_elapsed       | 36543          |\n",
      "|    total_timesteps    | 850000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -58.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8499           |\n",
      "|    policy_loss        | -26.3          |\n",
      "|    reward             | -1.3000001e-05 |\n",
      "|    std                | 85.6           |\n",
      "|    value_loss         | 0.637          |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 36982    |\n",
      "|    total_timesteps    | 860000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -183     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 86.4     |\n",
      "|    value_loss         | 13.6     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 37420    |\n",
      "|    total_timesteps    | 870000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | 138      |\n",
      "|    reward             | -1.6e-05 |\n",
      "|    std                | 86.6     |\n",
      "|    value_loss         | 9.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 37860    |\n",
      "|    total_timesteps    | 880000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -58.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | -318     |\n",
      "|    reward             | -1.3e-05 |\n",
      "|    std                | 87.4     |\n",
      "|    value_loss         | 39.7     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 8900           |\n",
      "|    time_elapsed       | 38301          |\n",
      "|    total_timesteps    | 890000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -58.9          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8899           |\n",
      "|    policy_loss        | -34.4          |\n",
      "|    reward             | -5.8000005e-05 |\n",
      "|    std                | 87.8           |\n",
      "|    value_loss         | 1.06           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 38722     |\n",
      "|    total_timesteps    | 900000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -2.3      |\n",
      "|    reward             | -2e-06    |\n",
      "|    std                | 88.4      |\n",
      "|    value_loss         | 0.00559   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 39139     |\n",
      "|    total_timesteps    | 910000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 3.19      |\n",
      "|    reward             | -0.000111 |\n",
      "|    std                | 90.1      |\n",
      "|    value_loss         | 0.0322    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 39558    |\n",
      "|    total_timesteps    | 920000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 78.8     |\n",
      "|    reward             | -1e-04   |\n",
      "|    std                | 91.2     |\n",
      "|    value_loss         | 2.67     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 39976     |\n",
      "|    total_timesteps    | 930000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -57.3     |\n",
      "|    reward             | -0.000542 |\n",
      "|    std                | 92        |\n",
      "|    value_loss         | 21.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 40393     |\n",
      "|    total_timesteps    | 940000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 108       |\n",
      "|    reward             | -0.288682 |\n",
      "|    std                | 92.6      |\n",
      "|    value_loss         | 3.94      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 9500          |\n",
      "|    time_elapsed       | 40811         |\n",
      "|    total_timesteps    | 950000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -59.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9499          |\n",
      "|    policy_loss        | -0.685        |\n",
      "|    reward             | -9.999991e-07 |\n",
      "|    std                | 93.2          |\n",
      "|    value_loss         | 0.468         |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 41229     |\n",
      "|    total_timesteps    | 960000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 107       |\n",
      "|    reward             | -0.000515 |\n",
      "|    std                | 93.8      |\n",
      "|    value_loss         | 7.29      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 41646     |\n",
      "|    total_timesteps    | 970000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -59.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -145      |\n",
      "|    reward             | -0.002595 |\n",
      "|    std                | 94.6      |\n",
      "|    value_loss         | 19.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 42064    |\n",
      "|    total_timesteps    | 980000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -59.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 42.9     |\n",
      "|    reward             | 0.028228 |\n",
      "|    std                | 96.2     |\n",
      "|    value_loss         | 0.61     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 42482     |\n",
      "|    total_timesteps    | 990000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 28.9      |\n",
      "|    reward             | 0.00804   |\n",
      "|    std                | 97.6      |\n",
      "|    value_loss         | 0.332     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 42899    |\n",
      "|    total_timesteps    | 1000000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -42.4    |\n",
      "|    reward             | -1.3e-05 |\n",
      "|    std                | 98.5     |\n",
      "|    value_loss         | 0.801    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 43317     |\n",
      "|    total_timesteps    | 1010000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | 31.7      |\n",
      "|    reward             | -0.000278 |\n",
      "|    std                | 99.3      |\n",
      "|    value_loss         | 0.538     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 43734     |\n",
      "|    total_timesteps    | 1020000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -525      |\n",
      "|    reward             | -0.000178 |\n",
      "|    std                | 99.6      |\n",
      "|    value_loss         | 95.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 44151     |\n",
      "|    total_timesteps    | 1030000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | 47.3      |\n",
      "|    reward             | -0.000109 |\n",
      "|    std                | 99.8      |\n",
      "|    value_loss         | 2.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 44567     |\n",
      "|    total_timesteps    | 1040000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 176       |\n",
      "|    reward             | -0.002876 |\n",
      "|    std                | 100       |\n",
      "|    value_loss         | 9.89      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 44982     |\n",
      "|    total_timesteps    | 1050000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | 10.5      |\n",
      "|    reward             | -0.026214 |\n",
      "|    std                | 101       |\n",
      "|    value_loss         | 0.0666    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 45399     |\n",
      "|    total_timesteps    | 1060000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | 71.4      |\n",
      "|    reward             | -0.055015 |\n",
      "|    std                | 102       |\n",
      "|    value_loss         | 1.9       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 45817     |\n",
      "|    total_timesteps    | 1070000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -48.2     |\n",
      "|    reward             | -0.000239 |\n",
      "|    std                | 103       |\n",
      "|    value_loss         | 1.25      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 46234    |\n",
      "|    total_timesteps    | 1080000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | 18       |\n",
      "|    reward             | -3.7e-05 |\n",
      "|    std                | 104      |\n",
      "|    value_loss         | 1.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 10900    |\n",
      "|    time_elapsed       | 46650    |\n",
      "|    total_timesteps    | 1090000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -60.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10899    |\n",
      "|    policy_loss        | -52.5    |\n",
      "|    reward             | -0.98135 |\n",
      "|    std                | 105      |\n",
      "|    value_loss         | 2.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 47084     |\n",
      "|    total_timesteps    | 1100000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | 200       |\n",
      "|    reward             | -0.001539 |\n",
      "|    std                | 105       |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 47520     |\n",
      "|    total_timesteps    | 1110000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | 19.7      |\n",
      "|    reward             | -0.750134 |\n",
      "|    std                | 105       |\n",
      "|    value_loss         | 2.25      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 47956     |\n",
      "|    total_timesteps    | 1120000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | 60.3      |\n",
      "|    reward             | -0.586911 |\n",
      "|    std                | 106       |\n",
      "|    value_loss         | 2.5       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 48394     |\n",
      "|    total_timesteps    | 1130000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -60.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | 1.73      |\n",
      "|    reward             | -0.003506 |\n",
      "|    std                | 107       |\n",
      "|    value_loss         | 0.261     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 48821     |\n",
      "|    total_timesteps    | 1140000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    reward             | -0.002207 |\n",
      "|    std                | 109       |\n",
      "|    value_loss         | 0.847     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 49246    |\n",
      "|    total_timesteps    | 1150000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 7.91     |\n",
      "|    reward             | -6.4e-05 |\n",
      "|    std                | 109      |\n",
      "|    value_loss         | 0.242    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 49671     |\n",
      "|    total_timesteps    | 1160000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | -477      |\n",
      "|    reward             | -0.001341 |\n",
      "|    std                | 110       |\n",
      "|    value_loss         | 115       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 50096     |\n",
      "|    total_timesteps    | 1170000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | 85.9      |\n",
      "|    reward             | -0.000706 |\n",
      "|    std                | 111       |\n",
      "|    value_loss         | 4.7       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 50521     |\n",
      "|    total_timesteps    | 1180000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -5.94     |\n",
      "|    reward             | -0.000377 |\n",
      "|    std                | 111       |\n",
      "|    value_loss         | 3.23      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 50945     |\n",
      "|    total_timesteps    | 1190000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | -132      |\n",
      "|    reward             | -0.000841 |\n",
      "|    std                | 110       |\n",
      "|    value_loss         | 9.32      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 51369     |\n",
      "|    total_timesteps    | 1200000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -24.5     |\n",
      "|    reward             | -0.000149 |\n",
      "|    std                | 111       |\n",
      "|    value_loss         | 0.173     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 51795    |\n",
      "|    total_timesteps    | 1210000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.4    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -92.4    |\n",
      "|    reward             | 0.103169 |\n",
      "|    std                | 113      |\n",
      "|    value_loss         | 2.61     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 52221     |\n",
      "|    total_timesteps    | 1220000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | 15.9      |\n",
      "|    reward             | -0.108397 |\n",
      "|    std                | 114       |\n",
      "|    value_loss         | 3.08      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 12300          |\n",
      "|    time_elapsed       | 52646          |\n",
      "|    total_timesteps    | 1230000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -61.6          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 12299          |\n",
      "|    policy_loss        | -57.9          |\n",
      "|    reward             | -2.1000002e-05 |\n",
      "|    std                | 114            |\n",
      "|    value_loss         | 1.16           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 12400         |\n",
      "|    time_elapsed       | 53070         |\n",
      "|    total_timesteps    | 1240000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -61.6         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12399         |\n",
      "|    policy_loss        | -216          |\n",
      "|    reward             | -0.0021859999 |\n",
      "|    std                | 114           |\n",
      "|    value_loss         | 17.3          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 53493    |\n",
      "|    total_timesteps    | 1250000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -61.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 3.4      |\n",
      "|    reward             | -3.2e-05 |\n",
      "|    std                | 114      |\n",
      "|    value_loss         | 5.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 53917     |\n",
      "|    total_timesteps    | 1260000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | 262       |\n",
      "|    reward             | -0.818336 |\n",
      "|    std                | 114       |\n",
      "|    value_loss         | 22.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 54340     |\n",
      "|    total_timesteps    | 1270000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | 387       |\n",
      "|    reward             | -0.000119 |\n",
      "|    std                | 115       |\n",
      "|    value_loss         | 49.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 54764     |\n",
      "|    total_timesteps    | 1280000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -14.2     |\n",
      "|    reward             | -0.001948 |\n",
      "|    std                | 117       |\n",
      "|    value_loss         | 0.121     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 55190     |\n",
      "|    total_timesteps    | 1290000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -61.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | 137       |\n",
      "|    reward             | -0.000159 |\n",
      "|    std                | 118       |\n",
      "|    value_loss         | 6.44      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 13000          |\n",
      "|    time_elapsed       | 55615          |\n",
      "|    total_timesteps    | 1300000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -61.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 12999          |\n",
      "|    policy_loss        | -109           |\n",
      "|    reward             | -2.3999995e-05 |\n",
      "|    std                | 119            |\n",
      "|    value_loss         | 3.53           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 13100          |\n",
      "|    time_elapsed       | 56033          |\n",
      "|    total_timesteps    | 1310000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -62            |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 13099          |\n",
      "|    policy_loss        | 53.6           |\n",
      "|    reward             | -2.2999995e-05 |\n",
      "|    std                | 119            |\n",
      "|    value_loss         | 18.1           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 13200         |\n",
      "|    time_elapsed       | 56449         |\n",
      "|    total_timesteps    | 1320000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -62           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13199         |\n",
      "|    policy_loss        | 183           |\n",
      "|    reward             | -3.499999e-05 |\n",
      "|    std                | 120           |\n",
      "|    value_loss         | 21.4          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 56865    |\n",
      "|    total_timesteps    | 1330000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -486     |\n",
      "|    reward             | -0.00013 |\n",
      "|    std                | 120      |\n",
      "|    value_loss         | 88.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 57281    |\n",
      "|    total_timesteps    | 1340000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | -190     |\n",
      "|    reward             | 6.221397 |\n",
      "|    std                | 120      |\n",
      "|    value_loss         | 31.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 57695    |\n",
      "|    total_timesteps    | 1350000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 19       |\n",
      "|    reward             | -0.0032  |\n",
      "|    std                | 121      |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 58111     |\n",
      "|    total_timesteps    | 1360000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | -13.1     |\n",
      "|    reward             | -0.001009 |\n",
      "|    std                | 123       |\n",
      "|    value_loss         | 0.346     |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 13700         |\n",
      "|    time_elapsed       | 58528         |\n",
      "|    total_timesteps    | 1370000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -62.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13699         |\n",
      "|    policy_loss        | -235          |\n",
      "|    reward             | -6.999999e-06 |\n",
      "|    std                | 124           |\n",
      "|    value_loss         | 18.1          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 58944     |\n",
      "|    total_timesteps    | 1380000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.4     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 157       |\n",
      "|    reward             | -0.000893 |\n",
      "|    std                | 124       |\n",
      "|    value_loss         | 7.76      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 59359     |\n",
      "|    total_timesteps    | 1390000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 124       |\n",
      "|    reward             | -2.031464 |\n",
      "|    std                | 124       |\n",
      "|    value_loss         | 6.28      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 59775     |\n",
      "|    total_timesteps    | 1400000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | 224       |\n",
      "|    reward             | -0.000231 |\n",
      "|    std                | 125       |\n",
      "|    value_loss         | 16        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 60191     |\n",
      "|    total_timesteps    | 1410000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -277      |\n",
      "|    reward             | -0.00112  |\n",
      "|    std                | 125       |\n",
      "|    value_loss         | 33.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 14200    |\n",
      "|    time_elapsed       | 60605    |\n",
      "|    total_timesteps    | 1420000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14199    |\n",
      "|    policy_loss        | 1.39     |\n",
      "|    reward             | 0.390488 |\n",
      "|    std                | 125      |\n",
      "|    value_loss         | 11.6     |\n",
      "------------------------------------\n",
      "Moment: 74871, episode: 20\n",
      "begin_total_asset: -601771669.24\n",
      "end_total_asset: -564490.26\n",
      "total_reward: -664490.26\n",
      "total_trades: 351644\n",
      "Sharpe: 0.093\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 61023     |\n",
      "|    total_timesteps    | 1430000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | 37        |\n",
      "|    reward             | -0.001228 |\n",
      "|    std                | 127       |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 61441     |\n",
      "|    total_timesteps    | 1440000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | 108       |\n",
      "|    reward             | -0.001501 |\n",
      "|    std                | 129       |\n",
      "|    value_loss         | 4.32      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 14500    |\n",
      "|    time_elapsed       | 61859    |\n",
      "|    total_timesteps    | 1450000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14499    |\n",
      "|    policy_loss        | 80.6     |\n",
      "|    reward             | -0.00293 |\n",
      "|    std                | 129      |\n",
      "|    value_loss         | 1.72     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 62275    |\n",
      "|    total_timesteps    | 1460000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -62.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | -36.3    |\n",
      "|    reward             | -7.9e-05 |\n",
      "|    std                | 130      |\n",
      "|    value_loss         | 3.39     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 62693     |\n",
      "|    total_timesteps    | 1470000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -64.1     |\n",
      "|    reward             | -0.001018 |\n",
      "|    std                | 130       |\n",
      "|    value_loss         | 3.33      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 14800          |\n",
      "|    time_elapsed       | 63110          |\n",
      "|    total_timesteps    | 1480000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -62.9          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 14799          |\n",
      "|    policy_loss        | -107           |\n",
      "|    reward             | -1.3999993e-05 |\n",
      "|    std                | 130            |\n",
      "|    value_loss         | 5.42           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 63527     |\n",
      "|    total_timesteps    | 1490000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | -29.3     |\n",
      "|    reward             | -0.000125 |\n",
      "|    std                | 131       |\n",
      "|    value_loss         | 3.9       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 63941     |\n",
      "|    total_timesteps    | 1500000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -62.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -69.1     |\n",
      "|    reward             | -0.003626 |\n",
      "|    std                | 131       |\n",
      "|    value_loss         | 1.34      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 15100    |\n",
      "|    time_elapsed       | 64358    |\n",
      "|    total_timesteps    | 1510000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.1    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15099    |\n",
      "|    policy_loss        | -71.6    |\n",
      "|    reward             | -4.6e-05 |\n",
      "|    std                | 133      |\n",
      "|    value_loss         | 1.5      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 64776     |\n",
      "|    total_timesteps    | 1520000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | -8.77     |\n",
      "|    reward             | -0.001232 |\n",
      "|    std                | 134       |\n",
      "|    value_loss         | 1.39      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 65192     |\n",
      "|    total_timesteps    | 1530000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | 216       |\n",
      "|    reward             | -0.000111 |\n",
      "|    std                | 135       |\n",
      "|    value_loss         | 21.2      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 15400          |\n",
      "|    time_elapsed       | 65608          |\n",
      "|    total_timesteps    | 1540000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -63.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 15399          |\n",
      "|    policy_loss        | -375           |\n",
      "|    reward             | -1.3000005e-05 |\n",
      "|    std                | 135            |\n",
      "|    value_loss         | 37.1           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 15500    |\n",
      "|    time_elapsed       | 66024    |\n",
      "|    total_timesteps    | 1550000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15499    |\n",
      "|    policy_loss        | -11.8    |\n",
      "|    reward             | 0.320136 |\n",
      "|    std                | 136      |\n",
      "|    value_loss         | 2.89     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 66441    |\n",
      "|    total_timesteps    | 1560000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | 21.2     |\n",
      "|    reward             | -0.00093 |\n",
      "|    std                | 137      |\n",
      "|    value_loss         | 14.7     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 15700          |\n",
      "|    time_elapsed       | 66856          |\n",
      "|    total_timesteps    | 1570000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -63.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 15699          |\n",
      "|    policy_loss        | 552            |\n",
      "|    reward             | -0.00020600001 |\n",
      "|    std                | 137            |\n",
      "|    value_loss         | 104            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 67273     |\n",
      "|    total_timesteps    | 1580000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | 44.2      |\n",
      "|    reward             | -0.053647 |\n",
      "|    std                | 139       |\n",
      "|    value_loss         | 1.24      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 67691    |\n",
      "|    total_timesteps    | 1590000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | 27.2     |\n",
      "|    reward             | 0.102133 |\n",
      "|    std                | 140      |\n",
      "|    value_loss         | 1.73     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 16000          |\n",
      "|    time_elapsed       | 68109          |\n",
      "|    total_timesteps    | 1600000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -63.7          |\n",
      "|    explained_variance | 1.79e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 15999          |\n",
      "|    policy_loss        | -108           |\n",
      "|    reward             | -0.00031899998 |\n",
      "|    std                | 142            |\n",
      "|    value_loss         | 4.35           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 68528     |\n",
      "|    total_timesteps    | 1610000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 149       |\n",
      "|    reward             | -0.002306 |\n",
      "|    std                | 142       |\n",
      "|    value_loss         | 10.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 68945     |\n",
      "|    total_timesteps    | 1620000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | 193       |\n",
      "|    reward             | -0.001029 |\n",
      "|    std                | 142       |\n",
      "|    value_loss         | 14.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 16300    |\n",
      "|    time_elapsed       | 69362    |\n",
      "|    total_timesteps    | 1630000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16299    |\n",
      "|    policy_loss        | -281     |\n",
      "|    reward             | 2.905604 |\n",
      "|    std                | 143      |\n",
      "|    value_loss         | 27.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 69778     |\n",
      "|    total_timesteps    | 1640000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -63.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 68.9      |\n",
      "|    reward             | -0.001505 |\n",
      "|    std                | 143       |\n",
      "|    value_loss         | 16.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 16500    |\n",
      "|    time_elapsed       | 70196    |\n",
      "|    total_timesteps    | 1650000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -63.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16499    |\n",
      "|    policy_loss        | 33.7     |\n",
      "|    reward             | 0.040272 |\n",
      "|    std                | 145      |\n",
      "|    value_loss         | 0.424    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 70614    |\n",
      "|    total_timesteps    | 1660000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 8.54     |\n",
      "|    reward             | 0.990249 |\n",
      "|    std                | 146      |\n",
      "|    value_loss         | 0.205    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 71035     |\n",
      "|    total_timesteps    | 1670000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -191      |\n",
      "|    reward             | 1.149983  |\n",
      "|    std                | 147       |\n",
      "|    value_loss         | 14.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 71455    |\n",
      "|    total_timesteps    | 1680000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -33.1    |\n",
      "|    reward             | 0.217337 |\n",
      "|    std                | 147      |\n",
      "|    value_loss         | 5.01     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 16900          |\n",
      "|    time_elapsed       | 71874          |\n",
      "|    total_timesteps    | 1690000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -64.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 16899          |\n",
      "|    policy_loss        | 163            |\n",
      "|    reward             | -1.1999995e-05 |\n",
      "|    std                | 148            |\n",
      "|    value_loss         | 9.68           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 17000          |\n",
      "|    time_elapsed       | 72293          |\n",
      "|    total_timesteps    | 1700000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -64.2          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 16999          |\n",
      "|    policy_loss        | -394           |\n",
      "|    reward             | -0.00015600001 |\n",
      "|    std                | 148            |\n",
      "|    value_loss         | 55.1           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 72713     |\n",
      "|    total_timesteps    | 1710000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | 76.6      |\n",
      "|    reward             | -0.000138 |\n",
      "|    std                | 148       |\n",
      "|    value_loss         | 6.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 73132     |\n",
      "|    total_timesteps    | 1720000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -366      |\n",
      "|    reward             | -0.003785 |\n",
      "|    std                | 148       |\n",
      "|    value_loss         | 262       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 73551     |\n",
      "|    total_timesteps    | 1730000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | -5.1      |\n",
      "|    reward             | -0.001542 |\n",
      "|    std                | 150       |\n",
      "|    value_loss         | 2.6       |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 17400          |\n",
      "|    time_elapsed       | 73970          |\n",
      "|    total_timesteps    | 1740000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -64.3          |\n",
      "|    explained_variance | 1.79e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 17399          |\n",
      "|    policy_loss        | -75.7          |\n",
      "|    reward             | -4.0999996e-05 |\n",
      "|    std                | 150            |\n",
      "|    value_loss         | 2.92           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 74390     |\n",
      "|    total_timesteps    | 1750000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.3     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 121       |\n",
      "|    reward             | -0.000145 |\n",
      "|    std                | 151       |\n",
      "|    value_loss         | 6.45      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 17600    |\n",
      "|    time_elapsed       | 74810    |\n",
      "|    total_timesteps    | 1760000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17599    |\n",
      "|    policy_loss        | 16.7     |\n",
      "|    reward             | -0.00028 |\n",
      "|    std                | 152      |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 17700          |\n",
      "|    time_elapsed       | 75230          |\n",
      "|    total_timesteps    | 1770000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -64.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 17699          |\n",
      "|    policy_loss        | 119            |\n",
      "|    reward             | -2.3000002e-05 |\n",
      "|    std                | 152            |\n",
      "|    value_loss         | 5.1            |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 17800    |\n",
      "|    time_elapsed       | 75648    |\n",
      "|    total_timesteps    | 1780000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17799    |\n",
      "|    policy_loss        | 159      |\n",
      "|    reward             | 1.906308 |\n",
      "|    std                | 153      |\n",
      "|    value_loss         | 49.3     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 17900          |\n",
      "|    time_elapsed       | 76065          |\n",
      "|    total_timesteps    | 1790000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -64.5          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 17899          |\n",
      "|    policy_loss        | -190           |\n",
      "|    reward             | -0.00037800003 |\n",
      "|    std                | 153            |\n",
      "|    value_loss         | 20.4           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 18000    |\n",
      "|    time_elapsed       | 76483    |\n",
      "|    total_timesteps    | 1800000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -46.8    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 154      |\n",
      "|    value_loss         | 0.607    |\n",
      "------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 23              |\n",
      "|    iterations         | 18100           |\n",
      "|    time_elapsed       | 76902           |\n",
      "|    total_timesteps    | 1810000         |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -64.6           |\n",
      "|    explained_variance | 1.79e-07        |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 18099           |\n",
      "|    policy_loss        | 86.4            |\n",
      "|    reward             | -0.000113999995 |\n",
      "|    std                | 156             |\n",
      "|    value_loss         | 3.04            |\n",
      "-------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 77321     |\n",
      "|    total_timesteps    | 1820000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | -145      |\n",
      "|    reward             | -0.498896 |\n",
      "|    std                | 157       |\n",
      "|    value_loss         | 6.64      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 18300          |\n",
      "|    time_elapsed       | 77740          |\n",
      "|    total_timesteps    | 1830000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -64.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 18299          |\n",
      "|    policy_loss        | 51.9           |\n",
      "|    reward             | -0.00014800002 |\n",
      "|    std                | 158            |\n",
      "|    value_loss         | 9.02           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 18400          |\n",
      "|    time_elapsed       | 78165          |\n",
      "|    total_timesteps    | 1840000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -64.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 18399          |\n",
      "|    policy_loss        | -829           |\n",
      "|    reward             | -0.00026200002 |\n",
      "|    std                | 159            |\n",
      "|    value_loss         | 195            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 78591     |\n",
      "|    total_timesteps    | 1850000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | 5.58      |\n",
      "|    reward             | -1.123833 |\n",
      "|    std                | 159       |\n",
      "|    value_loss         | 1.35      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 79018    |\n",
      "|    total_timesteps    | 1860000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -64.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | 162      |\n",
      "|    reward             | -0.00035 |\n",
      "|    std                | 159      |\n",
      "|    value_loss         | 28.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 79443     |\n",
      "|    total_timesteps    | 1870000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -86.2     |\n",
      "|    reward             | -0.001121 |\n",
      "|    std                | 159       |\n",
      "|    value_loss         | 11.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 79869     |\n",
      "|    total_timesteps    | 1880000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -64.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | -15.4     |\n",
      "|    reward             | -0.101579 |\n",
      "|    std                | 160       |\n",
      "|    value_loss         | 0.245     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 80296     |\n",
      "|    total_timesteps    | 1890000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | 238       |\n",
      "|    reward             | -0.140672 |\n",
      "|    std                | 161       |\n",
      "|    value_loss         | 15.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 80722     |\n",
      "|    total_timesteps    | 1900000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | -108      |\n",
      "|    reward             | -0.000611 |\n",
      "|    std                | 162       |\n",
      "|    value_loss         | 5.39      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 19100    |\n",
      "|    time_elapsed       | 81148    |\n",
      "|    total_timesteps    | 1910000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 19099    |\n",
      "|    policy_loss        | -51.5    |\n",
      "|    reward             | -4.7e-05 |\n",
      "|    std                | 162      |\n",
      "|    value_loss         | 2.73     |\n",
      "------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 23              |\n",
      "|    iterations         | 19200           |\n",
      "|    time_elapsed       | 81574           |\n",
      "|    total_timesteps    | 1920000         |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -65.1           |\n",
      "|    explained_variance | 1.19e-07        |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 19199           |\n",
      "|    policy_loss        | -145            |\n",
      "|    reward             | -0.000121999976 |\n",
      "|    std                | 163             |\n",
      "|    value_loss         | 7.01            |\n",
      "-------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 82001     |\n",
      "|    total_timesteps    | 1930000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | -486      |\n",
      "|    reward             | -0.001424 |\n",
      "|    std                | 163       |\n",
      "|    value_loss         | 108       |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 19400         |\n",
      "|    time_elapsed       | 82426         |\n",
      "|    total_timesteps    | 1940000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -65.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19399         |\n",
      "|    policy_loss        | 66.6          |\n",
      "|    reward             | -0.0012620001 |\n",
      "|    std                | 163           |\n",
      "|    value_loss         | 17.9          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 82849     |\n",
      "|    total_timesteps    | 1950000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | -32.3     |\n",
      "|    reward             | -0.001141 |\n",
      "|    std                | 164       |\n",
      "|    value_loss         | 0.322     |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 19600          |\n",
      "|    time_elapsed       | 83273          |\n",
      "|    total_timesteps    | 1960000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -65.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 19599          |\n",
      "|    policy_loss        | -18.9          |\n",
      "|    reward             | -6.0000002e-05 |\n",
      "|    std                | 166            |\n",
      "|    value_loss         | 0.4            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 83697     |\n",
      "|    total_timesteps    | 1970000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | -161      |\n",
      "|    reward             | -0.000149 |\n",
      "|    std                | 167       |\n",
      "|    value_loss         | 8.3       |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 19800          |\n",
      "|    time_elapsed       | 84122          |\n",
      "|    total_timesteps    | 1980000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -65.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 19799          |\n",
      "|    policy_loss        | 126            |\n",
      "|    reward             | -0.00092799996 |\n",
      "|    std                | 167            |\n",
      "|    value_loss         | 4.87           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 84547     |\n",
      "|    total_timesteps    | 1990000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | 129       |\n",
      "|    reward             | -0.000992 |\n",
      "|    std                | 167       |\n",
      "|    value_loss         | 27        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 84971     |\n",
      "|    total_timesteps    | 2000000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -259      |\n",
      "|    reward             | -0.000633 |\n",
      "|    std                | 168       |\n",
      "|    value_loss         | 67.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20100     |\n",
      "|    time_elapsed       | 85395     |\n",
      "|    total_timesteps    | 2010000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20099     |\n",
      "|    policy_loss        | 283       |\n",
      "|    reward             | -0.000169 |\n",
      "|    std                | 168       |\n",
      "|    value_loss         | 21.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20200     |\n",
      "|    time_elapsed       | 85819     |\n",
      "|    total_timesteps    | 2020000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20199     |\n",
      "|    policy_loss        | -124      |\n",
      "|    reward             | -0.000174 |\n",
      "|    std                | 168       |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20300     |\n",
      "|    time_elapsed       | 86244     |\n",
      "|    total_timesteps    | 2030000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20299     |\n",
      "|    policy_loss        | -20.8     |\n",
      "|    reward             | -0.002181 |\n",
      "|    std                | 170       |\n",
      "|    value_loss         | 0.89      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20400     |\n",
      "|    time_elapsed       | 86669     |\n",
      "|    total_timesteps    | 2040000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20399     |\n",
      "|    policy_loss        | -33.5     |\n",
      "|    reward             | -0.002943 |\n",
      "|    std                | 171       |\n",
      "|    value_loss         | 2.34      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20500     |\n",
      "|    time_elapsed       | 87094     |\n",
      "|    total_timesteps    | 2050000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20499     |\n",
      "|    policy_loss        | -7.43     |\n",
      "|    reward             | -0.002114 |\n",
      "|    std                | 171       |\n",
      "|    value_loss         | 1.2       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20600     |\n",
      "|    time_elapsed       | 87513     |\n",
      "|    total_timesteps    | 2060000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20599     |\n",
      "|    policy_loss        | 266       |\n",
      "|    reward             | -0.000132 |\n",
      "|    std                | 171       |\n",
      "|    value_loss         | 29.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20700     |\n",
      "|    time_elapsed       | 87931     |\n",
      "|    total_timesteps    | 2070000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20699     |\n",
      "|    policy_loss        | 363       |\n",
      "|    reward             | -0.001827 |\n",
      "|    std                | 172       |\n",
      "|    value_loss         | 38.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 20800     |\n",
      "|    time_elapsed       | 88350     |\n",
      "|    total_timesteps    | 2080000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 20799     |\n",
      "|    policy_loss        | -894      |\n",
      "|    reward             | -0.001527 |\n",
      "|    std                | 172       |\n",
      "|    value_loss         | 250       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 20900    |\n",
      "|    time_elapsed       | 88765    |\n",
      "|    total_timesteps    | 2090000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20899    |\n",
      "|    policy_loss        | -241     |\n",
      "|    reward             | -3.6e-05 |\n",
      "|    std                | 172      |\n",
      "|    value_loss         | 68.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 21000    |\n",
      "|    time_elapsed       | 89182    |\n",
      "|    total_timesteps    | 2100000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 20999    |\n",
      "|    policy_loss        | -57.7    |\n",
      "|    reward             | 0.147186 |\n",
      "|    std                | 173      |\n",
      "|    value_loss         | 0.871    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 21100    |\n",
      "|    time_elapsed       | 89599    |\n",
      "|    total_timesteps    | 2110000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21099    |\n",
      "|    policy_loss        | 15.1     |\n",
      "|    reward             | 0.86749  |\n",
      "|    std                | 174      |\n",
      "|    value_loss         | 8.68     |\n",
      "------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 23              |\n",
      "|    iterations         | 21200           |\n",
      "|    time_elapsed       | 90016           |\n",
      "|    total_timesteps    | 2120000         |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -65.8           |\n",
      "|    explained_variance | 5.96e-08        |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 21199           |\n",
      "|    policy_loss        | 243             |\n",
      "|    reward             | -0.000115999996 |\n",
      "|    std                | 174             |\n",
      "|    value_loss         | 27.4            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 21300          |\n",
      "|    time_elapsed       | 90433          |\n",
      "|    total_timesteps    | 2130000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -65.8          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 21299          |\n",
      "|    policy_loss        | -34.7          |\n",
      "|    reward             | -1.1999995e-05 |\n",
      "|    std                | 175            |\n",
      "|    value_loss         | 6.93           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 21400         |\n",
      "|    time_elapsed       | 90852         |\n",
      "|    total_timesteps    | 2140000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -65.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21399         |\n",
      "|    policy_loss        | 37.9          |\n",
      "|    reward             | -7.200001e-05 |\n",
      "|    std                | 176           |\n",
      "|    value_loss         | 25.8          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 21500     |\n",
      "|    time_elapsed       | 91270     |\n",
      "|    total_timesteps    | 2150000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -65.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21499     |\n",
      "|    policy_loss        | -408      |\n",
      "|    reward             | -0.000208 |\n",
      "|    std                | 176       |\n",
      "|    value_loss         | 40.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 21600    |\n",
      "|    time_elapsed       | 91687    |\n",
      "|    total_timesteps    | 2160000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21599    |\n",
      "|    policy_loss        | 8.05     |\n",
      "|    reward             | 0.620296 |\n",
      "|    std                | 177      |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 21700    |\n",
      "|    time_elapsed       | 92103    |\n",
      "|    total_timesteps    | 2170000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -65.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21699    |\n",
      "|    policy_loss        | 284      |\n",
      "|    reward             | 1.161573 |\n",
      "|    std                | 177      |\n",
      "|    value_loss         | 27.9     |\n",
      "------------------------------------\n",
      "Moment: 74871, episode: 30\n",
      "begin_total_asset: -912173549.24\n",
      "end_total_asset: -784383.13\n",
      "total_reward: -884383.13\n",
      "total_trades: 357508\n",
      "Sharpe: 0.109\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 21800     |\n",
      "|    time_elapsed       | 92520     |\n",
      "|    total_timesteps    | 2180000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21799     |\n",
      "|    policy_loss        | 3.63      |\n",
      "|    reward             | -0.002519 |\n",
      "|    std                | 179       |\n",
      "|    value_loss         | 0.35      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 21900     |\n",
      "|    time_elapsed       | 92939     |\n",
      "|    total_timesteps    | 2190000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21899     |\n",
      "|    policy_loss        | 28.3      |\n",
      "|    reward             | -0.001554 |\n",
      "|    std                | 180       |\n",
      "|    value_loss         | 1.73      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22000     |\n",
      "|    time_elapsed       | 93358     |\n",
      "|    total_timesteps    | 2200000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 21999     |\n",
      "|    policy_loss        | 34        |\n",
      "|    reward             | -0.002247 |\n",
      "|    std                | 180       |\n",
      "|    value_loss         | 6.47      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 22100          |\n",
      "|    time_elapsed       | 93779          |\n",
      "|    total_timesteps    | 2210000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -66.1          |\n",
      "|    explained_variance | 1.79e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 22099          |\n",
      "|    policy_loss        | 507            |\n",
      "|    reward             | -0.00032599998 |\n",
      "|    std                | 180            |\n",
      "|    value_loss         | 69.5           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22200     |\n",
      "|    time_elapsed       | 94199     |\n",
      "|    total_timesteps    | 2220000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22199     |\n",
      "|    policy_loss        | 233       |\n",
      "|    reward             | -0.001961 |\n",
      "|    std                | 181       |\n",
      "|    value_loss         | 39.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22300     |\n",
      "|    time_elapsed       | 94619     |\n",
      "|    total_timesteps    | 2230000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22299     |\n",
      "|    policy_loss        | -554      |\n",
      "|    reward             | -0.002295 |\n",
      "|    std                | 181       |\n",
      "|    value_loss         | 121       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22400     |\n",
      "|    time_elapsed       | 95037     |\n",
      "|    total_timesteps    | 2240000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22399     |\n",
      "|    policy_loss        | -701      |\n",
      "|    reward             | -0.003031 |\n",
      "|    std                | 181       |\n",
      "|    value_loss         | 204       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 22500    |\n",
      "|    time_elapsed       | 95455    |\n",
      "|    total_timesteps    | 2250000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 22499    |\n",
      "|    policy_loss        | -32.7    |\n",
      "|    reward             | 0.031593 |\n",
      "|    std                | 181      |\n",
      "|    value_loss         | 0.309    |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 22600          |\n",
      "|    time_elapsed       | 95875          |\n",
      "|    total_timesteps    | 2260000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -66.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 22599          |\n",
      "|    policy_loss        | 49.8           |\n",
      "|    reward             | -7.8000005e-05 |\n",
      "|    std                | 183            |\n",
      "|    value_loss         | 3.56           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22700     |\n",
      "|    time_elapsed       | 96295     |\n",
      "|    total_timesteps    | 2270000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22699     |\n",
      "|    policy_loss        | 1.35      |\n",
      "|    reward             | -0.002319 |\n",
      "|    std                | 183       |\n",
      "|    value_loss         | 16.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22800     |\n",
      "|    time_elapsed       | 96714     |\n",
      "|    total_timesteps    | 2280000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22799     |\n",
      "|    policy_loss        | 130       |\n",
      "|    reward             | -0.000396 |\n",
      "|    std                | 184       |\n",
      "|    value_loss         | 5.28      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 22900     |\n",
      "|    time_elapsed       | 97133     |\n",
      "|    total_timesteps    | 2290000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22899     |\n",
      "|    policy_loss        | -72.3     |\n",
      "|    reward             | -0.001851 |\n",
      "|    std                | 184       |\n",
      "|    value_loss         | 6.39      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 23000     |\n",
      "|    time_elapsed       | 97553     |\n",
      "|    total_timesteps    | 2300000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22999     |\n",
      "|    policy_loss        | -8.85     |\n",
      "|    reward             | -0.001843 |\n",
      "|    std                | 184       |\n",
      "|    value_loss         | 1.85      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 23100          |\n",
      "|    time_elapsed       | 97972          |\n",
      "|    total_timesteps    | 2310000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -66.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 23099          |\n",
      "|    policy_loss        | -159           |\n",
      "|    reward             | -3.1999993e-05 |\n",
      "|    std                | 184            |\n",
      "|    value_loss         | 39.5           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 23200     |\n",
      "|    time_elapsed       | 98389     |\n",
      "|    total_timesteps    | 2320000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23199     |\n",
      "|    policy_loss        | 243       |\n",
      "|    reward             | -0.000229 |\n",
      "|    std                | 185       |\n",
      "|    value_loss         | 27.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 23300     |\n",
      "|    time_elapsed       | 98809     |\n",
      "|    total_timesteps    | 2330000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23299     |\n",
      "|    policy_loss        | -103      |\n",
      "|    reward             | -0.000344 |\n",
      "|    std                | 187       |\n",
      "|    value_loss         | 3.69      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 23400     |\n",
      "|    time_elapsed       | 99228     |\n",
      "|    total_timesteps    | 2340000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23399     |\n",
      "|    policy_loss        | 67.5      |\n",
      "|    reward             | -0.001952 |\n",
      "|    std                | 188       |\n",
      "|    value_loss         | 1.56      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 23500     |\n",
      "|    time_elapsed       | 99648     |\n",
      "|    total_timesteps    | 2350000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23499     |\n",
      "|    policy_loss        | -183      |\n",
      "|    reward             | -0.003703 |\n",
      "|    std                | 189       |\n",
      "|    value_loss         | 14.2      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 23600          |\n",
      "|    time_elapsed       | 100067         |\n",
      "|    total_timesteps    | 2360000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -66.6          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 23599          |\n",
      "|    policy_loss        | 138            |\n",
      "|    reward             | -0.00018399999 |\n",
      "|    std                | 190            |\n",
      "|    value_loss         | 7.66           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 23700    |\n",
      "|    time_elapsed       | 100487   |\n",
      "|    total_timesteps    | 2370000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 23699    |\n",
      "|    policy_loss        | 304      |\n",
      "|    reward             | 3.31169  |\n",
      "|    std                | 190      |\n",
      "|    value_loss         | 33.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 23800     |\n",
      "|    time_elapsed       | 100907    |\n",
      "|    total_timesteps    | 2380000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23799     |\n",
      "|    policy_loss        | -351      |\n",
      "|    reward             | -0.000209 |\n",
      "|    std                | 190       |\n",
      "|    value_loss         | 45.8      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 23900          |\n",
      "|    time_elapsed       | 101325         |\n",
      "|    total_timesteps    | 2390000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -66.6          |\n",
      "|    explained_variance | -2.38e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 23899          |\n",
      "|    policy_loss        | -187           |\n",
      "|    reward             | -4.6000005e-05 |\n",
      "|    std                | 190            |\n",
      "|    value_loss         | 19             |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24000     |\n",
      "|    time_elapsed       | 101744    |\n",
      "|    total_timesteps    | 2400000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 23999     |\n",
      "|    policy_loss        | -1.07     |\n",
      "|    reward             | -0.004125 |\n",
      "|    std                | 191       |\n",
      "|    value_loss         | 0.0353    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24100     |\n",
      "|    time_elapsed       | 102164    |\n",
      "|    total_timesteps    | 2410000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24099     |\n",
      "|    policy_loss        | 20        |\n",
      "|    reward             | -0.001456 |\n",
      "|    std                | 193       |\n",
      "|    value_loss         | 0.808     |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 24200          |\n",
      "|    time_elapsed       | 102584         |\n",
      "|    total_timesteps    | 2420000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -66.9          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 24199          |\n",
      "|    policy_loss        | -354           |\n",
      "|    reward             | -4.2999996e-05 |\n",
      "|    std                | 195            |\n",
      "|    value_loss         | 35.6           |\n",
      "------------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 24300    |\n",
      "|    time_elapsed       | 103004   |\n",
      "|    total_timesteps    | 2430000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24299    |\n",
      "|    policy_loss        | -480     |\n",
      "|    reward             | 7.070641 |\n",
      "|    std                | 195      |\n",
      "|    value_loss         | 63.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24400     |\n",
      "|    time_elapsed       | 103424    |\n",
      "|    total_timesteps    | 2440000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -66.9     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24399     |\n",
      "|    policy_loss        | -366      |\n",
      "|    reward             | -0.001027 |\n",
      "|    std                | 196       |\n",
      "|    value_loss         | 42.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 24500    |\n",
      "|    time_elapsed       | 103843   |\n",
      "|    total_timesteps    | 2450000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -66.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 24499    |\n",
      "|    policy_loss        | 888      |\n",
      "|    reward             | -0.00024 |\n",
      "|    std                | 196      |\n",
      "|    value_loss         | 197      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24600     |\n",
      "|    time_elapsed       | 104263    |\n",
      "|    total_timesteps    | 2460000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24599     |\n",
      "|    policy_loss        | 55.8      |\n",
      "|    reward             | -0.000161 |\n",
      "|    std                | 197       |\n",
      "|    value_loss         | 8.51      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24700     |\n",
      "|    time_elapsed       | 104679    |\n",
      "|    total_timesteps    | 2470000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24699     |\n",
      "|    policy_loss        | -155      |\n",
      "|    reward             | -0.000647 |\n",
      "|    std                | 197       |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24800     |\n",
      "|    time_elapsed       | 105098    |\n",
      "|    total_timesteps    | 2480000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24799     |\n",
      "|    policy_loss        | -48.8     |\n",
      "|    reward             | -0.000485 |\n",
      "|    std                | 199       |\n",
      "|    value_loss         | 2.1       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 24900     |\n",
      "|    time_elapsed       | 105519    |\n",
      "|    total_timesteps    | 2490000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24899     |\n",
      "|    policy_loss        | -253      |\n",
      "|    reward             | -0.001275 |\n",
      "|    std                | 199       |\n",
      "|    value_loss         | 19.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25000     |\n",
      "|    time_elapsed       | 105938    |\n",
      "|    total_timesteps    | 2500000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24999     |\n",
      "|    policy_loss        | 127       |\n",
      "|    reward             | -0.000216 |\n",
      "|    std                | 200       |\n",
      "|    value_loss         | 3.85      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 25100         |\n",
      "|    time_elapsed       | 106358        |\n",
      "|    total_timesteps    | 2510000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -67.2         |\n",
      "|    explained_variance | 2.38e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 25099         |\n",
      "|    policy_loss        | -76.3         |\n",
      "|    reward             | -9.000003e-06 |\n",
      "|    std                | 201           |\n",
      "|    value_loss         | 14            |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25200     |\n",
      "|    time_elapsed       | 106778    |\n",
      "|    total_timesteps    | 2520000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25199     |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | -0.000231 |\n",
      "|    std                | 201       |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 25300    |\n",
      "|    time_elapsed       | 107197   |\n",
      "|    total_timesteps    | 2530000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25299    |\n",
      "|    policy_loss        | 748      |\n",
      "|    reward             | -0.00177 |\n",
      "|    std                | 201      |\n",
      "|    value_loss         | 146      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 25400    |\n",
      "|    time_elapsed       | 107616   |\n",
      "|    total_timesteps    | 2540000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25399    |\n",
      "|    policy_loss        | -48      |\n",
      "|    reward             | -8.7e-05 |\n",
      "|    std                | 201      |\n",
      "|    value_loss         | 6.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 25500    |\n",
      "|    time_elapsed       | 108034   |\n",
      "|    total_timesteps    | 2550000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25499    |\n",
      "|    policy_loss        | 8.13     |\n",
      "|    reward             | -4.4e-05 |\n",
      "|    std                | 203      |\n",
      "|    value_loss         | 0.117    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25600     |\n",
      "|    time_elapsed       | 108455    |\n",
      "|    total_timesteps    | 2560000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25599     |\n",
      "|    policy_loss        | 153       |\n",
      "|    reward             | -0.003349 |\n",
      "|    std                | 205       |\n",
      "|    value_loss         | 9.14      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25700     |\n",
      "|    time_elapsed       | 108874    |\n",
      "|    total_timesteps    | 2570000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25699     |\n",
      "|    policy_loss        | -118      |\n",
      "|    reward             | -0.002689 |\n",
      "|    std                | 206       |\n",
      "|    value_loss         | 7.25      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 25800    |\n",
      "|    time_elapsed       | 109296   |\n",
      "|    total_timesteps    | 2580000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 25799    |\n",
      "|    policy_loss        | 80.2     |\n",
      "|    reward             | -0.00051 |\n",
      "|    std                | 206      |\n",
      "|    value_loss         | 6.66     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 25900     |\n",
      "|    time_elapsed       | 109725    |\n",
      "|    total_timesteps    | 2590000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25899     |\n",
      "|    policy_loss        | 190       |\n",
      "|    reward             | -0.002977 |\n",
      "|    std                | 205       |\n",
      "|    value_loss         | 41.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26000     |\n",
      "|    time_elapsed       | 110152    |\n",
      "|    total_timesteps    | 2600000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 25999     |\n",
      "|    policy_loss        | -103      |\n",
      "|    reward             | -0.002295 |\n",
      "|    std                | 206       |\n",
      "|    value_loss         | 14        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26100     |\n",
      "|    time_elapsed       | 110579    |\n",
      "|    total_timesteps    | 2610000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26099     |\n",
      "|    policy_loss        | -153      |\n",
      "|    reward             | -0.000306 |\n",
      "|    std                | 207       |\n",
      "|    value_loss         | 16.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26200     |\n",
      "|    time_elapsed       | 111006    |\n",
      "|    total_timesteps    | 2620000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26199     |\n",
      "|    policy_loss        | -140      |\n",
      "|    reward             | 0.66764   |\n",
      "|    std                | 208       |\n",
      "|    value_loss         | 51.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26300     |\n",
      "|    time_elapsed       | 111431    |\n",
      "|    total_timesteps    | 2630000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26299     |\n",
      "|    policy_loss        | -76.9     |\n",
      "|    reward             | -0.004298 |\n",
      "|    std                | 210       |\n",
      "|    value_loss         | 3.89      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26400     |\n",
      "|    time_elapsed       | 111856    |\n",
      "|    total_timesteps    | 2640000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26399     |\n",
      "|    policy_loss        | -51.8     |\n",
      "|    reward             | -0.002011 |\n",
      "|    std                | 211       |\n",
      "|    value_loss         | 1.65      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26500     |\n",
      "|    time_elapsed       | 112280    |\n",
      "|    total_timesteps    | 2650000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26499     |\n",
      "|    policy_loss        | 56.7      |\n",
      "|    reward             | -0.000946 |\n",
      "|    std                | 212       |\n",
      "|    value_loss         | 1.69      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26600     |\n",
      "|    time_elapsed       | 112705    |\n",
      "|    total_timesteps    | 2660000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26599     |\n",
      "|    policy_loss        | -82.4     |\n",
      "|    reward             | -0.000407 |\n",
      "|    std                | 213       |\n",
      "|    value_loss         | 4.15      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 26700    |\n",
      "|    time_elapsed       | 113130   |\n",
      "|    total_timesteps    | 2670000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -67.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 26699    |\n",
      "|    policy_loss        | -83.7    |\n",
      "|    reward             | 4.808482 |\n",
      "|    std                | 214      |\n",
      "|    value_loss         | 15       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 26800     |\n",
      "|    time_elapsed       | 113556    |\n",
      "|    total_timesteps    | 2680000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26799     |\n",
      "|    policy_loss        | -1.27e+03 |\n",
      "|    reward             | -0.001203 |\n",
      "|    std                | 215       |\n",
      "|    value_loss         | 557       |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 26900          |\n",
      "|    time_elapsed       | 113983         |\n",
      "|    total_timesteps    | 2690000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -67.8          |\n",
      "|    explained_variance | -2.38e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 26899          |\n",
      "|    policy_loss        | -965           |\n",
      "|    reward             | -0.00013500001 |\n",
      "|    std                | 215            |\n",
      "|    value_loss         | 277            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27000     |\n",
      "|    time_elapsed       | 114409    |\n",
      "|    total_timesteps    | 2700000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -67.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 26999     |\n",
      "|    policy_loss        | 43.9      |\n",
      "|    reward             | -0.003131 |\n",
      "|    std                | 217       |\n",
      "|    value_loss         | 0.554     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27100     |\n",
      "|    time_elapsed       | 114836    |\n",
      "|    total_timesteps    | 2710000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27099     |\n",
      "|    policy_loss        | 51.4      |\n",
      "|    reward             | -0.003509 |\n",
      "|    std                | 219       |\n",
      "|    value_loss         | 3.07      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 27200          |\n",
      "|    time_elapsed       | 115263         |\n",
      "|    total_timesteps    | 2720000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -68            |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 27199          |\n",
      "|    policy_loss        | -532           |\n",
      "|    reward             | -7.2999996e-05 |\n",
      "|    std                | 219            |\n",
      "|    value_loss         | 84.1           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27300     |\n",
      "|    time_elapsed       | 115690    |\n",
      "|    total_timesteps    | 2730000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27299     |\n",
      "|    policy_loss        | 151       |\n",
      "|    reward             | -0.001798 |\n",
      "|    std                | 219       |\n",
      "|    value_loss         | 20.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27400     |\n",
      "|    time_elapsed       | 116117    |\n",
      "|    total_timesteps    | 2740000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27399     |\n",
      "|    policy_loss        | -216      |\n",
      "|    reward             | -0.438983 |\n",
      "|    std                | 219       |\n",
      "|    value_loss         | 39.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27500     |\n",
      "|    time_elapsed       | 116543    |\n",
      "|    total_timesteps    | 2750000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27499     |\n",
      "|    policy_loss        | -271      |\n",
      "|    reward             | -0.001534 |\n",
      "|    std                | 220       |\n",
      "|    value_loss         | 47.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27600     |\n",
      "|    time_elapsed       | 116971    |\n",
      "|    total_timesteps    | 2760000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27599     |\n",
      "|    policy_loss        | -601      |\n",
      "|    reward             | -0.001662 |\n",
      "|    std                | 221       |\n",
      "|    value_loss         | 374       |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 27700          |\n",
      "|    time_elapsed       | 117395         |\n",
      "|    total_timesteps    | 2770000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -68.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 27699          |\n",
      "|    policy_loss        | -449           |\n",
      "|    reward             | -0.00039399997 |\n",
      "|    std                | 220            |\n",
      "|    value_loss         | 88.1           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27800     |\n",
      "|    time_elapsed       | 117815    |\n",
      "|    total_timesteps    | 2780000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27799     |\n",
      "|    policy_loss        | -73.8     |\n",
      "|    reward             | -0.002511 |\n",
      "|    std                | 221       |\n",
      "|    value_loss         | 2.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 27900     |\n",
      "|    time_elapsed       | 118236    |\n",
      "|    total_timesteps    | 2790000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27899     |\n",
      "|    policy_loss        | 336       |\n",
      "|    reward             | -0.000164 |\n",
      "|    std                | 221       |\n",
      "|    value_loss         | 29.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28000     |\n",
      "|    time_elapsed       | 118664    |\n",
      "|    total_timesteps    | 2800000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27999     |\n",
      "|    policy_loss        | -290      |\n",
      "|    reward             | -0.000746 |\n",
      "|    std                | 221       |\n",
      "|    value_loss         | 21.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28100     |\n",
      "|    time_elapsed       | 119091    |\n",
      "|    total_timesteps    | 2810000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28099     |\n",
      "|    policy_loss        | -170      |\n",
      "|    reward             | -0.000734 |\n",
      "|    std                | 222       |\n",
      "|    value_loss         | 20.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28200     |\n",
      "|    time_elapsed       | 119518    |\n",
      "|    total_timesteps    | 2820000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28199     |\n",
      "|    policy_loss        | -6.22     |\n",
      "|    reward             | -0.002079 |\n",
      "|    std                | 222       |\n",
      "|    value_loss         | 4.91      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28300     |\n",
      "|    time_elapsed       | 119946    |\n",
      "|    total_timesteps    | 2830000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28299     |\n",
      "|    policy_loss        | 1.03e+03  |\n",
      "|    reward             | -0.000329 |\n",
      "|    std                | 223       |\n",
      "|    value_loss         | 351       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28400     |\n",
      "|    time_elapsed       | 120372    |\n",
      "|    total_timesteps    | 2840000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28399     |\n",
      "|    policy_loss        | 524       |\n",
      "|    reward             | -0.001531 |\n",
      "|    std                | 223       |\n",
      "|    value_loss         | 93.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28500     |\n",
      "|    time_elapsed       | 120799    |\n",
      "|    total_timesteps    | 2850000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28499     |\n",
      "|    policy_loss        | -45.3     |\n",
      "|    reward             | -0.003602 |\n",
      "|    std                | 224       |\n",
      "|    value_loss         | 0.55      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28600     |\n",
      "|    time_elapsed       | 121227    |\n",
      "|    total_timesteps    | 2860000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28599     |\n",
      "|    policy_loss        | 83.2      |\n",
      "|    reward             | -0.000175 |\n",
      "|    std                | 225       |\n",
      "|    value_loss         | 2.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28700     |\n",
      "|    time_elapsed       | 121655    |\n",
      "|    total_timesteps    | 2870000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28699     |\n",
      "|    policy_loss        | -122      |\n",
      "|    reward             | -0.002349 |\n",
      "|    std                | 226       |\n",
      "|    value_loss         | 4.65      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 28800     |\n",
      "|    time_elapsed       | 122083    |\n",
      "|    total_timesteps    | 2880000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28799     |\n",
      "|    policy_loss        | -152      |\n",
      "|    reward             | -0.001237 |\n",
      "|    std                | 227       |\n",
      "|    value_loss         | 14.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 28900    |\n",
      "|    time_elapsed       | 122511   |\n",
      "|    total_timesteps    | 2890000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 28899    |\n",
      "|    policy_loss        | 17.2     |\n",
      "|    reward             | -1.74623 |\n",
      "|    std                | 228      |\n",
      "|    value_loss         | 40.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29000     |\n",
      "|    time_elapsed       | 122939    |\n",
      "|    total_timesteps    | 2900000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28999     |\n",
      "|    policy_loss        | 237       |\n",
      "|    reward             | -0.001019 |\n",
      "|    std                | 228       |\n",
      "|    value_loss         | 23.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29100     |\n",
      "|    time_elapsed       | 123366    |\n",
      "|    total_timesteps    | 2910000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29099     |\n",
      "|    policy_loss        | 413       |\n",
      "|    reward             | -0.001226 |\n",
      "|    std                | 229       |\n",
      "|    value_loss         | 68.1      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 29200         |\n",
      "|    time_elapsed       | 123792        |\n",
      "|    total_timesteps    | 2920000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -68.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 29199         |\n",
      "|    policy_loss        | 1.18e+03      |\n",
      "|    reward             | -5.899999e-05 |\n",
      "|    std                | 230           |\n",
      "|    value_loss         | 397           |\n",
      "-----------------------------------------\n",
      "Moment: 74871, episode: 40\n",
      "begin_total_asset: -1125550419.38\n",
      "end_total_asset: -995512.21\n",
      "total_reward: -1095512.21\n",
      "total_trades: 360824\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29300     |\n",
      "|    time_elapsed       | 124220    |\n",
      "|    total_timesteps    | 2930000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29299     |\n",
      "|    policy_loss        | 205       |\n",
      "|    reward             | -0.001706 |\n",
      "|    std                | 231       |\n",
      "|    value_loss         | 14.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 29400    |\n",
      "|    time_elapsed       | 124647   |\n",
      "|    total_timesteps    | 2940000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29399    |\n",
      "|    policy_loss        | -43      |\n",
      "|    reward             | 1.437227 |\n",
      "|    std                | 232      |\n",
      "|    value_loss         | 5.74     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29500     |\n",
      "|    time_elapsed       | 125074    |\n",
      "|    total_timesteps    | 2950000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29499     |\n",
      "|    policy_loss        | -67.1     |\n",
      "|    reward             | -0.000103 |\n",
      "|    std                | 233       |\n",
      "|    value_loss         | 3.29      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 29600    |\n",
      "|    time_elapsed       | 125502   |\n",
      "|    total_timesteps    | 2960000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29599    |\n",
      "|    policy_loss        | -395     |\n",
      "|    reward             | -0.003   |\n",
      "|    std                | 233      |\n",
      "|    value_loss         | 49       |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 29700          |\n",
      "|    time_elapsed       | 125929         |\n",
      "|    total_timesteps    | 2970000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -68.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 29699          |\n",
      "|    policy_loss        | -5.38          |\n",
      "|    reward             | -0.00012900001 |\n",
      "|    std                | 233            |\n",
      "|    value_loss         | 4.76           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29800     |\n",
      "|    time_elapsed       | 126357    |\n",
      "|    total_timesteps    | 2980000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29799     |\n",
      "|    policy_loss        | -586      |\n",
      "|    reward             | -0.002985 |\n",
      "|    std                | 233       |\n",
      "|    value_loss         | 140       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 29900     |\n",
      "|    time_elapsed       | 126783    |\n",
      "|    total_timesteps    | 2990000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 29899     |\n",
      "|    policy_loss        | 349       |\n",
      "|    reward             | -0.003612 |\n",
      "|    std                | 233       |\n",
      "|    value_loss         | 33.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 30000    |\n",
      "|    time_elapsed       | 127204   |\n",
      "|    total_timesteps    | 3000000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 29999    |\n",
      "|    policy_loss        | 47.1     |\n",
      "|    reward             | 1.273788 |\n",
      "|    std                | 235      |\n",
      "|    value_loss         | 0.78     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30100     |\n",
      "|    time_elapsed       | 127625    |\n",
      "|    total_timesteps    | 3010000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30099     |\n",
      "|    policy_loss        | -46.8     |\n",
      "|    reward             | -0.001761 |\n",
      "|    std                | 236       |\n",
      "|    value_loss         | 2.06      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 30200    |\n",
      "|    time_elapsed       | 128044   |\n",
      "|    total_timesteps    | 3020000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30199    |\n",
      "|    policy_loss        | 106      |\n",
      "|    reward             | -0.00312 |\n",
      "|    std                | 236      |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30300     |\n",
      "|    time_elapsed       | 128465    |\n",
      "|    total_timesteps    | 3030000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30299     |\n",
      "|    policy_loss        | 505       |\n",
      "|    reward             | -0.001026 |\n",
      "|    std                | 236       |\n",
      "|    value_loss         | 74.6      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 30400          |\n",
      "|    time_elapsed       | 128885         |\n",
      "|    total_timesteps    | 3040000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -68.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 30399          |\n",
      "|    policy_loss        | 116            |\n",
      "|    reward             | -0.00096699997 |\n",
      "|    std                | 236            |\n",
      "|    value_loss         | 11.8           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30500     |\n",
      "|    time_elapsed       | 129306    |\n",
      "|    total_timesteps    | 3050000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30499     |\n",
      "|    policy_loss        | -472      |\n",
      "|    reward             | -0.840848 |\n",
      "|    std                | 236       |\n",
      "|    value_loss         | 105       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30600     |\n",
      "|    time_elapsed       | 129726    |\n",
      "|    total_timesteps    | 3060000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30599     |\n",
      "|    policy_loss        | 1.07e+03  |\n",
      "|    reward             | -0.00015  |\n",
      "|    std                | 236       |\n",
      "|    value_loss         | 309       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30700     |\n",
      "|    time_elapsed       | 130146    |\n",
      "|    total_timesteps    | 3070000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.8     |\n",
      "|    explained_variance | 0.355     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30699     |\n",
      "|    policy_loss        | 1.75      |\n",
      "|    reward             | -0.001561 |\n",
      "|    std                | 236       |\n",
      "|    value_loss         | 0.00429   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 30800    |\n",
      "|    time_elapsed       | 130566   |\n",
      "|    total_timesteps    | 3080000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -68.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 30799    |\n",
      "|    policy_loss        | 98.5     |\n",
      "|    reward             | -0.13078 |\n",
      "|    std                | 239      |\n",
      "|    value_loss         | 7.96     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 30900     |\n",
      "|    time_elapsed       | 130988    |\n",
      "|    total_timesteps    | 3090000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -68.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30899     |\n",
      "|    policy_loss        | -13.2     |\n",
      "|    reward             | -0.001225 |\n",
      "|    std                | 240       |\n",
      "|    value_loss         | 4.01      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31000     |\n",
      "|    time_elapsed       | 131411    |\n",
      "|    total_timesteps    | 3100000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30999     |\n",
      "|    policy_loss        | -783      |\n",
      "|    reward             | -0.623238 |\n",
      "|    std                | 241       |\n",
      "|    value_loss         | 151       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 31100    |\n",
      "|    time_elapsed       | 131832   |\n",
      "|    total_timesteps    | 3110000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31099    |\n",
      "|    policy_loss        | 170      |\n",
      "|    reward             | 2.538941 |\n",
      "|    std                | 242      |\n",
      "|    value_loss         | 9.57     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31200     |\n",
      "|    time_elapsed       | 132251    |\n",
      "|    total_timesteps    | 3120000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31199     |\n",
      "|    policy_loss        | -224      |\n",
      "|    reward             | -0.004622 |\n",
      "|    std                | 242       |\n",
      "|    value_loss         | 14.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31300     |\n",
      "|    time_elapsed       | 132673    |\n",
      "|    total_timesteps    | 3130000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31299     |\n",
      "|    policy_loss        | -629      |\n",
      "|    reward             | -0.004836 |\n",
      "|    std                | 242       |\n",
      "|    value_loss         | 112       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 31400    |\n",
      "|    time_elapsed       | 133094   |\n",
      "|    total_timesteps    | 3140000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31399    |\n",
      "|    policy_loss        | 1.12e+03 |\n",
      "|    reward             | -0.00123 |\n",
      "|    std                | 242      |\n",
      "|    value_loss         | 323      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31500     |\n",
      "|    time_elapsed       | 133515    |\n",
      "|    total_timesteps    | 3150000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.2     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31499     |\n",
      "|    policy_loss        | 22.4      |\n",
      "|    reward             | -0.001643 |\n",
      "|    std                | 245       |\n",
      "|    value_loss         | 0.207     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31600     |\n",
      "|    time_elapsed       | 133934    |\n",
      "|    total_timesteps    | 3160000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31599     |\n",
      "|    policy_loss        | -262      |\n",
      "|    reward             | -0.001452 |\n",
      "|    std                | 247       |\n",
      "|    value_loss         | 16.4      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 31700         |\n",
      "|    time_elapsed       | 134354        |\n",
      "|    total_timesteps    | 3170000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -69.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 31699         |\n",
      "|    policy_loss        | 304           |\n",
      "|    reward             | -0.0012620001 |\n",
      "|    std                | 248           |\n",
      "|    value_loss         | 51.6          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 31800     |\n",
      "|    time_elapsed       | 134775    |\n",
      "|    total_timesteps    | 3180000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31799     |\n",
      "|    policy_loss        | 890       |\n",
      "|    reward             | -0.001479 |\n",
      "|    std                | 249       |\n",
      "|    value_loss         | 251       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 31900    |\n",
      "|    time_elapsed       | 135196   |\n",
      "|    total_timesteps    | 3190000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 31899    |\n",
      "|    policy_loss        | -535     |\n",
      "|    reward             | 0.499622 |\n",
      "|    std                | 250      |\n",
      "|    value_loss         | 219      |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 32000          |\n",
      "|    time_elapsed       | 135616         |\n",
      "|    total_timesteps    | 3200000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -69.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 31999          |\n",
      "|    policy_loss        | -408           |\n",
      "|    reward             | -0.00010700001 |\n",
      "|    std                | 249            |\n",
      "|    value_loss         | 231            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32100     |\n",
      "|    time_elapsed       | 136035    |\n",
      "|    total_timesteps    | 3210000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32099     |\n",
      "|    policy_loss        | -172      |\n",
      "|    reward             | -0.000207 |\n",
      "|    std                | 250       |\n",
      "|    value_loss         | 142       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32200     |\n",
      "|    time_elapsed       | 136454    |\n",
      "|    total_timesteps    | 3220000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32199     |\n",
      "|    policy_loss        | -10.2     |\n",
      "|    reward             | -0.000239 |\n",
      "|    std                | 251       |\n",
      "|    value_loss         | 0.0339    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32300     |\n",
      "|    time_elapsed       | 136875    |\n",
      "|    total_timesteps    | 3230000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32299     |\n",
      "|    policy_loss        | -151      |\n",
      "|    reward             | -0.000239 |\n",
      "|    std                | 253       |\n",
      "|    value_loss         | 10.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32400     |\n",
      "|    time_elapsed       | 137297    |\n",
      "|    total_timesteps    | 3240000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32399     |\n",
      "|    policy_loss        | -205      |\n",
      "|    reward             | -0.798651 |\n",
      "|    std                | 254       |\n",
      "|    value_loss         | 12.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32500     |\n",
      "|    time_elapsed       | 137717    |\n",
      "|    total_timesteps    | 3250000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32499     |\n",
      "|    policy_loss        | -91.6     |\n",
      "|    reward             | -0.001716 |\n",
      "|    std                | 254       |\n",
      "|    value_loss         | 4.08      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32600     |\n",
      "|    time_elapsed       | 138139    |\n",
      "|    total_timesteps    | 3260000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32599     |\n",
      "|    policy_loss        | 237       |\n",
      "|    reward             | -0.000932 |\n",
      "|    std                | 254       |\n",
      "|    value_loss         | 16.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32700     |\n",
      "|    time_elapsed       | 138561    |\n",
      "|    total_timesteps    | 3270000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32699     |\n",
      "|    policy_loss        | -337      |\n",
      "|    reward             | -0.003815 |\n",
      "|    std                | 255       |\n",
      "|    value_loss         | 41.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 32800     |\n",
      "|    time_elapsed       | 138982    |\n",
      "|    total_timesteps    | 3280000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32799     |\n",
      "|    policy_loss        | -1.09e+03 |\n",
      "|    reward             | -1.250856 |\n",
      "|    std                | 256       |\n",
      "|    value_loss         | 270       |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 32900          |\n",
      "|    time_elapsed       | 139400         |\n",
      "|    total_timesteps    | 3290000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -69.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 32899          |\n",
      "|    policy_loss        | -1.43e+03      |\n",
      "|    reward             | -5.0999974e-05 |\n",
      "|    std                | 256            |\n",
      "|    value_loss         | 913            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33000     |\n",
      "|    time_elapsed       | 139819    |\n",
      "|    total_timesteps    | 3300000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 32999     |\n",
      "|    policy_loss        | 50.7      |\n",
      "|    reward             | -0.253536 |\n",
      "|    std                | 258       |\n",
      "|    value_loss         | 3.29      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33100     |\n",
      "|    time_elapsed       | 140240    |\n",
      "|    total_timesteps    | 3310000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33099     |\n",
      "|    policy_loss        | 21        |\n",
      "|    reward             | -0.001875 |\n",
      "|    std                | 260       |\n",
      "|    value_loss         | 0.525     |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 33200          |\n",
      "|    time_elapsed       | 140660         |\n",
      "|    total_timesteps    | 3320000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -69.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 33199          |\n",
      "|    policy_loss        | 267            |\n",
      "|    reward             | -1.5000003e-05 |\n",
      "|    std                | 260            |\n",
      "|    value_loss         | 25.7           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33300     |\n",
      "|    time_elapsed       | 141079    |\n",
      "|    total_timesteps    | 3330000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33299     |\n",
      "|    policy_loss        | -156      |\n",
      "|    reward             | -0.001761 |\n",
      "|    std                | 261       |\n",
      "|    value_loss         | 5.97      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 33400    |\n",
      "|    time_elapsed       | 141499   |\n",
      "|    total_timesteps    | 3340000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -69.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 33399    |\n",
      "|    policy_loss        | -71.4    |\n",
      "|    reward             | 0.462526 |\n",
      "|    std                | 262      |\n",
      "|    value_loss         | 5.23     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 33500          |\n",
      "|    time_elapsed       | 141918         |\n",
      "|    total_timesteps    | 3350000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -69.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 33499          |\n",
      "|    policy_loss        | 1.29e+03       |\n",
      "|    reward             | -4.2999996e-05 |\n",
      "|    std                | 261            |\n",
      "|    value_loss         | 476            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33600     |\n",
      "|    time_elapsed       | 142336    |\n",
      "|    total_timesteps    | 3360000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33599     |\n",
      "|    policy_loss        | 357       |\n",
      "|    reward             | -0.001714 |\n",
      "|    std                | 262       |\n",
      "|    value_loss         | 34.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33700     |\n",
      "|    time_elapsed       | 142755    |\n",
      "|    total_timesteps    | 3370000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.8     |\n",
      "|    explained_variance | -0.00247  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33699     |\n",
      "|    policy_loss        | -7.19     |\n",
      "|    reward             | -0.003972 |\n",
      "|    std                | 262       |\n",
      "|    value_loss         | 0.048     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33800     |\n",
      "|    time_elapsed       | 143174    |\n",
      "|    total_timesteps    | 3380000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -69.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33799     |\n",
      "|    policy_loss        | 88.2      |\n",
      "|    reward             | -0.001268 |\n",
      "|    std                | 264       |\n",
      "|    value_loss         | 2.63      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 33900     |\n",
      "|    time_elapsed       | 143592    |\n",
      "|    total_timesteps    | 3390000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33899     |\n",
      "|    policy_loss        | -366      |\n",
      "|    reward             | -0.000286 |\n",
      "|    std                | 265       |\n",
      "|    value_loss         | 59.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34000     |\n",
      "|    time_elapsed       | 144010    |\n",
      "|    total_timesteps    | 3400000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 33999     |\n",
      "|    policy_loss        | 166       |\n",
      "|    reward             | -0.002145 |\n",
      "|    std                | 266       |\n",
      "|    value_loss         | 10        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34100     |\n",
      "|    time_elapsed       | 144428    |\n",
      "|    total_timesteps    | 3410000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34099     |\n",
      "|    policy_loss        | 80.1      |\n",
      "|    reward             | -0.000723 |\n",
      "|    std                | 266       |\n",
      "|    value_loss         | 6.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34200     |\n",
      "|    time_elapsed       | 144846    |\n",
      "|    total_timesteps    | 3420000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34199     |\n",
      "|    policy_loss        | -82.9     |\n",
      "|    reward             | -0.002898 |\n",
      "|    std                | 267       |\n",
      "|    value_loss         | 11.6      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 34300          |\n",
      "|    time_elapsed       | 145264         |\n",
      "|    total_timesteps    | 3430000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -70.1          |\n",
      "|    explained_variance | -2.38e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 34299          |\n",
      "|    policy_loss        | 2.44e+03       |\n",
      "|    reward             | -4.4999993e-05 |\n",
      "|    std                | 268            |\n",
      "|    value_loss         | 1.38e+03       |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34400     |\n",
      "|    time_elapsed       | 145682    |\n",
      "|    total_timesteps    | 3440000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34399     |\n",
      "|    policy_loss        | 53.6      |\n",
      "|    reward             | -0.002073 |\n",
      "|    std                | 269       |\n",
      "|    value_loss         | 53.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34500     |\n",
      "|    time_elapsed       | 146104    |\n",
      "|    total_timesteps    | 3450000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34499     |\n",
      "|    policy_loss        | 93        |\n",
      "|    reward             | -0.632736 |\n",
      "|    std                | 270       |\n",
      "|    value_loss         | 1.91      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34600     |\n",
      "|    time_elapsed       | 146530    |\n",
      "|    total_timesteps    | 3460000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34599     |\n",
      "|    policy_loss        | 177       |\n",
      "|    reward             | -0.001478 |\n",
      "|    std                | 272       |\n",
      "|    value_loss         | 10.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34700     |\n",
      "|    time_elapsed       | 146955    |\n",
      "|    total_timesteps    | 3470000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34699     |\n",
      "|    policy_loss        | -123      |\n",
      "|    reward             | -0.921218 |\n",
      "|    std                | 271       |\n",
      "|    value_loss         | 7.15      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 34800          |\n",
      "|    time_elapsed       | 147381         |\n",
      "|    total_timesteps    | 3480000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -70.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 34799          |\n",
      "|    policy_loss        | 410            |\n",
      "|    reward             | -3.8999988e-05 |\n",
      "|    std                | 273            |\n",
      "|    value_loss         | 51.8           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 34900     |\n",
      "|    time_elapsed       | 147806    |\n",
      "|    total_timesteps    | 3490000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34899     |\n",
      "|    policy_loss        | -489      |\n",
      "|    reward             | -5.752262 |\n",
      "|    std                | 274       |\n",
      "|    value_loss         | 57.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35000     |\n",
      "|    time_elapsed       | 148232    |\n",
      "|    total_timesteps    | 3500000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34999     |\n",
      "|    policy_loss        | 1.24e+03  |\n",
      "|    reward             | -0.000767 |\n",
      "|    std                | 274       |\n",
      "|    value_loss         | 436       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35100     |\n",
      "|    time_elapsed       | 148658    |\n",
      "|    total_timesteps    | 3510000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35099     |\n",
      "|    policy_loss        | 598       |\n",
      "|    reward             | -0.001226 |\n",
      "|    std                | 275       |\n",
      "|    value_loss         | 95.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 35200    |\n",
      "|    time_elapsed       | 149083   |\n",
      "|    total_timesteps    | 3520000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35199    |\n",
      "|    policy_loss        | -33.2    |\n",
      "|    reward             | -0.10743 |\n",
      "|    std                | 275      |\n",
      "|    value_loss         | 0.454    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 35300    |\n",
      "|    time_elapsed       | 149509   |\n",
      "|    total_timesteps    | 3530000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35299    |\n",
      "|    policy_loss        | -47.4    |\n",
      "|    reward             | 0.369896 |\n",
      "|    std                | 277      |\n",
      "|    value_loss         | 4.34     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35400     |\n",
      "|    time_elapsed       | 149936    |\n",
      "|    total_timesteps    | 3540000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35399     |\n",
      "|    policy_loss        | 169       |\n",
      "|    reward             | -0.002052 |\n",
      "|    std                | 277       |\n",
      "|    value_loss         | 13.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35500     |\n",
      "|    time_elapsed       | 150362    |\n",
      "|    total_timesteps    | 3550000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35499     |\n",
      "|    policy_loss        | -52.2     |\n",
      "|    reward             | -0.000132 |\n",
      "|    std                | 278       |\n",
      "|    value_loss         | 9.89      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 35600          |\n",
      "|    time_elapsed       | 150788         |\n",
      "|    total_timesteps    | 3560000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -70.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 35599          |\n",
      "|    policy_loss        | -41.7          |\n",
      "|    reward             | -8.0000045e-06 |\n",
      "|    std                | 279            |\n",
      "|    value_loss         | 19.8           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35700     |\n",
      "|    time_elapsed       | 151215    |\n",
      "|    total_timesteps    | 3570000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35699     |\n",
      "|    policy_loss        | 1.68e+03  |\n",
      "|    reward             | -0.003856 |\n",
      "|    std                | 279       |\n",
      "|    value_loss         | 649       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 35800     |\n",
      "|    time_elapsed       | 151641    |\n",
      "|    total_timesteps    | 3580000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35799     |\n",
      "|    policy_loss        | -766      |\n",
      "|    reward             | -0.000257 |\n",
      "|    std                | 280       |\n",
      "|    value_loss         | 150       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 35900    |\n",
      "|    time_elapsed       | 152066   |\n",
      "|    total_timesteps    | 3590000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35899    |\n",
      "|    policy_loss        | -748     |\n",
      "|    reward             | -0.00154 |\n",
      "|    std                | 281      |\n",
      "|    value_loss         | 155      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36000     |\n",
      "|    time_elapsed       | 152491    |\n",
      "|    total_timesteps    | 3600000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 35999     |\n",
      "|    policy_loss        | -16.3     |\n",
      "|    reward             | -0.003241 |\n",
      "|    std                | 283       |\n",
      "|    value_loss         | 2.97      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36100     |\n",
      "|    time_elapsed       | 152918    |\n",
      "|    total_timesteps    | 3610000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36099     |\n",
      "|    policy_loss        | -136      |\n",
      "|    reward             | -0.001629 |\n",
      "|    std                | 284       |\n",
      "|    value_loss         | 5.66      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 36200    |\n",
      "|    time_elapsed       | 153342   |\n",
      "|    total_timesteps    | 3620000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36199    |\n",
      "|    policy_loss        | 111      |\n",
      "|    reward             | 0.27668  |\n",
      "|    std                | 285      |\n",
      "|    value_loss         | 7.48     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36300     |\n",
      "|    time_elapsed       | 153760    |\n",
      "|    total_timesteps    | 3630000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36299     |\n",
      "|    policy_loss        | -151      |\n",
      "|    reward             | -0.001616 |\n",
      "|    std                | 285       |\n",
      "|    value_loss         | 10.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36400     |\n",
      "|    time_elapsed       | 154179    |\n",
      "|    total_timesteps    | 3640000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36399     |\n",
      "|    policy_loss        | 20.4      |\n",
      "|    reward             | -0.003101 |\n",
      "|    std                | 284       |\n",
      "|    value_loss         | 1.84      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36500     |\n",
      "|    time_elapsed       | 154598    |\n",
      "|    total_timesteps    | 3650000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36499     |\n",
      "|    policy_loss        | -699      |\n",
      "|    reward             | -0.003429 |\n",
      "|    std                | 285       |\n",
      "|    value_loss         | 127       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36600     |\n",
      "|    time_elapsed       | 155017    |\n",
      "|    total_timesteps    | 3660000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36599     |\n",
      "|    policy_loss        | -511      |\n",
      "|    reward             | -0.002138 |\n",
      "|    std                | 284       |\n",
      "|    value_loss         | 60        |\n",
      "-------------------------------------\n",
      "Moment: 74871, episode: 50\n",
      "begin_total_asset: -1259457611.36\n",
      "end_total_asset: -1085060.99\n",
      "total_reward: -1185060.99\n",
      "total_trades: 363413\n",
      "Sharpe: 0.044\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36700     |\n",
      "|    time_elapsed       | 155434    |\n",
      "|    total_timesteps    | 3670000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36699     |\n",
      "|    policy_loss        | -4.13     |\n",
      "|    reward             | -0.001867 |\n",
      "|    std                | 284       |\n",
      "|    value_loss         | 0.0445    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 36800     |\n",
      "|    time_elapsed       | 155853    |\n",
      "|    total_timesteps    | 3680000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36799     |\n",
      "|    policy_loss        | 171       |\n",
      "|    reward             | -0.003728 |\n",
      "|    std                | 287       |\n",
      "|    value_loss         | 6.68      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 36900    |\n",
      "|    time_elapsed       | 156272   |\n",
      "|    total_timesteps    | 3690000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 36899    |\n",
      "|    policy_loss        | 21.3     |\n",
      "|    reward             | -0.0062  |\n",
      "|    std                | 287      |\n",
      "|    value_loss         | 6.6      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37000     |\n",
      "|    time_elapsed       | 156692    |\n",
      "|    total_timesteps    | 3700000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36999     |\n",
      "|    policy_loss        | -6.36     |\n",
      "|    reward             | -1.048821 |\n",
      "|    std                | 290       |\n",
      "|    value_loss         | 6.4       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37100     |\n",
      "|    time_elapsed       | 157110    |\n",
      "|    total_timesteps    | 3710000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37099     |\n",
      "|    policy_loss        | -366      |\n",
      "|    reward             | -1.066321 |\n",
      "|    std                | 290       |\n",
      "|    value_loss         | 44        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 37200    |\n",
      "|    time_elapsed       | 157531   |\n",
      "|    total_timesteps    | 3720000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -70.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37199    |\n",
      "|    policy_loss        | 466      |\n",
      "|    reward             | -0.00123 |\n",
      "|    std                | 290      |\n",
      "|    value_loss         | 85.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37300     |\n",
      "|    time_elapsed       | 157950    |\n",
      "|    total_timesteps    | 3730000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37299     |\n",
      "|    policy_loss        | -217      |\n",
      "|    reward             | -0.000453 |\n",
      "|    std                | 290       |\n",
      "|    value_loss         | 45        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37400     |\n",
      "|    time_elapsed       | 158368    |\n",
      "|    total_timesteps    | 3740000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37399     |\n",
      "|    policy_loss        | -2.22e+03 |\n",
      "|    reward             | -0.001804 |\n",
      "|    std                | 291       |\n",
      "|    value_loss         | 1.27e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37500     |\n",
      "|    time_elapsed       | 158786    |\n",
      "|    total_timesteps    | 3750000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -70.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37499     |\n",
      "|    policy_loss        | 16.2      |\n",
      "|    reward             | -0.004619 |\n",
      "|    std                | 293       |\n",
      "|    value_loss         | 0.427     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 37600    |\n",
      "|    time_elapsed       | 159205   |\n",
      "|    total_timesteps    | 3760000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 37599    |\n",
      "|    policy_loss        | -187     |\n",
      "|    reward             | 0.718611 |\n",
      "|    std                | 294      |\n",
      "|    value_loss         | 11.2     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 37700          |\n",
      "|    time_elapsed       | 159624         |\n",
      "|    total_timesteps    | 3770000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71            |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 37699          |\n",
      "|    policy_loss        | -153           |\n",
      "|    reward             | -8.9999994e-05 |\n",
      "|    std                | 295            |\n",
      "|    value_loss         | 9.6            |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 37800         |\n",
      "|    time_elapsed       | 160043        |\n",
      "|    total_timesteps    | 3780000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -71           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 37799         |\n",
      "|    policy_loss        | -805          |\n",
      "|    reward             | -0.0018569999 |\n",
      "|    std                | 295           |\n",
      "|    value_loss         | 187           |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 37900     |\n",
      "|    time_elapsed       | 160461    |\n",
      "|    total_timesteps    | 3790000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37899     |\n",
      "|    policy_loss        | 801       |\n",
      "|    reward             | 0.49393   |\n",
      "|    std                | 297       |\n",
      "|    value_loss         | 208       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38000     |\n",
      "|    time_elapsed       | 160882    |\n",
      "|    total_timesteps    | 3800000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37999     |\n",
      "|    policy_loss        | -1.53e+03 |\n",
      "|    reward             | -0.000578 |\n",
      "|    std                | 298       |\n",
      "|    value_loss         | 595       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38100     |\n",
      "|    time_elapsed       | 161302    |\n",
      "|    total_timesteps    | 3810000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38099     |\n",
      "|    policy_loss        | -24.2     |\n",
      "|    reward             | -0.004712 |\n",
      "|    std                | 298       |\n",
      "|    value_loss         | 7.64      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38200     |\n",
      "|    time_elapsed       | 161721    |\n",
      "|    total_timesteps    | 3820000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38199     |\n",
      "|    policy_loss        | -20       |\n",
      "|    reward             | -0.029812 |\n",
      "|    std                | 299       |\n",
      "|    value_loss         | 0.16      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 38300    |\n",
      "|    time_elapsed       | 162142   |\n",
      "|    total_timesteps    | 3830000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 38299    |\n",
      "|    policy_loss        | 24.8     |\n",
      "|    reward             | -0.00062 |\n",
      "|    std                | 301      |\n",
      "|    value_loss         | 0.528    |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 38400          |\n",
      "|    time_elapsed       | 162561         |\n",
      "|    total_timesteps    | 3840000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 38399          |\n",
      "|    policy_loss        | 275            |\n",
      "|    reward             | -5.4000004e-05 |\n",
      "|    std                | 302            |\n",
      "|    value_loss         | 23             |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38500     |\n",
      "|    time_elapsed       | 162980    |\n",
      "|    total_timesteps    | 3850000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38499     |\n",
      "|    policy_loss        | 0.738     |\n",
      "|    reward             | -0.352253 |\n",
      "|    std                | 303       |\n",
      "|    value_loss         | 254       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38600     |\n",
      "|    time_elapsed       | 163400    |\n",
      "|    total_timesteps    | 3860000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38599     |\n",
      "|    policy_loss        | 486       |\n",
      "|    reward             | -0.002887 |\n",
      "|    std                | 304       |\n",
      "|    value_loss         | 51.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 38700     |\n",
      "|    time_elapsed       | 163821    |\n",
      "|    total_timesteps    | 3870000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38699     |\n",
      "|    policy_loss        | -46.1     |\n",
      "|    reward             | -0.000446 |\n",
      "|    std                | 304       |\n",
      "|    value_loss         | 7.14      |\n",
      "-------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 23              |\n",
      "|    iterations         | 38800           |\n",
      "|    time_elapsed       | 164240          |\n",
      "|    total_timesteps    | 3880000         |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -71.3           |\n",
      "|    explained_variance | 0               |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 38799           |\n",
      "|    policy_loss        | 530             |\n",
      "|    reward             | -0.000121999976 |\n",
      "|    std                | 304             |\n",
      "|    value_loss         | 102             |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 38900         |\n",
      "|    time_elapsed       | 164659        |\n",
      "|    total_timesteps    | 3890000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -71.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 38899         |\n",
      "|    policy_loss        | -136          |\n",
      "|    reward             | -0.0035009999 |\n",
      "|    std                | 305           |\n",
      "|    value_loss         | 165           |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39000     |\n",
      "|    time_elapsed       | 165079    |\n",
      "|    total_timesteps    | 3900000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38999     |\n",
      "|    policy_loss        | 144       |\n",
      "|    reward             | -0.003099 |\n",
      "|    std                | 307       |\n",
      "|    value_loss         | 4.96      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 39100          |\n",
      "|    time_elapsed       | 165500         |\n",
      "|    total_timesteps    | 3910000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 39099          |\n",
      "|    policy_loss        | 49.7           |\n",
      "|    reward             | -8.9999994e-05 |\n",
      "|    std                | 308            |\n",
      "|    value_loss         | 1.34           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39200     |\n",
      "|    time_elapsed       | 165920    |\n",
      "|    total_timesteps    | 3920000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39199     |\n",
      "|    policy_loss        | -23.6     |\n",
      "|    reward             | -0.003048 |\n",
      "|    std                | 309       |\n",
      "|    value_loss         | 3.09      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39300     |\n",
      "|    time_elapsed       | 166340    |\n",
      "|    total_timesteps    | 3930000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39299     |\n",
      "|    policy_loss        | 106       |\n",
      "|    reward             | -0.001092 |\n",
      "|    std                | 311       |\n",
      "|    value_loss         | 4.07      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39400     |\n",
      "|    time_elapsed       | 166759    |\n",
      "|    total_timesteps    | 3940000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.5     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39399     |\n",
      "|    policy_loss        | -1.81e+03 |\n",
      "|    reward             | 5.373805  |\n",
      "|    std                | 310       |\n",
      "|    value_loss         | 758       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 39500    |\n",
      "|    time_elapsed       | 167178   |\n",
      "|    total_timesteps    | 3950000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39499    |\n",
      "|    policy_loss        | -6.74    |\n",
      "|    reward             | -0.00115 |\n",
      "|    std                | 310      |\n",
      "|    value_loss         | 24       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39600     |\n",
      "|    time_elapsed       | 167598    |\n",
      "|    total_timesteps    | 3960000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39599     |\n",
      "|    policy_loss        | 622       |\n",
      "|    reward             | -9.366624 |\n",
      "|    std                | 310       |\n",
      "|    value_loss         | 82.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 39700    |\n",
      "|    time_elapsed       | 168017   |\n",
      "|    total_timesteps    | 3970000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39699    |\n",
      "|    policy_loss        | 23.2     |\n",
      "|    reward             | 0.194162 |\n",
      "|    std                | 311      |\n",
      "|    value_loss         | 0.354    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 39800     |\n",
      "|    time_elapsed       | 168437    |\n",
      "|    total_timesteps    | 3980000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39799     |\n",
      "|    policy_loss        | -9.78     |\n",
      "|    reward             | -0.003637 |\n",
      "|    std                | 314       |\n",
      "|    value_loss         | 2.62      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 39900          |\n",
      "|    time_elapsed       | 168856         |\n",
      "|    total_timesteps    | 3990000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 39899          |\n",
      "|    policy_loss        | -182           |\n",
      "|    reward             | -5.7999994e-05 |\n",
      "|    std                | 314            |\n",
      "|    value_loss         | 11.4           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40000     |\n",
      "|    time_elapsed       | 169276    |\n",
      "|    total_timesteps    | 4000000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 39999     |\n",
      "|    policy_loss        | 214       |\n",
      "|    reward             | -0.004038 |\n",
      "|    std                | 315       |\n",
      "|    value_loss         | 14.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40100     |\n",
      "|    time_elapsed       | 169695    |\n",
      "|    total_timesteps    | 4010000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40099     |\n",
      "|    policy_loss        | -170      |\n",
      "|    reward             | -0.001455 |\n",
      "|    std                | 316       |\n",
      "|    value_loss         | 22.2      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 40200          |\n",
      "|    time_elapsed       | 170114         |\n",
      "|    total_timesteps    | 4020000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 40199          |\n",
      "|    policy_loss        | 293            |\n",
      "|    reward             | -3.4000004e-05 |\n",
      "|    std                | 316            |\n",
      "|    value_loss         | 19.6           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40300     |\n",
      "|    time_elapsed       | 170533    |\n",
      "|    total_timesteps    | 4030000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40299     |\n",
      "|    policy_loss        | 268       |\n",
      "|    reward             | -0.001127 |\n",
      "|    std                | 318       |\n",
      "|    value_loss         | 25.5      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 40400          |\n",
      "|    time_elapsed       | 170953         |\n",
      "|    total_timesteps    | 4040000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 40399          |\n",
      "|    policy_loss        | 36.2           |\n",
      "|    reward             | -0.00040899997 |\n",
      "|    std                | 317            |\n",
      "|    value_loss         | 17.2           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40500     |\n",
      "|    time_elapsed       | 171371    |\n",
      "|    total_timesteps    | 4050000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40499     |\n",
      "|    policy_loss        | 9.84      |\n",
      "|    reward             | -0.001344 |\n",
      "|    std                | 319       |\n",
      "|    value_loss         | 1.95      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40600     |\n",
      "|    time_elapsed       | 171790    |\n",
      "|    total_timesteps    | 4060000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40599     |\n",
      "|    policy_loss        | -85.3     |\n",
      "|    reward             | -0.003337 |\n",
      "|    std                | 321       |\n",
      "|    value_loss         | 5.31      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 40700    |\n",
      "|    time_elapsed       | 172210   |\n",
      "|    total_timesteps    | 4070000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 40699    |\n",
      "|    policy_loss        | -122     |\n",
      "|    reward             | -8.3e-05 |\n",
      "|    std                | 320      |\n",
      "|    value_loss         | 8.93     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 40800     |\n",
      "|    time_elapsed       | 172628    |\n",
      "|    total_timesteps    | 4080000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40799     |\n",
      "|    policy_loss        | -1.69e+03 |\n",
      "|    reward             | -0.001726 |\n",
      "|    std                | 321       |\n",
      "|    value_loss         | 871       |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 40900          |\n",
      "|    time_elapsed       | 173047         |\n",
      "|    total_timesteps    | 4090000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -71.9          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 40899          |\n",
      "|    policy_loss        | 254            |\n",
      "|    reward             | -8.9999994e-05 |\n",
      "|    std                | 321            |\n",
      "|    value_loss         | 39.4           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41000     |\n",
      "|    time_elapsed       | 173467    |\n",
      "|    total_timesteps    | 4100000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 40999     |\n",
      "|    policy_loss        | 24        |\n",
      "|    reward             | -0.003431 |\n",
      "|    std                | 322       |\n",
      "|    value_loss         | 23.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 41100    |\n",
      "|    time_elapsed       | 173886   |\n",
      "|    total_timesteps    | 4110000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -71.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41099    |\n",
      "|    policy_loss        | -461     |\n",
      "|    reward             | 1.170151 |\n",
      "|    std                | 322      |\n",
      "|    value_loss         | 71.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41200     |\n",
      "|    time_elapsed       | 174306    |\n",
      "|    total_timesteps    | 4120000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -71.9     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41199     |\n",
      "|    policy_loss        | -56.2     |\n",
      "|    reward             | -0.00179  |\n",
      "|    std                | 324       |\n",
      "|    value_loss         | 0.681     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41300     |\n",
      "|    time_elapsed       | 174724    |\n",
      "|    total_timesteps    | 4130000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41299     |\n",
      "|    policy_loss        | -22.2     |\n",
      "|    reward             | -0.004264 |\n",
      "|    std                | 327       |\n",
      "|    value_loss         | 1.48      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 41400    |\n",
      "|    time_elapsed       | 175145   |\n",
      "|    total_timesteps    | 4140000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 41399    |\n",
      "|    policy_loss        | 97.1     |\n",
      "|    reward             | 0.771152 |\n",
      "|    std                | 327      |\n",
      "|    value_loss         | 24.2     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 41500          |\n",
      "|    time_elapsed       | 175565         |\n",
      "|    total_timesteps    | 4150000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -72.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 41499          |\n",
      "|    policy_loss        | 92.2           |\n",
      "|    reward             | -0.00055399997 |\n",
      "|    std                | 329            |\n",
      "|    value_loss         | 2.37           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41600     |\n",
      "|    time_elapsed       | 175987    |\n",
      "|    total_timesteps    | 4160000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41599     |\n",
      "|    policy_loss        | -605      |\n",
      "|    reward             | 0.596349  |\n",
      "|    std                | 330       |\n",
      "|    value_loss         | 99.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41700     |\n",
      "|    time_elapsed       | 176407    |\n",
      "|    total_timesteps    | 4170000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41699     |\n",
      "|    policy_loss        | -282      |\n",
      "|    reward             | -0.000141 |\n",
      "|    std                | 330       |\n",
      "|    value_loss         | 43.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41800     |\n",
      "|    time_elapsed       | 176827    |\n",
      "|    total_timesteps    | 4180000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41799     |\n",
      "|    policy_loss        | 251       |\n",
      "|    reward             | -0.004872 |\n",
      "|    std                | 330       |\n",
      "|    value_loss         | 38.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 41900     |\n",
      "|    time_elapsed       | 177246    |\n",
      "|    total_timesteps    | 4190000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.2     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41899     |\n",
      "|    policy_loss        | 701       |\n",
      "|    reward             | -0.002167 |\n",
      "|    std                | 332       |\n",
      "|    value_loss         | 148       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42000     |\n",
      "|    time_elapsed       | 177667    |\n",
      "|    total_timesteps    | 4200000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41999     |\n",
      "|    policy_loss        | -70       |\n",
      "|    reward             | -0.000137 |\n",
      "|    std                | 335       |\n",
      "|    value_loss         | 1.77      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42100     |\n",
      "|    time_elapsed       | 178088    |\n",
      "|    total_timesteps    | 4210000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42099     |\n",
      "|    policy_loss        | 234       |\n",
      "|    reward             | -5.6e-05  |\n",
      "|    std                | 336       |\n",
      "|    value_loss         | 18.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42200     |\n",
      "|    time_elapsed       | 178509    |\n",
      "|    total_timesteps    | 4220000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42199     |\n",
      "|    policy_loss        | -32       |\n",
      "|    reward             | -0.000719 |\n",
      "|    std                | 336       |\n",
      "|    value_loss         | 2.42      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 42300         |\n",
      "|    time_elapsed       | 178930        |\n",
      "|    total_timesteps    | 4230000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -72.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 42299         |\n",
      "|    policy_loss        | 35.8          |\n",
      "|    reward             | -8.299998e-05 |\n",
      "|    std                | 337           |\n",
      "|    value_loss         | 126           |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42400     |\n",
      "|    time_elapsed       | 179352    |\n",
      "|    total_timesteps    | 4240000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42399     |\n",
      "|    policy_loss        | 694       |\n",
      "|    reward             | -0.001446 |\n",
      "|    std                | 338       |\n",
      "|    value_loss         | 166       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42500     |\n",
      "|    time_elapsed       | 179774    |\n",
      "|    total_timesteps    | 4250000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42499     |\n",
      "|    policy_loss        | -1.57e+03 |\n",
      "|    reward             | -0.002073 |\n",
      "|    std                | 337       |\n",
      "|    value_loss         | 581       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 42600    |\n",
      "|    time_elapsed       | 180194   |\n",
      "|    total_timesteps    | 4260000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42599    |\n",
      "|    policy_loss        | -712     |\n",
      "|    reward             | 3.814465 |\n",
      "|    std                | 338      |\n",
      "|    value_loss         | 242      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42700     |\n",
      "|    time_elapsed       | 180614    |\n",
      "|    total_timesteps    | 4270000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42699     |\n",
      "|    policy_loss        | 48.8      |\n",
      "|    reward             | -0.007145 |\n",
      "|    std                | 338       |\n",
      "|    value_loss         | 0.594     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 42800    |\n",
      "|    time_elapsed       | 181034   |\n",
      "|    total_timesteps    | 4280000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.5    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 42799    |\n",
      "|    policy_loss        | 77.3     |\n",
      "|    reward             | -1.9e-05 |\n",
      "|    std                | 341      |\n",
      "|    value_loss         | 1.8      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 42900     |\n",
      "|    time_elapsed       | 181457    |\n",
      "|    total_timesteps    | 4290000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42899     |\n",
      "|    policy_loss        | -670      |\n",
      "|    reward             | -0.004501 |\n",
      "|    std                | 342       |\n",
      "|    value_loss         | 99.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43000     |\n",
      "|    time_elapsed       | 181878    |\n",
      "|    total_timesteps    | 4300000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 42999     |\n",
      "|    policy_loss        | 132       |\n",
      "|    reward             | -0.003322 |\n",
      "|    std                | 343       |\n",
      "|    value_loss         | 5.88      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43100     |\n",
      "|    time_elapsed       | 182300    |\n",
      "|    total_timesteps    | 4310000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43099     |\n",
      "|    policy_loss        | 347       |\n",
      "|    reward             | -0.000203 |\n",
      "|    std                | 344       |\n",
      "|    value_loss         | 34.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43200     |\n",
      "|    time_elapsed       | 182722    |\n",
      "|    total_timesteps    | 4320000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43199     |\n",
      "|    policy_loss        | 642       |\n",
      "|    reward             | -0.000791 |\n",
      "|    std                | 344       |\n",
      "|    value_loss         | 89.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 43300    |\n",
      "|    time_elapsed       | 183142   |\n",
      "|    total_timesteps    | 4330000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 43299    |\n",
      "|    policy_loss        | -559     |\n",
      "|    reward             | -0.00143 |\n",
      "|    std                | 344      |\n",
      "|    value_loss         | 143      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43400     |\n",
      "|    time_elapsed       | 183562    |\n",
      "|    total_timesteps    | 4340000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43399     |\n",
      "|    policy_loss        | -255      |\n",
      "|    reward             | -0.002452 |\n",
      "|    std                | 344       |\n",
      "|    value_loss         | 71.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43500     |\n",
      "|    time_elapsed       | 183992    |\n",
      "|    total_timesteps    | 4350000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43499     |\n",
      "|    policy_loss        | 112       |\n",
      "|    reward             | -0.432512 |\n",
      "|    std                | 347       |\n",
      "|    value_loss         | 6.9       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43600     |\n",
      "|    time_elapsed       | 184421    |\n",
      "|    total_timesteps    | 4360000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43599     |\n",
      "|    policy_loss        | 376       |\n",
      "|    reward             | -2.172421 |\n",
      "|    std                | 348       |\n",
      "|    value_loss         | 34.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 43700     |\n",
      "|    time_elapsed       | 184850    |\n",
      "|    total_timesteps    | 4370000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43699     |\n",
      "|    policy_loss        | 23.4      |\n",
      "|    reward             | -0.004357 |\n",
      "|    std                | 347       |\n",
      "|    value_loss         | 0.301     |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 43800         |\n",
      "|    time_elapsed       | 185279        |\n",
      "|    total_timesteps    | 4380000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -72.7         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 43799         |\n",
      "|    policy_loss        | -193          |\n",
      "|    reward             | -0.0013519999 |\n",
      "|    std                | 348           |\n",
      "|    value_loss         | 25.3          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 43900          |\n",
      "|    time_elapsed       | 185707         |\n",
      "|    total_timesteps    | 4390000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -72.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 43899          |\n",
      "|    policy_loss        | 78.8           |\n",
      "|    reward             | -4.5000015e-05 |\n",
      "|    std                | 349            |\n",
      "|    value_loss         | 7.66           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 44000          |\n",
      "|    time_elapsed       | 186136         |\n",
      "|    total_timesteps    | 4400000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -72.7          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 43999          |\n",
      "|    policy_loss        | -19.3          |\n",
      "|    reward             | -0.00013000001 |\n",
      "|    std                | 352            |\n",
      "|    value_loss         | 7.87           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44100     |\n",
      "|    time_elapsed       | 186564    |\n",
      "|    total_timesteps    | 4410000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44099     |\n",
      "|    policy_loss        | -337      |\n",
      "|    reward             | -0.00207  |\n",
      "|    std                | 352       |\n",
      "|    value_loss         | 43.7      |\n",
      "-------------------------------------\n",
      "Moment: 74871, episode: 60\n",
      "begin_total_asset: -1414334128.76\n",
      "end_total_asset: -1203932.69\n",
      "total_reward: -1303932.69\n",
      "total_trades: 365224\n",
      "Sharpe: 0.064\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44200     |\n",
      "|    time_elapsed       | 186993    |\n",
      "|    total_timesteps    | 4420000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44199     |\n",
      "|    policy_loss        | -111      |\n",
      "|    reward             | -0.000218 |\n",
      "|    std                | 354       |\n",
      "|    value_loss         | 2.94      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44300     |\n",
      "|    time_elapsed       | 187421    |\n",
      "|    total_timesteps    | 4430000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44299     |\n",
      "|    policy_loss        | 28.8      |\n",
      "|    reward             | -0.002787 |\n",
      "|    std                | 356       |\n",
      "|    value_loss         | 0.573     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44400     |\n",
      "|    time_elapsed       | 187850    |\n",
      "|    total_timesteps    | 4440000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44399     |\n",
      "|    policy_loss        | -106      |\n",
      "|    reward             | -0.001331 |\n",
      "|    std                | 357       |\n",
      "|    value_loss         | 6.7       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44500     |\n",
      "|    time_elapsed       | 188278    |\n",
      "|    total_timesteps    | 4450000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44499     |\n",
      "|    policy_loss        | 537       |\n",
      "|    reward             | -0.000297 |\n",
      "|    std                | 357       |\n",
      "|    value_loss         | 85.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44600     |\n",
      "|    time_elapsed       | 188706    |\n",
      "|    total_timesteps    | 4460000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44599     |\n",
      "|    policy_loss        | -209      |\n",
      "|    reward             | -0.003377 |\n",
      "|    std                | 357       |\n",
      "|    value_loss         | 16.6      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 44700         |\n",
      "|    time_elapsed       | 189135        |\n",
      "|    total_timesteps    | 4470000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -72.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 44699         |\n",
      "|    policy_loss        | -99.5         |\n",
      "|    reward             | -4.299998e-05 |\n",
      "|    std                | 357           |\n",
      "|    value_loss         | 16.9          |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 44800    |\n",
      "|    time_elapsed       | 189564   |\n",
      "|    total_timesteps    | 4480000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -72.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44799    |\n",
      "|    policy_loss        | -134     |\n",
      "|    reward             | -0.00217 |\n",
      "|    std                | 357      |\n",
      "|    value_loss         | 103      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 44900     |\n",
      "|    time_elapsed       | 189991    |\n",
      "|    total_timesteps    | 4490000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -72.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 44899     |\n",
      "|    policy_loss        | 2.38e+03  |\n",
      "|    reward             | -0.004207 |\n",
      "|    std                | 358       |\n",
      "|    value_loss         | 1.17e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 45000    |\n",
      "|    time_elapsed       | 190419   |\n",
      "|    total_timesteps    | 4500000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 44999    |\n",
      "|    policy_loss        | 156      |\n",
      "|    reward             | 0.206905 |\n",
      "|    std                | 361      |\n",
      "|    value_loss         | 6.96     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 45100     |\n",
      "|    time_elapsed       | 190848    |\n",
      "|    total_timesteps    | 4510000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45099     |\n",
      "|    policy_loss        | -146      |\n",
      "|    reward             | -1.376987 |\n",
      "|    std                | 362       |\n",
      "|    value_loss         | 8.65      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 45200    |\n",
      "|    time_elapsed       | 191269   |\n",
      "|    total_timesteps    | 4520000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45199    |\n",
      "|    policy_loss        | -191     |\n",
      "|    reward             | -1e-04   |\n",
      "|    std                | 363      |\n",
      "|    value_loss         | 12.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 45300     |\n",
      "|    time_elapsed       | 191690    |\n",
      "|    total_timesteps    | 4530000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45299     |\n",
      "|    policy_loss        | 59.1      |\n",
      "|    reward             | -0.004944 |\n",
      "|    std                | 365       |\n",
      "|    value_loss         | 25.6      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 45400         |\n",
      "|    time_elapsed       | 192110        |\n",
      "|    total_timesteps    | 4540000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -73.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 45399         |\n",
      "|    policy_loss        | 187           |\n",
      "|    reward             | -0.0014300001 |\n",
      "|    std                | 365           |\n",
      "|    value_loss         | 35.2          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 45500         |\n",
      "|    time_elapsed       | 192532        |\n",
      "|    total_timesteps    | 4550000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -73.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 45499         |\n",
      "|    policy_loss        | -536          |\n",
      "|    reward             | -0.0027359999 |\n",
      "|    std                | 367           |\n",
      "|    value_loss         | 78.3          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 45600         |\n",
      "|    time_elapsed       | 192951        |\n",
      "|    total_timesteps    | 4560000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -73.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 45599         |\n",
      "|    policy_loss        | 240           |\n",
      "|    reward             | -3.000002e-05 |\n",
      "|    std                | 367           |\n",
      "|    value_loss         | 76.5          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 45700     |\n",
      "|    time_elapsed       | 193370    |\n",
      "|    total_timesteps    | 4570000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45699     |\n",
      "|    policy_loss        | 76.9      |\n",
      "|    reward             | -0.000197 |\n",
      "|    std                | 370       |\n",
      "|    value_loss         | 1.73      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 45800    |\n",
      "|    time_elapsed       | 193791   |\n",
      "|    total_timesteps    | 4580000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45799    |\n",
      "|    policy_loss        | -5.9     |\n",
      "|    reward             | 0.324677 |\n",
      "|    std                | 372      |\n",
      "|    value_loss         | 0.615    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 45900     |\n",
      "|    time_elapsed       | 194212    |\n",
      "|    total_timesteps    | 4590000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45899     |\n",
      "|    policy_loss        | -437      |\n",
      "|    reward             | -0.001351 |\n",
      "|    std                | 375       |\n",
      "|    value_loss         | 50.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46000     |\n",
      "|    time_elapsed       | 194633    |\n",
      "|    total_timesteps    | 4600000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 45999     |\n",
      "|    policy_loss        | -89.3     |\n",
      "|    reward             | -0.003043 |\n",
      "|    std                | 374       |\n",
      "|    value_loss         | 18.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46100     |\n",
      "|    time_elapsed       | 195054    |\n",
      "|    total_timesteps    | 4610000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46099     |\n",
      "|    policy_loss        | -105      |\n",
      "|    reward             | -0.001635 |\n",
      "|    std                | 375       |\n",
      "|    value_loss         | 11.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 46200    |\n",
      "|    time_elapsed       | 195476   |\n",
      "|    total_timesteps    | 4620000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46199    |\n",
      "|    policy_loss        | -830     |\n",
      "|    reward             | 0.74371  |\n",
      "|    std                | 376      |\n",
      "|    value_loss         | 183      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46300     |\n",
      "|    time_elapsed       | 195897    |\n",
      "|    total_timesteps    | 4630000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46299     |\n",
      "|    policy_loss        | 174       |\n",
      "|    reward             | -0.001717 |\n",
      "|    std                | 376       |\n",
      "|    value_loss         | 25        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46400     |\n",
      "|    time_elapsed       | 196316    |\n",
      "|    total_timesteps    | 4640000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46399     |\n",
      "|    policy_loss        | -1.03e+03 |\n",
      "|    reward             | -0.002141 |\n",
      "|    std                | 377       |\n",
      "|    value_loss         | 1.06e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46500     |\n",
      "|    time_elapsed       | 196737    |\n",
      "|    total_timesteps    | 4650000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46499     |\n",
      "|    policy_loss        | -197      |\n",
      "|    reward             | 0.622256  |\n",
      "|    std                | 379       |\n",
      "|    value_loss         | 14.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 46600    |\n",
      "|    time_elapsed       | 197159   |\n",
      "|    total_timesteps    | 4660000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46599    |\n",
      "|    policy_loss        | -119     |\n",
      "|    reward             | -3.9e-05 |\n",
      "|    std                | 381      |\n",
      "|    value_loss         | 9.07     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46700     |\n",
      "|    time_elapsed       | 197581    |\n",
      "|    total_timesteps    | 4670000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46699     |\n",
      "|    policy_loss        | 195       |\n",
      "|    reward             | -0.002287 |\n",
      "|    std                | 382       |\n",
      "|    value_loss         | 16.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 46800    |\n",
      "|    time_elapsed       | 198001   |\n",
      "|    total_timesteps    | 4680000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 46799    |\n",
      "|    policy_loss        | 21.2     |\n",
      "|    reward             | 0.465806 |\n",
      "|    std                | 382      |\n",
      "|    value_loss         | 51.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 46900     |\n",
      "|    time_elapsed       | 198424    |\n",
      "|    total_timesteps    | 4690000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46899     |\n",
      "|    policy_loss        | 253       |\n",
      "|    reward             | -0.001494 |\n",
      "|    std                | 382       |\n",
      "|    value_loss         | 17.4      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 47000         |\n",
      "|    time_elapsed       | 198847        |\n",
      "|    total_timesteps    | 4700000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -73.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 46999         |\n",
      "|    policy_loss        | 487           |\n",
      "|    reward             | -0.0046180002 |\n",
      "|    std                | 383           |\n",
      "|    value_loss         | 227           |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47100     |\n",
      "|    time_elapsed       | 199268    |\n",
      "|    total_timesteps    | 4710000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47099     |\n",
      "|    policy_loss        | -218      |\n",
      "|    reward             | -0.002261 |\n",
      "|    std                | 384       |\n",
      "|    value_loss         | 74.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 47200    |\n",
      "|    time_elapsed       | 199687   |\n",
      "|    total_timesteps    | 4720000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47199    |\n",
      "|    policy_loss        | -115     |\n",
      "|    reward             | 0.057999 |\n",
      "|    std                | 386      |\n",
      "|    value_loss         | 2.53     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47300     |\n",
      "|    time_elapsed       | 200110    |\n",
      "|    total_timesteps    | 4730000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47299     |\n",
      "|    policy_loss        | 184       |\n",
      "|    reward             | -0.002637 |\n",
      "|    std                | 389       |\n",
      "|    value_loss         | 10.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 47400    |\n",
      "|    time_elapsed       | 200531   |\n",
      "|    total_timesteps    | 4740000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47399    |\n",
      "|    policy_loss        | -118     |\n",
      "|    reward             | -0.00064 |\n",
      "|    std                | 391      |\n",
      "|    value_loss         | 6.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 47500    |\n",
      "|    time_elapsed       | 200952   |\n",
      "|    total_timesteps    | 4750000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47499    |\n",
      "|    policy_loss        | 298      |\n",
      "|    reward             | 0.408113 |\n",
      "|    std                | 393      |\n",
      "|    value_loss         | 51       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47600     |\n",
      "|    time_elapsed       | 201386    |\n",
      "|    total_timesteps    | 4760000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47599     |\n",
      "|    policy_loss        | -2.09e+03 |\n",
      "|    reward             | -0.00173  |\n",
      "|    std                | 393       |\n",
      "|    value_loss         | 845       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47700     |\n",
      "|    time_elapsed       | 201824    |\n",
      "|    total_timesteps    | 4770000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47699     |\n",
      "|    policy_loss        | -22.8     |\n",
      "|    reward             | -0.001597 |\n",
      "|    std                | 395       |\n",
      "|    value_loss         | 6.56      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47800     |\n",
      "|    time_elapsed       | 202256    |\n",
      "|    total_timesteps    | 4780000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47799     |\n",
      "|    policy_loss        | 68.3      |\n",
      "|    reward             | -0.005204 |\n",
      "|    std                | 396       |\n",
      "|    value_loss         | 68.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 47900     |\n",
      "|    time_elapsed       | 202691    |\n",
      "|    total_timesteps    | 4790000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -73.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47899     |\n",
      "|    policy_loss        | 556       |\n",
      "|    reward             | -0.003814 |\n",
      "|    std                | 395       |\n",
      "|    value_loss         | 185       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 48000    |\n",
      "|    time_elapsed       | 203125   |\n",
      "|    total_timesteps    | 4800000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -73.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 47999    |\n",
      "|    policy_loss        | 75.1     |\n",
      "|    reward             | 0.86138  |\n",
      "|    std                | 397      |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48100     |\n",
      "|    time_elapsed       | 203556    |\n",
      "|    total_timesteps    | 4810000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48099     |\n",
      "|    policy_loss        | 324       |\n",
      "|    reward             | -0.003442 |\n",
      "|    std                | 399       |\n",
      "|    value_loss         | 22.8      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 48200          |\n",
      "|    time_elapsed       | 203990         |\n",
      "|    total_timesteps    | 4820000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -74            |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 48199          |\n",
      "|    policy_loss        | -293           |\n",
      "|    reward             | -9.8000004e-05 |\n",
      "|    std                | 399            |\n",
      "|    value_loss         | 22.2           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48300     |\n",
      "|    time_elapsed       | 204411    |\n",
      "|    total_timesteps    | 4830000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48299     |\n",
      "|    policy_loss        | -159      |\n",
      "|    reward             | -0.006701 |\n",
      "|    std                | 400       |\n",
      "|    value_loss         | 10.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48400     |\n",
      "|    time_elapsed       | 204831    |\n",
      "|    total_timesteps    | 4840000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48399     |\n",
      "|    policy_loss        | -222      |\n",
      "|    reward             | -0.000865 |\n",
      "|    std                | 401       |\n",
      "|    value_loss         | 14.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48500     |\n",
      "|    time_elapsed       | 205252    |\n",
      "|    total_timesteps    | 4850000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48499     |\n",
      "|    policy_loss        | -1.05e+03 |\n",
      "|    reward             | -0.001132 |\n",
      "|    std                | 401       |\n",
      "|    value_loss         | 348       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48600     |\n",
      "|    time_elapsed       | 205672    |\n",
      "|    total_timesteps    | 4860000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48599     |\n",
      "|    policy_loss        | -98.2     |\n",
      "|    reward             | -0.004713 |\n",
      "|    std                | 401       |\n",
      "|    value_loss         | 51.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48700     |\n",
      "|    time_elapsed       | 206090    |\n",
      "|    total_timesteps    | 4870000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48699     |\n",
      "|    policy_loss        | 3.57      |\n",
      "|    reward             | -1.020432 |\n",
      "|    std                | 404       |\n",
      "|    value_loss         | 0.282     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 48800     |\n",
      "|    time_elapsed       | 206509    |\n",
      "|    total_timesteps    | 4880000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48799     |\n",
      "|    policy_loss        | -53.5     |\n",
      "|    reward             | -0.003225 |\n",
      "|    std                | 406       |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 48900    |\n",
      "|    time_elapsed       | 206927   |\n",
      "|    total_timesteps    | 4890000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 48899    |\n",
      "|    policy_loss        | -326     |\n",
      "|    reward             | 2.108775 |\n",
      "|    std                | 407      |\n",
      "|    value_loss         | 24.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49000     |\n",
      "|    time_elapsed       | 207346    |\n",
      "|    total_timesteps    | 4900000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.2     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 48999     |\n",
      "|    policy_loss        | 215       |\n",
      "|    reward             | -0.000165 |\n",
      "|    std                | 407       |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49100     |\n",
      "|    time_elapsed       | 207764    |\n",
      "|    total_timesteps    | 4910000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49099     |\n",
      "|    policy_loss        | 285       |\n",
      "|    reward             | -1.093809 |\n",
      "|    std                | 408       |\n",
      "|    value_loss         | 93.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49200     |\n",
      "|    time_elapsed       | 208184    |\n",
      "|    total_timesteps    | 4920000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49199     |\n",
      "|    policy_loss        | -725      |\n",
      "|    reward             | -0.002324 |\n",
      "|    std                | 409       |\n",
      "|    value_loss         | 298       |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 49300         |\n",
      "|    time_elapsed       | 208603        |\n",
      "|    total_timesteps    | 4930000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -74.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 49299         |\n",
      "|    policy_loss        | 204           |\n",
      "|    reward             | -0.0017050001 |\n",
      "|    std                | 410           |\n",
      "|    value_loss         | 17            |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49400     |\n",
      "|    time_elapsed       | 209021    |\n",
      "|    total_timesteps    | 4940000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49399     |\n",
      "|    policy_loss        | -396      |\n",
      "|    reward             | -0.002821 |\n",
      "|    std                | 410       |\n",
      "|    value_loss         | 70.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49500     |\n",
      "|    time_elapsed       | 209440    |\n",
      "|    total_timesteps    | 4950000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49499     |\n",
      "|    policy_loss        | -103      |\n",
      "|    reward             | -0.001522 |\n",
      "|    std                | 413       |\n",
      "|    value_loss         | 4         |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49600     |\n",
      "|    time_elapsed       | 209859    |\n",
      "|    total_timesteps    | 4960000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49599     |\n",
      "|    policy_loss        | -87.2     |\n",
      "|    reward             | -0.000166 |\n",
      "|    std                | 415       |\n",
      "|    value_loss         | 7.96      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49700     |\n",
      "|    time_elapsed       | 210279    |\n",
      "|    total_timesteps    | 4970000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49699     |\n",
      "|    policy_loss        | 35.9      |\n",
      "|    reward             | -0.000547 |\n",
      "|    std                | 415       |\n",
      "|    value_loss         | 9.05      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49800     |\n",
      "|    time_elapsed       | 210698    |\n",
      "|    total_timesteps    | 4980000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.4     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49799     |\n",
      "|    policy_loss        | 707       |\n",
      "|    reward             | -0.001204 |\n",
      "|    std                | 418       |\n",
      "|    value_loss         | 133       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 49900     |\n",
      "|    time_elapsed       | 211117    |\n",
      "|    total_timesteps    | 4990000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 49899     |\n",
      "|    policy_loss        | 105       |\n",
      "|    reward             | -0.001335 |\n",
      "|    std                | 417       |\n",
      "|    value_loss         | 13.3      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 50000          |\n",
      "|    time_elapsed       | 211537         |\n",
      "|    total_timesteps    | 5000000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -74.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 49999          |\n",
      "|    policy_loss        | -2.03e+03      |\n",
      "|    reward             | -0.00021600003 |\n",
      "|    std                | 419            |\n",
      "|    value_loss         | 887            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50100     |\n",
      "|    time_elapsed       | 211956    |\n",
      "|    total_timesteps    | 5010000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50099     |\n",
      "|    policy_loss        | -563      |\n",
      "|    reward             | -0.001501 |\n",
      "|    std                | 419       |\n",
      "|    value_loss         | 238       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 50200    |\n",
      "|    time_elapsed       | 212376   |\n",
      "|    total_timesteps    | 5020000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50199    |\n",
      "|    policy_loss        | -41.6    |\n",
      "|    reward             | 0.061226 |\n",
      "|    std                | 422      |\n",
      "|    value_loss         | 0.508    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50300     |\n",
      "|    time_elapsed       | 212794    |\n",
      "|    total_timesteps    | 5030000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50299     |\n",
      "|    policy_loss        | -209      |\n",
      "|    reward             | -0.174442 |\n",
      "|    std                | 424       |\n",
      "|    value_loss         | 36.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50400     |\n",
      "|    time_elapsed       | 213213    |\n",
      "|    total_timesteps    | 5040000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50399     |\n",
      "|    policy_loss        | 577       |\n",
      "|    reward             | -0.000957 |\n",
      "|    std                | 425       |\n",
      "|    value_loss         | 94.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50500     |\n",
      "|    time_elapsed       | 213632    |\n",
      "|    total_timesteps    | 5050000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50499     |\n",
      "|    policy_loss        | -61.9     |\n",
      "|    reward             | -0.002191 |\n",
      "|    std                | 429       |\n",
      "|    value_loss         | 20.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 50600    |\n",
      "|    time_elapsed       | 214051   |\n",
      "|    total_timesteps    | 5060000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -74.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 50599    |\n",
      "|    policy_loss        | -268     |\n",
      "|    reward             | 0.65737  |\n",
      "|    std                | 430      |\n",
      "|    value_loss         | 73.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50700     |\n",
      "|    time_elapsed       | 214470    |\n",
      "|    total_timesteps    | 5070000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50699     |\n",
      "|    policy_loss        | -324      |\n",
      "|    reward             | -0.001852 |\n",
      "|    std                | 432       |\n",
      "|    value_loss         | 21.8      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 50800          |\n",
      "|    time_elapsed       | 214889         |\n",
      "|    total_timesteps    | 5080000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -74.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 50799          |\n",
      "|    policy_loss        | -92.9          |\n",
      "|    reward             | -2.9000044e-05 |\n",
      "|    std                | 432            |\n",
      "|    value_loss         | 32.9           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 50900     |\n",
      "|    time_elapsed       | 215308    |\n",
      "|    total_timesteps    | 5090000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50899     |\n",
      "|    policy_loss        | 655       |\n",
      "|    reward             | -3.777073 |\n",
      "|    std                | 432       |\n",
      "|    value_loss         | 93.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51000     |\n",
      "|    time_elapsed       | 215727    |\n",
      "|    total_timesteps    | 5100000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50999     |\n",
      "|    policy_loss        | -10.5     |\n",
      "|    reward             | -0.262694 |\n",
      "|    std                | 436       |\n",
      "|    value_loss         | 0.486     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51100     |\n",
      "|    time_elapsed       | 216149    |\n",
      "|    total_timesteps    | 5110000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51099     |\n",
      "|    policy_loss        | 36.2      |\n",
      "|    reward             | -0.000847 |\n",
      "|    std                | 437       |\n",
      "|    value_loss         | 3.9       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51200     |\n",
      "|    time_elapsed       | 216570    |\n",
      "|    total_timesteps    | 5120000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51199     |\n",
      "|    policy_loss        | 505       |\n",
      "|    reward             | -0.001848 |\n",
      "|    std                | 436       |\n",
      "|    value_loss         | 57.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51300     |\n",
      "|    time_elapsed       | 216992    |\n",
      "|    total_timesteps    | 5130000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51299     |\n",
      "|    policy_loss        | 262       |\n",
      "|    reward             | -0.004633 |\n",
      "|    std                | 438       |\n",
      "|    value_loss         | 36.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51400     |\n",
      "|    time_elapsed       | 217412    |\n",
      "|    total_timesteps    | 5140000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51399     |\n",
      "|    policy_loss        | 753       |\n",
      "|    reward             | -0.004419 |\n",
      "|    std                | 438       |\n",
      "|    value_loss         | 165       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51500     |\n",
      "|    time_elapsed       | 217833    |\n",
      "|    total_timesteps    | 5150000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51499     |\n",
      "|    policy_loss        | -1.1e+03  |\n",
      "|    reward             | -0.002009 |\n",
      "|    std                | 439       |\n",
      "|    value_loss         | 336       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51600     |\n",
      "|    time_elapsed       | 218253    |\n",
      "|    total_timesteps    | 5160000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -74.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51599     |\n",
      "|    policy_loss        | -1.49e+03 |\n",
      "|    reward             | -0.004118 |\n",
      "|    std                | 440       |\n",
      "|    value_loss         | 627       |\n",
      "-------------------------------------\n",
      "Moment: 74871, episode: 70\n",
      "begin_total_asset: -1541392185.96\n",
      "end_total_asset: -1317506.77\n",
      "total_reward: -1417506.77\n",
      "total_trades: 367016\n",
      "Sharpe: 0.002\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51700     |\n",
      "|    time_elapsed       | 218673    |\n",
      "|    total_timesteps    | 5170000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51699     |\n",
      "|    policy_loss        | -35.7     |\n",
      "|    reward             | 0.046305  |\n",
      "|    std                | 441       |\n",
      "|    value_loss         | 0.525     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51800     |\n",
      "|    time_elapsed       | 219093    |\n",
      "|    total_timesteps    | 5180000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51799     |\n",
      "|    policy_loss        | 89        |\n",
      "|    reward             | -0.001262 |\n",
      "|    std                | 444       |\n",
      "|    value_loss         | 10.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 51900     |\n",
      "|    time_elapsed       | 219515    |\n",
      "|    total_timesteps    | 5190000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51899     |\n",
      "|    policy_loss        | -439      |\n",
      "|    reward             | -1.899655 |\n",
      "|    std                | 445       |\n",
      "|    value_loss         | 63.3      |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 23            |\n",
      "|    iterations         | 52000         |\n",
      "|    time_elapsed       | 219935        |\n",
      "|    total_timesteps    | 5200000       |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -75.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 51999         |\n",
      "|    policy_loss        | 134           |\n",
      "|    reward             | -0.0011539999 |\n",
      "|    std                | 446           |\n",
      "|    value_loss         | 9.4           |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 52100          |\n",
      "|    time_elapsed       | 220357         |\n",
      "|    total_timesteps    | 5210000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.1          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 52099          |\n",
      "|    policy_loss        | 483            |\n",
      "|    reward             | -0.00043800002 |\n",
      "|    std                | 447            |\n",
      "|    value_loss         | 54             |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52200     |\n",
      "|    time_elapsed       | 220777    |\n",
      "|    total_timesteps    | 5220000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52199     |\n",
      "|    policy_loss        | -127      |\n",
      "|    reward             | -0.003035 |\n",
      "|    std                | 449       |\n",
      "|    value_loss         | 23.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52300     |\n",
      "|    time_elapsed       | 221197    |\n",
      "|    total_timesteps    | 5230000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52299     |\n",
      "|    policy_loss        | -15.6     |\n",
      "|    reward             | -0.001722 |\n",
      "|    std                | 449       |\n",
      "|    value_loss         | 107       |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 52400          |\n",
      "|    time_elapsed       | 221616         |\n",
      "|    total_timesteps    | 5240000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.2          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 52399          |\n",
      "|    policy_loss        | 315            |\n",
      "|    reward             | -5.6999947e-05 |\n",
      "|    std                | 450            |\n",
      "|    value_loss         | 63.1           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52500     |\n",
      "|    time_elapsed       | 222035    |\n",
      "|    total_timesteps    | 5250000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52499     |\n",
      "|    policy_loss        | -258      |\n",
      "|    reward             | -0.128584 |\n",
      "|    std                | 454       |\n",
      "|    value_loss         | 13.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52600     |\n",
      "|    time_elapsed       | 222455    |\n",
      "|    total_timesteps    | 5260000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52599     |\n",
      "|    policy_loss        | 151       |\n",
      "|    reward             | -0.002393 |\n",
      "|    std                | 457       |\n",
      "|    value_loss         | 5.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52700     |\n",
      "|    time_elapsed       | 222878    |\n",
      "|    total_timesteps    | 5270000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52699     |\n",
      "|    policy_loss        | -368      |\n",
      "|    reward             | -0.001649 |\n",
      "|    std                | 456       |\n",
      "|    value_loss         | 39.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52800     |\n",
      "|    time_elapsed       | 223299    |\n",
      "|    total_timesteps    | 5280000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52799     |\n",
      "|    policy_loss        | 105       |\n",
      "|    reward             | -0.000143 |\n",
      "|    std                | 458       |\n",
      "|    value_loss         | 9.47      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 52900     |\n",
      "|    time_elapsed       | 223720    |\n",
      "|    total_timesteps    | 5290000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52899     |\n",
      "|    policy_loss        | 696       |\n",
      "|    reward             | -0.002883 |\n",
      "|    std                | 458       |\n",
      "|    value_loss         | 114       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53000     |\n",
      "|    time_elapsed       | 224141    |\n",
      "|    total_timesteps    | 5300000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 52999     |\n",
      "|    policy_loss        | 225       |\n",
      "|    reward             | -0.001632 |\n",
      "|    std                | 458       |\n",
      "|    value_loss         | 39.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53100     |\n",
      "|    time_elapsed       | 224561    |\n",
      "|    total_timesteps    | 5310000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53099     |\n",
      "|    policy_loss        | -530      |\n",
      "|    reward             | -0.003505 |\n",
      "|    std                | 459       |\n",
      "|    value_loss         | 126       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 53200    |\n",
      "|    time_elapsed       | 224981   |\n",
      "|    total_timesteps    | 5320000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 53199    |\n",
      "|    policy_loss        | -2.79    |\n",
      "|    reward             | -6.9e-05 |\n",
      "|    std                | 461      |\n",
      "|    value_loss         | 0.0821   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53300     |\n",
      "|    time_elapsed       | 225401    |\n",
      "|    total_timesteps    | 5330000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53299     |\n",
      "|    policy_loss        | 97.7      |\n",
      "|    reward             | -0.002127 |\n",
      "|    std                | 461       |\n",
      "|    value_loss         | 4.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53400     |\n",
      "|    time_elapsed       | 225821    |\n",
      "|    total_timesteps    | 5340000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53399     |\n",
      "|    policy_loss        | -660      |\n",
      "|    reward             | -0.002401 |\n",
      "|    std                | 461       |\n",
      "|    value_loss         | 90.6      |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 53500          |\n",
      "|    time_elapsed       | 226241         |\n",
      "|    total_timesteps    | 5350000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.5          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 53499          |\n",
      "|    policy_loss        | -886           |\n",
      "|    reward             | -5.4000007e-05 |\n",
      "|    std                | 463            |\n",
      "|    value_loss         | 164            |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 53600     |\n",
      "|    time_elapsed       | 226661    |\n",
      "|    total_timesteps    | 5360000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53599     |\n",
      "|    policy_loss        | -751      |\n",
      "|    reward             | -0.001409 |\n",
      "|    std                | 462       |\n",
      "|    value_loss         | 125       |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 53700          |\n",
      "|    time_elapsed       | 227081         |\n",
      "|    total_timesteps    | 5370000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.5          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 53699          |\n",
      "|    policy_loss        | 1.14e+03       |\n",
      "|    reward             | -0.00014300001 |\n",
      "|    std                | 463            |\n",
      "|    value_loss         | 265            |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 53800          |\n",
      "|    time_elapsed       | 227501         |\n",
      "|    total_timesteps    | 5380000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 53799          |\n",
      "|    policy_loss        | 172            |\n",
      "|    reward             | -5.8000016e-05 |\n",
      "|    std                | 463            |\n",
      "|    value_loss         | 33.7           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 53900          |\n",
      "|    time_elapsed       | 227920         |\n",
      "|    total_timesteps    | 5390000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 53899          |\n",
      "|    policy_loss        | -238           |\n",
      "|    reward             | -0.00011099999 |\n",
      "|    std                | 463            |\n",
      "|    value_loss         | 32             |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54000     |\n",
      "|    time_elapsed       | 228340    |\n",
      "|    total_timesteps    | 5400000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53999     |\n",
      "|    policy_loss        | -38.7     |\n",
      "|    reward             | -0.000386 |\n",
      "|    std                | 467       |\n",
      "|    value_loss         | 10.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 54100    |\n",
      "|    time_elapsed       | 228760   |\n",
      "|    total_timesteps    | 5410000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54099    |\n",
      "|    policy_loss        | -431     |\n",
      "|    reward             | 0.299868 |\n",
      "|    std                | 469      |\n",
      "|    value_loss         | 44.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54200     |\n",
      "|    time_elapsed       | 229179    |\n",
      "|    total_timesteps    | 5420000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54199     |\n",
      "|    policy_loss        | 36.7      |\n",
      "|    reward             | -0.000347 |\n",
      "|    std                | 471       |\n",
      "|    value_loss         | 0.817     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54300     |\n",
      "|    time_elapsed       | 229599    |\n",
      "|    total_timesteps    | 5430000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54299     |\n",
      "|    policy_loss        | -241      |\n",
      "|    reward             | -0.002615 |\n",
      "|    std                | 471       |\n",
      "|    value_loss         | 52.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54400     |\n",
      "|    time_elapsed       | 230019    |\n",
      "|    total_timesteps    | 5440000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54399     |\n",
      "|    policy_loss        | -392      |\n",
      "|    reward             | -0.000147 |\n",
      "|    std                | 471       |\n",
      "|    value_loss         | 69.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 54500    |\n",
      "|    time_elapsed       | 230439   |\n",
      "|    total_timesteps    | 5450000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54499    |\n",
      "|    policy_loss        | 771      |\n",
      "|    reward             | 5.507504 |\n",
      "|    std                | 470      |\n",
      "|    value_loss         | 197      |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 54600          |\n",
      "|    time_elapsed       | 230859         |\n",
      "|    total_timesteps    | 5460000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 54599          |\n",
      "|    policy_loss        | -96.1          |\n",
      "|    reward             | -0.00024599998 |\n",
      "|    std                | 470            |\n",
      "|    value_loss         | 14.2           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54700     |\n",
      "|    time_elapsed       | 231279    |\n",
      "|    total_timesteps    | 5470000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54699     |\n",
      "|    policy_loss        | 31.5      |\n",
      "|    reward             | -0.001381 |\n",
      "|    std                | 472       |\n",
      "|    value_loss         | 0.378     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 54800     |\n",
      "|    time_elapsed       | 231701    |\n",
      "|    total_timesteps    | 5480000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 54799     |\n",
      "|    policy_loss        | 303       |\n",
      "|    reward             | -0.002127 |\n",
      "|    std                | 473       |\n",
      "|    value_loss         | 24.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 54900    |\n",
      "|    time_elapsed       | 232122   |\n",
      "|    total_timesteps    | 5490000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -75.7    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 54899    |\n",
      "|    policy_loss        | -448     |\n",
      "|    reward             | 1.151129 |\n",
      "|    std                | 475      |\n",
      "|    value_loss         | 44.3     |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 23             |\n",
      "|    iterations         | 55000          |\n",
      "|    time_elapsed       | 232543         |\n",
      "|    total_timesteps    | 5500000        |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -75.8          |\n",
      "|    explained_variance | 5.96e-08       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 54999          |\n",
      "|    policy_loss        | 232            |\n",
      "|    reward             | -6.1000013e-05 |\n",
      "|    std                | 478            |\n",
      "|    value_loss         | 20.4           |\n",
      "------------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55100     |\n",
      "|    time_elapsed       | 232965    |\n",
      "|    total_timesteps    | 5510000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55099     |\n",
      "|    policy_loss        | 197       |\n",
      "|    reward             | -0.002646 |\n",
      "|    std                | 478       |\n",
      "|    value_loss         | 113       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55200     |\n",
      "|    time_elapsed       | 233386    |\n",
      "|    total_timesteps    | 5520000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55199     |\n",
      "|    policy_loss        | -130      |\n",
      "|    reward             | -0.003421 |\n",
      "|    std                | 478       |\n",
      "|    value_loss         | 40.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55300     |\n",
      "|    time_elapsed       | 233807    |\n",
      "|    total_timesteps    | 5530000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55299     |\n",
      "|    policy_loss        | 254       |\n",
      "|    reward             | -0.001236 |\n",
      "|    std                | 480       |\n",
      "|    value_loss         | 26.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55400     |\n",
      "|    time_elapsed       | 234226    |\n",
      "|    total_timesteps    | 5540000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55399     |\n",
      "|    policy_loss        | -438      |\n",
      "|    reward             | -0.003911 |\n",
      "|    std                | 482       |\n",
      "|    value_loss         | 155       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55500     |\n",
      "|    time_elapsed       | 234647    |\n",
      "|    total_timesteps    | 5550000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -75.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55499     |\n",
      "|    policy_loss        | -158      |\n",
      "|    reward             | -0.001964 |\n",
      "|    std                | 486       |\n",
      "|    value_loss         | 11.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 23       |\n",
      "|    iterations         | 55600    |\n",
      "|    time_elapsed       | 235069   |\n",
      "|    total_timesteps    | 5560000  |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -76      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 55599    |\n",
      "|    policy_loss        | -101     |\n",
      "|    reward             | -4.3e-05 |\n",
      "|    std                | 489      |\n",
      "|    value_loss         | 4.61     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55700     |\n",
      "|    time_elapsed       | 235490    |\n",
      "|    total_timesteps    | 5570000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55699     |\n",
      "|    policy_loss        | 113       |\n",
      "|    reward             | -0.003967 |\n",
      "|    std                | 492       |\n",
      "|    value_loss         | 4.4       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55800     |\n",
      "|    time_elapsed       | 235910    |\n",
      "|    total_timesteps    | 5580000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55799     |\n",
      "|    policy_loss        | -148      |\n",
      "|    reward             | -3.791651 |\n",
      "|    std                | 491       |\n",
      "|    value_loss         | 10.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 55900     |\n",
      "|    time_elapsed       | 236317    |\n",
      "|    total_timesteps    | 5590000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55899     |\n",
      "|    policy_loss        | -96.6     |\n",
      "|    reward             | 0.593291  |\n",
      "|    std                | 492       |\n",
      "|    value_loss         | 32        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 56000     |\n",
      "|    time_elapsed       | 236711    |\n",
      "|    total_timesteps    | 5600000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 55999     |\n",
      "|    policy_loss        | -2.36e+03 |\n",
      "|    reward             | -0.000148 |\n",
      "|    std                | 493       |\n",
      "|    value_loss         | 1.36e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 23        |\n",
      "|    iterations         | 56100     |\n",
      "|    time_elapsed       | 237107    |\n",
      "|    total_timesteps    | 5610000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -76.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 56099     |\n",
      "|    policy_loss        | -1.67e+03 |\n",
      "|    reward             | -0.00273  |\n",
      "|    std                | 494       |\n",
      "|    value_loss         | 625       |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=train.date.unique().shape[0]*75\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_a2c.save('./trained_models/a2cLOB_no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c67HYoXYN1vR"
   },
   "source": [
    "###**Trade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pq0Q3iCBNyx2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_daily_return, df_actions = DRL_prediction(model=trained_a2c,environment= e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "N2htLNjQN3gy"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2012-06-21T14:41:59.000000000]</td>\n",
       "      <td>100000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2012-06-21T14:41:59.250000000]</td>\n",
       "      <td>99970.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2012-06-21T14:41:59.500000000]</td>\n",
       "      <td>99914.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2012-06-21T14:41:59.750000000]</td>\n",
       "      <td>99898.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2012-06-21T14:42:00.000000000]</td>\n",
       "      <td>99867.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18715</th>\n",
       "      <td>[2012-06-21T15:59:57.750000000]</td>\n",
       "      <td>-170846.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18716</th>\n",
       "      <td>[2012-06-21T15:59:58.000000000]</td>\n",
       "      <td>-168354.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18717</th>\n",
       "      <td>[2012-06-21T15:59:58.250000000]</td>\n",
       "      <td>-150133.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18718</th>\n",
       "      <td>[2012-06-21T15:59:58.500000000]</td>\n",
       "      <td>-150376.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18719</th>\n",
       "      <td>[2012-06-21T15:59:58.750000000]</td>\n",
       "      <td>-207644.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18720 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  date  account_value\n",
       "0      [2012-06-21T14:41:59.000000000]      100000.00\n",
       "1      [2012-06-21T14:41:59.250000000]       99970.59\n",
       "2      [2012-06-21T14:41:59.500000000]       99914.04\n",
       "3      [2012-06-21T14:41:59.750000000]       99898.64\n",
       "4      [2012-06-21T14:42:00.000000000]       99867.52\n",
       "...                                ...            ...\n",
       "18715  [2012-06-21T15:59:57.750000000]     -170846.86\n",
       "18716  [2012-06-21T15:59:58.000000000]     -168354.87\n",
       "18717  [2012-06-21T15:59:58.250000000]     -150133.21\n",
       "18718  [2012-06-21T15:59:58.500000000]     -150376.42\n",
       "18719  [2012-06-21T15:59:58.750000000]     -207644.74\n",
       "\n",
       "[18720 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ImeW9Wwz1RNe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>INTC</th>\n",
       "      <th>MSFT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-06-21 14:42:02.250</th>\n",
       "      <td>SS1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>LB100</td>\n",
       "      <td>SB100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 14:42:27.250</th>\n",
       "      <td>LB100</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SS20.0</td>\n",
       "      <td>SS1</td>\n",
       "      <td>SB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 14:42:30.250</th>\n",
       "      <td>SS1</td>\n",
       "      <td>LB100</td>\n",
       "      <td>SS20.0</td>\n",
       "      <td>LS1</td>\n",
       "      <td>SB100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 14:43:10.000</th>\n",
       "      <td>SS1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>SS15.0</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SB100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 14:43:14.750</th>\n",
       "      <td>SS1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>LB35</td>\n",
       "      <td>SS100</td>\n",
       "      <td>SB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 15:57:39.750</th>\n",
       "      <td>SS10.0</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SS100</td>\n",
       "      <td>SS100</td>\n",
       "      <td>SB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 15:57:54.500</th>\n",
       "      <td>LB1</td>\n",
       "      <td>SS100</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SS1</td>\n",
       "      <td>SB100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 15:57:58.000</th>\n",
       "      <td>LB100</td>\n",
       "      <td>LB1</td>\n",
       "      <td>LB35.0</td>\n",
       "      <td>SS1</td>\n",
       "      <td>SB100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 15:59:28.500</th>\n",
       "      <td>SS1</td>\n",
       "      <td>LB1</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SS100</td>\n",
       "      <td>SB100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 15:59:35.500</th>\n",
       "      <td>LB1</td>\n",
       "      <td>SS61</td>\n",
       "      <td>LB100</td>\n",
       "      <td>LB1</td>\n",
       "      <td>SB1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AAPL   AMZN    GOOG   INTC   MSFT\n",
       "date                                                        \n",
       "2012-06-21 14:42:02.250     SS1    SS1     SS1  LB100  SB100\n",
       "2012-06-21 14:42:27.250   LB100    LB1  SS20.0    SS1    SB1\n",
       "2012-06-21 14:42:30.250     SS1  LB100  SS20.0    LS1  SB100\n",
       "2012-06-21 14:43:10.000     SS1    SS1  SS15.0    LB1  SB100\n",
       "2012-06-21 14:43:14.750     SS1    SS1    LB35  SS100    SB1\n",
       "...                         ...    ...     ...    ...    ...\n",
       "2012-06-21 15:57:39.750  SS10.0    LB1   SS100  SS100    SB1\n",
       "2012-06-21 15:57:54.500     LB1  SS100     LB1    SS1  SB100\n",
       "2012-06-21 15:57:58.000   LB100    LB1  LB35.0    SS1  SB100\n",
       "2012-06-21 15:59:28.500     SS1    LB1     LB1  SS100  SB100\n",
       "2012-06-21 15:59:35.500     LB1   SS61   LB100    LB1    SB1\n",
       "\n",
       "[277 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions[df_actions['MSFT'].str.match('^SB.*')]\n",
    "#df_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KfL8CF5E1bjl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LB1', 'LB100', 'LB43.0', ..., 'LB3.0', 'LB0.0', 'LB1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions['GOOG'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3py3WDAhN8Dh"
   },
   "source": [
    "###**BackTest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aKdudIieN6UV"
   },
   "outputs": [],
   "source": [
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from finrl.plot import backtest_plot,convert_daily_return_to_pyfolio_ts,get_daily_return\n",
    "from pyfolio import timeseries\n",
    "import pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "3eOzDmc3HsSr"
   },
   "outputs": [],
   "source": [
    "df_daily_return['date']=pd.DataFrame(np.concatenate(df_daily_return.date.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "fxH88JjNOA5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============A2C Strategy Stats===========\n",
      "Annual return                NaN\n",
      "Cumulative returns     -3.076447\n",
      "Annual volatility      50.664869\n",
      "Sharpe ratio            0.121508\n",
      "Calmar ratio                 NaN\n",
      "Stability                    NaN\n",
      "Max drawdown           -3.436573\n",
      "Omega ratio             1.588832\n",
      "Sortino ratio           0.245898\n",
      "Skew                         NaN\n",
      "Kurtosis                     NaN\n",
      "Tail ratio              1.093646\n",
      "Daily value at risk    -6.358744\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdelmoez/.local/lib/python3.8/site-packages/empyrical/stats.py:447: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return ending_value ** (1 / num_years) - 1\n",
      "/home/abdelmoez/.local/lib/python3.8/site-packages/empyrical/stats.py:1494: RuntimeWarning: invalid value encountered in log1p\n",
      "  cum_log_returns = np.log1p(returns).cumsum()\n"
     ]
    }
   ],
   "source": [
    "print(\"==============A2C Strategy Stats===========\")\n",
    "perf_stats_all = backtest_stats(df_daily_return)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GPU_DRLinLOB_Final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
